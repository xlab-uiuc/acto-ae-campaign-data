18:05:51 ConfigMap b569adb7.cassandra.datastax.com 995:	cass-operator-controller-manager-5956548988-vrj8q_98d072bc-227d-47bc-9d0f-697736c26b8b became leader
18:05:51 Lease b569adb7.cassandra.datastax.com 996:	cass-operator-controller-manager-5956548988-vrj8q_98d072bc-227d-47bc-9d0f-697736c26b8b became leader
18:07:07 ConfigMap b569adb7.cassandra.datastax.com 1364:	cass-operator-controller-manager-8467c6fbb-fdr8s_a2021d87-4431-4593-bc89-fd61ea58f354 became leader
18:07:07 Lease b569adb7.cassandra.datastax.com 1365:	cass-operator-controller-manager-8467c6fbb-fdr8s_a2021d87-4431-4593-bc89-fd61ea58f354 became leader
18:05:48 Pod cass-operator-controller-manager-5956548988-vrj8q 943:	Successfully assigned cass-operator/cass-operator-controller-manager-5956548988-vrj8q to acto-cluster-14-worker
18:05:48 Pod cass-operator-controller-manager-5956548988-vrj8q 946:	MountVolume.SetUp failed for volume "cert" : secret "webhook-server-cert" not found
18:05:50 Pod cass-operator-controller-manager-5956548988-vrj8q 946:	Container image "k8ssandra/cass-operator:v1.10.3" already present on machine
18:05:50 Pod cass-operator-controller-manager-5956548988-vrj8q 946:	Created container manager
18:05:50 Pod cass-operator-controller-manager-5956548988-vrj8q 946:	Started container manager
18:06:39 Pod cass-operator-controller-manager-5956548988-vrj8q 946:	Stopping container manager
18:05:48 ReplicaSet cass-operator-controller-manager-5956548988 940:	Created pod: cass-operator-controller-manager-5956548988-vrj8q
18:06:39 ReplicaSet cass-operator-controller-manager-5956548988 1277:	Deleted pod: cass-operator-controller-manager-5956548988-vrj8q
18:06:29 Pod cass-operator-controller-manager-8467c6fbb-fdr8s 1117:	Successfully assigned cass-operator/cass-operator-controller-manager-8467c6fbb-fdr8s to acto-cluster-14-worker3
18:06:29 Pod cass-operator-controller-manager-8467c6fbb-fdr8s 1120:	Container image "k8ssandra/cass-operator:v1.10.3" already present on machine
18:06:29 Pod cass-operator-controller-manager-8467c6fbb-fdr8s 1120:	Created container manager
18:06:30 Pod cass-operator-controller-manager-8467c6fbb-fdr8s 1120:	Started container manager
18:06:29 ReplicaSet cass-operator-controller-manager-8467c6fbb 1113:	Created pod: cass-operator-controller-manager-8467c6fbb-fdr8s
18:05:48 Deployment cass-operator-controller-manager 939:	Scaled up replica set cass-operator-controller-manager-5956548988 to 1
18:06:28 Deployment cass-operator-controller-manager 1112:	Scaled up replica set cass-operator-controller-manager-8467c6fbb to 1
18:06:39 Deployment cass-operator-controller-manager 1125:	Scaled down replica set cass-operator-controller-manager-5956548988 to 0
18:05:48 CertificateRequest cass-operator-serving-cert-sspz4 969:	Certificate request has been approved by cert-manager.io
18:05:48 CertificateRequest cass-operator-serving-cert-sspz4 971:	Certificate will be issued with an empty Issuer DN, which contravenes RFC 5280 and could break some strict clients
18:05:48 CertificateRequest cass-operator-serving-cert-sspz4 971:	Certificate fetched from issuer successfully
18:05:48 Certificate cass-operator-serving-cert 958:	Issuing certificate as Secret does not exist
18:05:48 Certificate cass-operator-serving-cert 961:	Stored new private key in temporary Secret resource "cass-operator-serving-cert-7v7pr"
18:05:48 Certificate cass-operator-serving-cert 967:	Created new CertificateRequest resource "cass-operator-serving-cert-sspz4"
18:05:48 Certificate cass-operator-serving-cert 967:	The certificate has been successfully issued
18:06:36 Pod cluster1-test-cluster-default-sts-0 1165:	Successfully assigned cass-operator/cluster1-test-cluster-default-sts-0 to acto-cluster-14-worker
18:06:36 Pod cluster1-test-cluster-default-sts-0 1244:	MountVolume.SetUp failed for volume "encryption-cred-storage" : secret "test-cluster-keystore" not found
18:08:39 Pod cluster1-test-cluster-default-sts-0 1244:	Unable to attach or mount volumes: unmounted volumes=[encryption-cred-storage], unattached volumes=[server-logs server-data encryption-cred-storage server-config kube-api-access-sk4rl]: timed out waiting for the condition
18:08:54 Pod cluster1-test-cluster-default-sts-0 1244:	Container image "datastax/cass-config-builder:1.0.4-ubi7" already present on machine
18:08:54 Pod cluster1-test-cluster-default-sts-0 1244:	Created container server-config-init
18:08:55 Pod cluster1-test-cluster-default-sts-0 1244:	Started container server-config-init
18:08:59 Pod cluster1-test-cluster-default-sts-0 1244:	Container image "k8ssandra/cass-management-api:3.11.7" already present on machine
18:08:59 Pod cluster1-test-cluster-default-sts-0 1244:	Created container cassandra
18:08:59 Pod cluster1-test-cluster-default-sts-0 1244:	Started container cassandra
18:08:59 Pod cluster1-test-cluster-default-sts-0 1244:	Container image "k8ssandra/system-logger:v1.10.3" already present on machine
18:08:59 Pod cluster1-test-cluster-default-sts-0 1244:	Created container server-system-logger
18:09:00 Pod cluster1-test-cluster-default-sts-0 1244:	Started container server-system-logger
18:09:26 Pod cluster1-test-cluster-default-sts-0 1244:	Readiness probe failed: HTTP probe failed with statuscode: 500
18:06:36 Pod cluster1-test-cluster-default-sts-1 1173:	Successfully assigned cass-operator/cluster1-test-cluster-default-sts-1 to acto-cluster-14-worker3
18:06:36 Pod cluster1-test-cluster-default-sts-1 1246:	MountVolume.SetUp failed for volume "encryption-cred-storage" : secret "test-cluster-keystore" not found
18:08:39 Pod cluster1-test-cluster-default-sts-1 1246:	Unable to attach or mount volumes: unmounted volumes=[encryption-cred-storage], unattached volumes=[server-data encryption-cred-storage server-config kube-api-access-49rpl server-logs]: timed out waiting for the condition
18:08:54 Pod cluster1-test-cluster-default-sts-1 1246:	Container image "datastax/cass-config-builder:1.0.4-ubi7" already present on machine
18:08:54 Pod cluster1-test-cluster-default-sts-1 1246:	Created container server-config-init
18:08:55 Pod cluster1-test-cluster-default-sts-1 1246:	Started container server-config-init
18:08:59 Pod cluster1-test-cluster-default-sts-1 1246:	Container image "k8ssandra/cass-management-api:3.11.7" already present on machine
18:08:59 Pod cluster1-test-cluster-default-sts-1 1246:	Created container cassandra
18:08:59 Pod cluster1-test-cluster-default-sts-1 1246:	Started container cassandra
18:08:59 Pod cluster1-test-cluster-default-sts-1 1246:	Container image "k8ssandra/system-logger:v1.10.3" already present on machine
18:08:59 Pod cluster1-test-cluster-default-sts-1 1246:	Created container server-system-logger
18:09:00 Pod cluster1-test-cluster-default-sts-1 1246:	Started container server-system-logger
18:09:26 Pod cluster1-test-cluster-default-sts-1 1246:	Readiness probe failed: HTTP probe failed with statuscode: 500
18:06:37 Pod cluster1-test-cluster-default-sts-2 1182:	Successfully assigned cass-operator/cluster1-test-cluster-default-sts-2 to acto-cluster-14-worker2
18:06:37 Pod cluster1-test-cluster-default-sts-2 1262:	MountVolume.SetUp failed for volume "encryption-cred-storage" : secret "test-cluster-keystore" not found
18:08:40 Pod cluster1-test-cluster-default-sts-2 1262:	Unable to attach or mount volumes: unmounted volumes=[encryption-cred-storage], unattached volumes=[server-config kube-api-access-7g9b5 server-logs server-data encryption-cred-storage]: timed out waiting for the condition
18:08:56 Pod cluster1-test-cluster-default-sts-2 1262:	Container image "datastax/cass-config-builder:1.0.4-ubi7" already present on machine
18:08:56 Pod cluster1-test-cluster-default-sts-2 1262:	Created container server-config-init
18:08:56 Pod cluster1-test-cluster-default-sts-2 1262:	Started container server-config-init
18:09:00 Pod cluster1-test-cluster-default-sts-2 1262:	Container image "k8ssandra/cass-management-api:3.11.7" already present on machine
18:09:00 Pod cluster1-test-cluster-default-sts-2 1262:	Created container cassandra
18:09:00 Pod cluster1-test-cluster-default-sts-2 1262:	Started container cassandra
18:09:00 Pod cluster1-test-cluster-default-sts-2 1262:	Container image "k8ssandra/system-logger:v1.10.3" already present on machine
18:09:00 Pod cluster1-test-cluster-default-sts-2 1262:	Created container server-system-logger
18:09:01 Pod cluster1-test-cluster-default-sts-2 1262:	Started container server-system-logger
18:09:27 Pod cluster1-test-cluster-default-sts-2 1262:	Readiness probe failed: HTTP probe failed with statuscode: 500
18:12:30 Pod cluster1-test-cluster-default-sts-2 1262:	Stopping container cassandra
18:06:32 StatefulSet cluster1-test-cluster-default-sts 1158:	create Claim server-data-cluster1-test-cluster-default-sts-0 Pod cluster1-test-cluster-default-sts-0 in StatefulSet cluster1-test-cluster-default-sts success
18:06:32 StatefulSet cluster1-test-cluster-default-sts 1158:	create Pod cluster1-test-cluster-default-sts-0 in StatefulSet cluster1-test-cluster-default-sts successful
18:06:32 StatefulSet cluster1-test-cluster-default-sts 1158:	create Claim server-data-cluster1-test-cluster-default-sts-1 Pod cluster1-test-cluster-default-sts-1 in StatefulSet cluster1-test-cluster-default-sts success
18:06:32 StatefulSet cluster1-test-cluster-default-sts 1158:	create Pod cluster1-test-cluster-default-sts-1 in StatefulSet cluster1-test-cluster-default-sts successful
18:06:32 StatefulSet cluster1-test-cluster-default-sts 1158:	create Claim server-data-cluster1-test-cluster-default-sts-2 Pod cluster1-test-cluster-default-sts-2 in StatefulSet cluster1-test-cluster-default-sts success
18:06:32 StatefulSet cluster1-test-cluster-default-sts 1158:	create Pod cluster1-test-cluster-default-sts-2 in StatefulSet cluster1-test-cluster-default-sts successful
18:12:30 StatefulSet cluster1-test-cluster-default-sts 2412:	delete Pod cluster1-test-cluster-default-sts-2 in StatefulSet cluster1-test-cluster-default-sts successful
18:12:33 StatefulSet cluster1-test-cluster-default-sts 2440:	create Pod cluster1-test-cluster-default-sts-2 in StatefulSet cluster1-test-cluster-default-sts failed error: Pod "cluster1-test-cluster-default-sts-2" is invalid: [spec.containers[0].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[0].image: Required value, spec.containers[1].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[1].name: Duplicate value: "ACTOKEY", spec.containers[1].image: Required value, spec.containers[2].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[2].name: Duplicate value: "ACTOKEY", spec.containers[2].image: Required value, spec.containers[3].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[3].name: Duplicate value: "ACTOKEY", spec.containers[3].image: Required value, spec.initContainers[0].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.initContainers[0].image: Required value, spec.initContainers[0].resources.requests: Invalid value: "1": must be less than or equal to cpu limit, spec.initContainers[0].resources.requests[cwztszfdoy]: Invalid value: "cwztszfdoy": must be a standard resource type or fully qualified, spec.initContainers[0].resources.requests[cwztszfdoy]: Invalid value: "cwztszfdoy": must be a standard resource for containers, spec.initContainers[0].name: Duplicate value: "ACTOKEY"]
18:12:33 StatefulSet cluster1-test-cluster-default-sts 2440:	create Pod cluster1-test-cluster-default-sts-2 in StatefulSet cluster1-test-cluster-default-sts failed error: Pod "cluster1-test-cluster-default-sts-2" is invalid: [spec.containers[0].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[0].image: Required value, spec.containers[1].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[1].name: Duplicate value: "ACTOKEY", spec.containers[1].image: Required value, spec.containers[2].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[2].name: Duplicate value: "ACTOKEY", spec.containers[2].image: Required value, spec.containers[3].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.containers[3].name: Duplicate value: "ACTOKEY", spec.containers[3].image: Required value, spec.initContainers[0].name: Invalid value: "ACTOKEY": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?'), spec.initContainers[0].image: Required value, spec.initContainers[0].resources.requests[cwztszfdoy]: Invalid value: "cwztszfdoy": must be a standard resource type or fully qualified, spec.initContainers[0].resources.requests[cwztszfdoy]: Invalid value: "cwztszfdoy": must be a standard resource for containers, spec.initContainers[0].resources.requests: Invalid value: "1": must be less than or equal to cpu limit, spec.initContainers[0].name: Duplicate value: "ACTOKEY"]
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-0 1163:	waiting for first consumer to be created before binding
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-0 1174:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-0 1174:	External provisioner is provisioning volume for claim "cass-operator/server-data-cluster1-test-cluster-default-sts-0"
18:06:36 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-0 1174:	Successfully provisioned volume pvc-c9eba936-e05e-4a13-b439-e392f3acdf4d
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-1 1166:	waiting for first consumer to be created before binding
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-1 1183:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-1 1183:	External provisioner is provisioning volume for claim "cass-operator/server-data-cluster1-test-cluster-default-sts-1"
18:06:36 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-1 1183:	Successfully provisioned volume pvc-31216b44-ee12-4265-b5ba-2a7e4cec1e12
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-2 1176:	waiting for first consumer to be created before binding
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-2 1189:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
18:06:32 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-2 1189:	External provisioner is provisioning volume for claim "cass-operator/server-data-cluster1-test-cluster-default-sts-2"
18:06:36 PersistentVolumeClaim server-data-cluster1-test-cluster-default-sts-2 1189:	Successfully provisioned volume pvc-109e3531-a9ef-4ca9-afc1-4c6b13a89f6f
18:06:32 CassandraDatacenter test-cluster 1142:	Created service cluster1-test-cluster-service
18:06:32 CassandraDatacenter test-cluster 1142:	Created service cluster1-seed-service
18:06:32 CassandraDatacenter test-cluster 1142:	Created service cluster1-test-cluster-all-pods-service
18:06:32 CassandraDatacenter test-cluster 1142:	Created service cluster1-test-cluster-additional-seed-service
18:06:32 CassandraDatacenter test-cluster 1157:	Created statefulset cluster1-test-cluster-default-sts
18:09:10 CassandraDatacenter test-cluster 1370:	Labeled pod a seed node cluster1-test-cluster-default-sts-0
18:09:15 CassandraDatacenter test-cluster 1370:	Starting Cassandra for pod cluster1-test-cluster-default-sts-0
18:09:36 CassandraDatacenter test-cluster 1854:	Started Cassandra for pod cluster1-test-cluster-default-sts-0
18:09:36 CassandraDatacenter test-cluster 1854:	Starting Cassandra for pod cluster1-test-cluster-default-sts-1
18:10:36 CassandraDatacenter test-cluster 2021:	Labeled as seed node pod cluster1-test-cluster-default-sts-1
18:10:36 CassandraDatacenter test-cluster 2021:	Started Cassandra for pod cluster1-test-cluster-default-sts-1
18:10:36 CassandraDatacenter test-cluster 2021:	Starting Cassandra for pod cluster1-test-cluster-default-sts-2
18:11:27 CassandraDatacenter test-cluster 2201:	Labeled as seed node pod cluster1-test-cluster-default-sts-2
18:11:27 CassandraDatacenter test-cluster 2201:	Started Cassandra for pod cluster1-test-cluster-default-sts-2
18:11:27 CassandraDatacenter test-cluster 2201:	Created PodDisruptionBudget test-cluster-pdb
18:11:27 CassandraDatacenter test-cluster 2201:	Created users
18:11:27 CassandraDatacenter test-cluster 2201:	Created superuser
18:12:29 CassandraDatacenter test-cluster 2408:	Updating rack default
18:12:49 CassandraDatacenter test-cluster 2414:	checks failed desired:3, ready:2, started:2
