12:21:53 HorizontalPodAutoscaler broker-filter-hpa 1486:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:53 HorizontalPodAutoscaler broker-filter-hpa 1486:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:34 HorizontalPodAutoscaler broker-filter-hpa 3411:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:34 HorizontalPodAutoscaler broker-filter-hpa 3411:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:23 HorizontalPodAutoscaler broker-filter-hpa 5636:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:23 HorizontalPodAutoscaler broker-filter-hpa 5636:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:25 HorizontalPodAutoscaler broker-filter-hpa 7824:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:25 HorizontalPodAutoscaler broker-filter-hpa 7824:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:43:10 HorizontalPodAutoscaler broker-filter-hpa 9891:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:43:10 HorizontalPodAutoscaler broker-filter-hpa 9891:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:51 HorizontalPodAutoscaler broker-filter-hpa 11990:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:51 HorizontalPodAutoscaler broker-filter-hpa 11990:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:53 HorizontalPodAutoscaler broker-ingress-hpa 1485:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:53 HorizontalPodAutoscaler broker-ingress-hpa 1485:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:34 HorizontalPodAutoscaler broker-ingress-hpa 3402:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:34 HorizontalPodAutoscaler broker-ingress-hpa 3402:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:23 HorizontalPodAutoscaler broker-ingress-hpa 5625:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:23 HorizontalPodAutoscaler broker-ingress-hpa 5625:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:25 HorizontalPodAutoscaler broker-ingress-hpa 7820:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:25 HorizontalPodAutoscaler broker-ingress-hpa 7820:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:43:10 HorizontalPodAutoscaler broker-ingress-hpa 9889:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:43:10 HorizontalPodAutoscaler broker-ingress-hpa 9889:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:51 HorizontalPodAutoscaler broker-ingress-hpa 11989:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:51 HorizontalPodAutoscaler broker-ingress-hpa 11989:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:04 Pod eventing-controller-578f9ff97f-zmjkf 7585:	Successfully assigned knative-eventing/eventing-controller-578f9ff97f-zmjkf to acto-cluster-3-worker
12:38:05 Pod eventing-controller-578f9ff97f-zmjkf 7587:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:38:05 Pod eventing-controller-578f9ff97f-zmjkf 7587:	Created container eventing-controller
12:38:05 Pod eventing-controller-578f9ff97f-zmjkf 7587:	Started container eventing-controller
12:42:20 Pod eventing-controller-578f9ff97f-zmjkf 7587:	Stopping container eventing-controller
12:38:04 ReplicaSet eventing-controller-578f9ff97f 7582:	Created pod: eventing-controller-578f9ff97f-zmjkf
12:21:32 Pod eventing-controller-59fb498864-q6788 1170:	Successfully assigned knative-eventing/eventing-controller-59fb498864-q6788 to acto-cluster-3-worker
12:21:33 Pod eventing-controller-59fb498864-q6788 1174:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:21:36 Pod eventing-controller-59fb498864-q6788 1174:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.306720887s
12:21:36 Pod eventing-controller-59fb498864-q6788 1174:	Created container eventing-controller
12:21:36 Pod eventing-controller-59fb498864-q6788 1174:	Started container eventing-controller
12:25:44 Pod eventing-controller-59fb498864-q6788 1174:	Stopping container eventing-controller
12:21:32 ReplicaSet eventing-controller-59fb498864 1168:	Created pod: eventing-controller-59fb498864-q6788
12:26:13 Pod eventing-controller-6c78bb8c7f-4tz8c 3186:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-4tz8c to acto-cluster-3-worker
12:26:13 Pod eventing-controller-6c78bb8c7f-4tz8c 3187:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:26:13 Pod eventing-controller-6c78bb8c7f-4tz8c 3187:	Created container eventing-controller
12:26:13 Pod eventing-controller-6c78bb8c7f-4tz8c 3187:	Started container eventing-controller
12:30:25 Pod eventing-controller-6c78bb8c7f-4tz8c 3187:	Stopping container eventing-controller
12:32:02 Pod eventing-controller-6c78bb8c7f-nf84c 5393:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-nf84c to acto-cluster-3-worker
12:32:03 Pod eventing-controller-6c78bb8c7f-nf84c 5395:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:32:03 Pod eventing-controller-6c78bb8c7f-nf84c 5395:	Created container eventing-controller
12:32:03 Pod eventing-controller-6c78bb8c7f-nf84c 5395:	Started container eventing-controller
12:36:14 Pod eventing-controller-6c78bb8c7f-nf84c 5395:	Stopping container eventing-controller
12:26:13 ReplicaSet eventing-controller-6c78bb8c7f 3183:	Created pod: eventing-controller-6c78bb8c7f-4tz8c
12:32:02 ReplicaSet eventing-controller-6c78bb8c7f 5390:	Created pod: eventing-controller-6c78bb8c7f-nf84c
12:47:30 Pod eventing-controller-779fbf8f65-wb4gp 11744:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-wb4gp to acto-cluster-3-worker2
12:47:30 Pod eventing-controller-779fbf8f65-wb4gp 11747:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:47:30 Pod eventing-controller-779fbf8f65-wb4gp 11747:	Created container eventing-controller
12:47:30 Pod eventing-controller-779fbf8f65-wb4gp 11747:	Started container eventing-controller
12:51:42 Pod eventing-controller-779fbf8f65-wb4gp 11747:	Stopping container eventing-controller
12:47:30 ReplicaSet eventing-controller-779fbf8f65 11741:	Created pod: eventing-controller-779fbf8f65-wb4gp
12:42:49 Pod eventing-controller-86d49cf697-2zx6x 9670:	Successfully assigned knative-eventing/eventing-controller-86d49cf697-2zx6x to acto-cluster-3-worker2
12:42:49 Pod eventing-controller-86d49cf697-2zx6x 9672:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:42:52 Pod eventing-controller-86d49cf697-2zx6x 9672:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.717923107s
12:42:52 Pod eventing-controller-86d49cf697-2zx6x 9672:	Created container eventing-controller
12:42:52 Pod eventing-controller-86d49cf697-2zx6x 9672:	Started container eventing-controller
12:47:01 Pod eventing-controller-86d49cf697-2zx6x 9672:	Stopping container eventing-controller
12:42:49 ReplicaSet eventing-controller-86d49cf697 9667:	Created pod: eventing-controller-86d49cf697-2zx6x
12:21:32 Deployment eventing-controller 1167:	Scaled up replica set eventing-controller-59fb498864 to 1
12:26:13 Deployment eventing-controller 3182:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:32:02 Deployment eventing-controller 5389:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:38:04 Deployment eventing-controller 7581:	Scaled up replica set eventing-controller-578f9ff97f to 1
12:42:49 Deployment eventing-controller 9666:	Scaled up replica set eventing-controller-86d49cf697 to 1
12:47:30 Deployment eventing-controller 11740:	Scaled up replica set eventing-controller-779fbf8f65 to 1
12:38:05 Pod eventing-webhook-5755489569-cqzph 7613:	Successfully assigned knative-eventing/eventing-webhook-5755489569-cqzph to acto-cluster-3-worker
12:38:06 Pod eventing-webhook-5755489569-cqzph 7615:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:38:09 Pod eventing-webhook-5755489569-cqzph 7615:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.735371713s
12:38:09 Pod eventing-webhook-5755489569-cqzph 7615:	Created container eventing-webhook
12:38:09 Pod eventing-webhook-5755489569-cqzph 7615:	Started container eventing-webhook
12:38:10 Pod eventing-webhook-5755489569-cqzph 7615:	Readiness probe failed: Get "https://10.244.3.10:8443/": dial tcp 10.244.3.10:8443: connect: connection refused
12:38:10 Pod eventing-webhook-5755489569-cqzph 7615:	Readiness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:42:19 Pod eventing-webhook-5755489569-cqzph 7615:	Liveness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:42:19 Pod eventing-webhook-5755489569-cqzph 7615:	Stopping container eventing-webhook
12:21:33 Pod eventing-webhook-5755489569-dnq8s 1199:	Successfully assigned knative-eventing/eventing-webhook-5755489569-dnq8s to acto-cluster-3-worker3
12:21:34 Pod eventing-webhook-5755489569-dnq8s 1203:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:21:38 Pod eventing-webhook-5755489569-dnq8s 1203:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 3.810615388s
12:21:38 Pod eventing-webhook-5755489569-dnq8s 1203:	Created container eventing-webhook
12:21:38 Pod eventing-webhook-5755489569-dnq8s 1203:	Started container eventing-webhook
12:21:39 Pod eventing-webhook-5755489569-dnq8s 1203:	Readiness probe failed: Get "https://10.244.1.3:8443/": dial tcp 10.244.1.3:8443: connect: connection refused
12:21:39 Pod eventing-webhook-5755489569-dnq8s 1203:	Readiness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
12:25:43 Pod eventing-webhook-5755489569-dnq8s 1203:	Liveness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
12:25:43 Pod eventing-webhook-5755489569-dnq8s 1203:	Stopping container eventing-webhook
12:32:03 Pod eventing-webhook-5755489569-dxmbs 5417:	Successfully assigned knative-eventing/eventing-webhook-5755489569-dxmbs to acto-cluster-3-worker2
12:32:04 Pod eventing-webhook-5755489569-dxmbs 5421:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:32:04 Pod eventing-webhook-5755489569-dxmbs 5421:	Created container eventing-webhook
12:32:04 Pod eventing-webhook-5755489569-dxmbs 5421:	Started container eventing-webhook
12:32:05 Pod eventing-webhook-5755489569-dxmbs 5421:	Readiness probe failed: Get "https://10.244.2.9:8443/": remote error: tls: unrecognized name
12:36:13 Pod eventing-webhook-5755489569-dxmbs 5421:	Liveness probe failed: Get "https://10.244.2.9:8443/": remote error: tls: unrecognized name
12:36:13 Pod eventing-webhook-5755489569-dxmbs 5421:	Stopping container eventing-webhook
12:26:13 Pod eventing-webhook-5755489569-fktsb 3211:	Successfully assigned knative-eventing/eventing-webhook-5755489569-fktsb to acto-cluster-3-worker2
12:26:14 Pod eventing-webhook-5755489569-fktsb 3214:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:26:17 Pod eventing-webhook-5755489569-fktsb 3214:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.715249839s
12:26:17 Pod eventing-webhook-5755489569-fktsb 3214:	Created container eventing-webhook
12:26:18 Pod eventing-webhook-5755489569-fktsb 3214:	Started container eventing-webhook
12:26:18 Pod eventing-webhook-5755489569-fktsb 3214:	Readiness probe failed: Get "https://10.244.2.5:8443/": remote error: tls: unrecognized name
12:30:23 Pod eventing-webhook-5755489569-fktsb 3214:	Liveness probe failed: Get "https://10.244.2.5:8443/": remote error: tls: unrecognized name
12:30:24 Pod eventing-webhook-5755489569-fktsb 3214:	Stopping container eventing-webhook
12:42:49 Pod eventing-webhook-5755489569-khfpq 9695:	Successfully assigned knative-eventing/eventing-webhook-5755489569-khfpq to acto-cluster-3-worker3
12:42:50 Pod eventing-webhook-5755489569-khfpq 9698:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:42:50 Pod eventing-webhook-5755489569-khfpq 9698:	Created container eventing-webhook
12:42:51 Pod eventing-webhook-5755489569-khfpq 9698:	Started container eventing-webhook
12:46:59 Pod eventing-webhook-5755489569-khfpq 9698:	Readiness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:46:59 Pod eventing-webhook-5755489569-khfpq 9698:	Liveness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:47:00 Pod eventing-webhook-5755489569-khfpq 9698:	Stopping container eventing-webhook
12:47:30 Pod eventing-webhook-5755489569-nq8nq 11770:	Successfully assigned knative-eventing/eventing-webhook-5755489569-nq8nq to acto-cluster-3-worker2
12:47:31 Pod eventing-webhook-5755489569-nq8nq 11772:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:47:31 Pod eventing-webhook-5755489569-nq8nq 11772:	Created container eventing-webhook
12:47:32 Pod eventing-webhook-5755489569-nq8nq 11772:	Started container eventing-webhook
12:47:32 Pod eventing-webhook-5755489569-nq8nq 11772:	Readiness probe failed: Get "https://10.244.2.20:8443/": dial tcp 10.244.2.20:8443: connect: connection refused
12:51:40 Pod eventing-webhook-5755489569-nq8nq 11772:	Readiness probe failed: Get "https://10.244.2.20:8443/": remote error: tls: unrecognized name
12:51:40 Pod eventing-webhook-5755489569-nq8nq 11772:	Liveness probe failed: Get "https://10.244.2.20:8443/": remote error: tls: unrecognized name
12:51:41 Pod eventing-webhook-5755489569-nq8nq 11772:	Stopping container eventing-webhook
12:21:33 ReplicaSet eventing-webhook-5755489569 1196:	Created pod: eventing-webhook-5755489569-dnq8s
12:26:13 ReplicaSet eventing-webhook-5755489569 3209:	Created pod: eventing-webhook-5755489569-fktsb
12:32:03 ReplicaSet eventing-webhook-5755489569 5415:	Created pod: eventing-webhook-5755489569-dxmbs
12:38:05 ReplicaSet eventing-webhook-5755489569 7610:	Created pod: eventing-webhook-5755489569-cqzph
12:42:49 ReplicaSet eventing-webhook-5755489569 9693:	Created pod: eventing-webhook-5755489569-khfpq
12:47:30 ReplicaSet eventing-webhook-5755489569 11766:	Created pod: eventing-webhook-5755489569-nq8nq
12:21:33 PodDisruptionBudget eventing-webhook 1189:	No matching pods found
12:21:33 Deployment eventing-webhook 1195:	Scaled up replica set eventing-webhook-5755489569 to 1
12:21:47 HorizontalPodAutoscaler eventing-webhook 1231:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:47 HorizontalPodAutoscaler eventing-webhook 1231:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:25:43 PodDisruptionBudget eventing-webhook 1480:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:26:13 PodDisruptionBudget eventing-webhook 3204:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:26:13 Deployment eventing-webhook 3208:	Scaled up replica set eventing-webhook-5755489569 to 1
12:26:13 PodDisruptionBudget eventing-webhook 3205:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-dnq8s"
12:26:28 HorizontalPodAutoscaler eventing-webhook 3201:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:28 HorizontalPodAutoscaler eventing-webhook 3201:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:03 PodDisruptionBudget eventing-webhook 5410:	No matching pods found
12:32:03 Deployment eventing-webhook 5414:	Scaled up replica set eventing-webhook-5755489569 to 1
12:32:17 HorizontalPodAutoscaler eventing-webhook 5407:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:17 HorizontalPodAutoscaler eventing-webhook 5407:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:36:13 PodDisruptionBudget eventing-webhook 5869:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:38:05 PodDisruptionBudget eventing-webhook 7604:	No matching pods found
12:38:05 Deployment eventing-webhook 7609:	Scaled up replica set eventing-webhook-5755489569 to 1
12:38:20 HorizontalPodAutoscaler eventing-webhook 7599:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:20 HorizontalPodAutoscaler eventing-webhook 7599:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:19 PodDisruptionBudget eventing-webhook 8057:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:42:49 PodDisruptionBudget eventing-webhook 9687:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:42:49 Deployment eventing-webhook 9692:	Scaled up replica set eventing-webhook-5755489569 to 1
12:42:49 PodDisruptionBudget eventing-webhook 9690:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-cqzph"
12:43:04 HorizontalPodAutoscaler eventing-webhook 9684:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:43:04 HorizontalPodAutoscaler eventing-webhook 9684:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:30 PodDisruptionBudget eventing-webhook 11759:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:47:30 Deployment eventing-webhook 11765:	Scaled up replica set eventing-webhook-5755489569 to 1
12:47:30 PodDisruptionBudget eventing-webhook 11763:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-khfpq"
12:47:45 HorizontalPodAutoscaler eventing-webhook 11758:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:45 HorizontalPodAutoscaler eventing-webhook 11758:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:33 Pod imc-controller-567b4f565b-chxjr 11853:	Successfully assigned knative-eventing/imc-controller-567b4f565b-chxjr to acto-cluster-3-worker2
12:47:34 Pod imc-controller-567b4f565b-chxjr 11856:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:47:34 Pod imc-controller-567b4f565b-chxjr 11856:	Created container controller
12:47:34 Pod imc-controller-567b4f565b-chxjr 11856:	Started container controller
12:51:38 Pod imc-controller-567b4f565b-chxjr 11856:	Readiness probe failed: Get "https://10.244.2.21:8443/": remote error: tls: unrecognized name
12:51:38 Pod imc-controller-567b4f565b-chxjr 11856:	Liveness probe failed: Get "https://10.244.2.21:8443/": remote error: tls: unrecognized name
12:51:39 Pod imc-controller-567b4f565b-chxjr 11856:	Stopping container controller
12:42:52 Pod imc-controller-567b4f565b-f57zz 9761:	Successfully assigned knative-eventing/imc-controller-567b4f565b-f57zz to acto-cluster-3-worker
12:42:53 Pod imc-controller-567b4f565b-f57zz 9764:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:42:55 Pod imc-controller-567b4f565b-f57zz 9764:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.716830068s
12:42:55 Pod imc-controller-567b4f565b-f57zz 9764:	Created container controller
12:42:56 Pod imc-controller-567b4f565b-f57zz 9764:	Started container controller
12:46:57 Pod imc-controller-567b4f565b-f57zz 9764:	Liveness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
12:46:57 Pod imc-controller-567b4f565b-f57zz 9764:	Readiness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
12:46:58 Pod imc-controller-567b4f565b-f57zz 9764:	Stopping container controller
12:21:35 Pod imc-controller-567b4f565b-fhk9b 1249:	Successfully assigned knative-eventing/imc-controller-567b4f565b-fhk9b to acto-cluster-3-worker2
12:21:36 Pod imc-controller-567b4f565b-fhk9b 1251:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:21:39 Pod imc-controller-567b4f565b-fhk9b 1251:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 3.045471277s
12:21:39 Pod imc-controller-567b4f565b-fhk9b 1251:	Created container controller
12:21:39 Pod imc-controller-567b4f565b-fhk9b 1251:	Started container controller
12:25:40 Pod imc-controller-567b4f565b-fhk9b 1251:	Liveness probe failed: Get "https://10.244.2.3:8443/": remote error: tls: unrecognized name
12:25:40 Pod imc-controller-567b4f565b-fhk9b 1251:	Readiness probe failed: Get "https://10.244.2.3:8443/": remote error: tls: unrecognized name
12:25:41 Pod imc-controller-567b4f565b-fhk9b 1251:	Stopping container controller
12:32:06 Pod imc-controller-567b4f565b-mphk8 5499:	Successfully assigned knative-eventing/imc-controller-567b4f565b-mphk8 to acto-cluster-3-worker2
12:32:06 Pod imc-controller-567b4f565b-mphk8 5502:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:32:06 Pod imc-controller-567b4f565b-mphk8 5502:	Created container controller
12:32:06 Pod imc-controller-567b4f565b-mphk8 5502:	Started container controller
12:36:11 Pod imc-controller-567b4f565b-mphk8 5502:	Readiness probe failed: Get "https://10.244.2.10:8443/": remote error: tls: unrecognized name
12:36:11 Pod imc-controller-567b4f565b-mphk8 5502:	Liveness probe failed: Get "https://10.244.2.10:8443/": remote error: tls: unrecognized name
12:36:11 Pod imc-controller-567b4f565b-mphk8 5502:	Stopping container controller
12:26:16 Pod imc-controller-567b4f565b-pkzxd 3272:	Successfully assigned knative-eventing/imc-controller-567b4f565b-pkzxd to acto-cluster-3-worker3
12:26:17 Pod imc-controller-567b4f565b-pkzxd 3275:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:26:19 Pod imc-controller-567b4f565b-pkzxd 3275:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.640753084s
12:26:19 Pod imc-controller-567b4f565b-pkzxd 3275:	Created container controller
12:26:20 Pod imc-controller-567b4f565b-pkzxd 3275:	Started container controller
12:30:21 Pod imc-controller-567b4f565b-pkzxd 3275:	Liveness probe failed: Get "https://10.244.1.7:8443/": remote error: tls: unrecognized name
12:30:21 Pod imc-controller-567b4f565b-pkzxd 3275:	Readiness probe failed: Get "https://10.244.1.7:8443/": remote error: tls: unrecognized name
12:30:21 Pod imc-controller-567b4f565b-pkzxd 3275:	Stopping container controller
12:38:08 Pod imc-controller-567b4f565b-sdhpp 7671:	Successfully assigned knative-eventing/imc-controller-567b4f565b-sdhpp to acto-cluster-3-worker3
12:38:08 Pod imc-controller-567b4f565b-sdhpp 7674:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:38:08 Pod imc-controller-567b4f565b-sdhpp 7674:	Created container controller
12:38:08 Pod imc-controller-567b4f565b-sdhpp 7674:	Started container controller
12:42:16 Pod imc-controller-567b4f565b-sdhpp 7674:	Liveness probe failed: Get "https://10.244.1.10:8443/": remote error: tls: unrecognized name
12:42:16 Pod imc-controller-567b4f565b-sdhpp 7674:	Readiness probe failed: Get "https://10.244.1.10:8443/": remote error: tls: unrecognized name
12:42:17 Pod imc-controller-567b4f565b-sdhpp 7674:	Stopping container controller
12:21:35 ReplicaSet imc-controller-567b4f565b 1246:	Created pod: imc-controller-567b4f565b-fhk9b
12:26:16 ReplicaSet imc-controller-567b4f565b 3270:	Created pod: imc-controller-567b4f565b-pkzxd
12:32:06 ReplicaSet imc-controller-567b4f565b 5497:	Created pod: imc-controller-567b4f565b-mphk8
12:38:08 ReplicaSet imc-controller-567b4f565b 7669:	Created pod: imc-controller-567b4f565b-sdhpp
12:42:52 ReplicaSet imc-controller-567b4f565b 9759:	Created pod: imc-controller-567b4f565b-f57zz
12:47:33 ReplicaSet imc-controller-567b4f565b 11851:	Created pod: imc-controller-567b4f565b-chxjr
12:21:35 Deployment imc-controller 1245:	Scaled up replica set imc-controller-567b4f565b to 1
12:26:16 Deployment imc-controller 3269:	Scaled up replica set imc-controller-567b4f565b to 1
12:32:06 Deployment imc-controller 5496:	Scaled up replica set imc-controller-567b4f565b to 1
12:38:08 Deployment imc-controller 7668:	Scaled up replica set imc-controller-567b4f565b to 1
12:42:52 Deployment imc-controller 9758:	Scaled up replica set imc-controller-567b4f565b to 1
12:47:33 Deployment imc-controller 11850:	Scaled up replica set imc-controller-567b4f565b to 1
12:21:36 Pod imc-dispatcher-545bcb44c5-lljq5 1272:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-lljq5 to acto-cluster-3-worker2
12:21:37 Pod imc-dispatcher-545bcb44c5-lljq5 1275:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:21:42 Pod imc-dispatcher-545bcb44c5-lljq5 1275:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 5.796749459s
12:21:42 Pod imc-dispatcher-545bcb44c5-lljq5 1275:	Created container dispatcher
12:21:42 Pod imc-dispatcher-545bcb44c5-lljq5 1275:	Started container dispatcher
12:25:40 Pod imc-dispatcher-545bcb44c5-lljq5 1275:	Stopping container dispatcher
12:32:06 Pod imc-dispatcher-545bcb44c5-pwqbl 5531:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-pwqbl to acto-cluster-3-worker3
12:32:07 Pod imc-dispatcher-545bcb44c5-pwqbl 5533:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:32:09 Pod imc-dispatcher-545bcb44c5-pwqbl 5533:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.7860753s
12:32:09 Pod imc-dispatcher-545bcb44c5-pwqbl 5533:	Created container dispatcher
12:32:10 Pod imc-dispatcher-545bcb44c5-pwqbl 5533:	Started container dispatcher
12:36:10 Pod imc-dispatcher-545bcb44c5-pwqbl 5533:	Stopping container dispatcher
12:26:17 Pod imc-dispatcher-545bcb44c5-rlndn 3295:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-rlndn to acto-cluster-3-worker2
12:26:17 Pod imc-dispatcher-545bcb44c5-rlndn 3298:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:26:17 Pod imc-dispatcher-545bcb44c5-rlndn 3298:	Created container dispatcher
12:26:18 Pod imc-dispatcher-545bcb44c5-rlndn 3298:	Started container dispatcher
12:30:21 Pod imc-dispatcher-545bcb44c5-rlndn 3298:	Stopping container dispatcher
12:42:53 Pod imc-dispatcher-545bcb44c5-t2h5l 9807:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-t2h5l to acto-cluster-3-worker
12:42:53 Pod imc-dispatcher-545bcb44c5-t2h5l 9811:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:42:58 Pod imc-dispatcher-545bcb44c5-t2h5l 9811:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 4.805202656s
12:42:58 Pod imc-dispatcher-545bcb44c5-t2h5l 9811:	Created container dispatcher
12:42:58 Pod imc-dispatcher-545bcb44c5-t2h5l 9811:	Started container dispatcher
12:46:57 Pod imc-dispatcher-545bcb44c5-t2h5l 9811:	Stopping container dispatcher
12:47:34 Pod imc-dispatcher-545bcb44c5-tcczh 11885:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-tcczh to acto-cluster-3-worker
12:47:34 Pod imc-dispatcher-545bcb44c5-tcczh 11890:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:47:34 Pod imc-dispatcher-545bcb44c5-tcczh 11890:	Created container dispatcher
12:47:34 Pod imc-dispatcher-545bcb44c5-tcczh 11890:	Started container dispatcher
12:51:38 Pod imc-dispatcher-545bcb44c5-tcczh 11890:	Stopping container dispatcher
12:38:08 Pod imc-dispatcher-545bcb44c5-ww8mp 7694:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-ww8mp to acto-cluster-3-worker2
12:38:09 Pod imc-dispatcher-545bcb44c5-ww8mp 7698:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:38:09 Pod imc-dispatcher-545bcb44c5-ww8mp 7698:	Created container dispatcher
12:38:09 Pod imc-dispatcher-545bcb44c5-ww8mp 7698:	Started container dispatcher
12:42:16 Pod imc-dispatcher-545bcb44c5-ww8mp 7698:	Stopping container dispatcher
12:42:17 Pod imc-dispatcher-545bcb44c5-ww8mp 7698:	Readiness probe failed: Get "http://10.244.2.13:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:42:17 Pod imc-dispatcher-545bcb44c5-ww8mp 7698:	Liveness probe failed: Get "http://10.244.2.13:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:21:36 ReplicaSet imc-dispatcher-545bcb44c5 1269:	Created pod: imc-dispatcher-545bcb44c5-lljq5
12:26:17 ReplicaSet imc-dispatcher-545bcb44c5 3292:	Created pod: imc-dispatcher-545bcb44c5-rlndn
12:32:06 ReplicaSet imc-dispatcher-545bcb44c5 5528:	Created pod: imc-dispatcher-545bcb44c5-pwqbl
12:38:08 ReplicaSet imc-dispatcher-545bcb44c5 7692:	Created pod: imc-dispatcher-545bcb44c5-ww8mp
12:42:53 ReplicaSet imc-dispatcher-545bcb44c5 9805:	Created pod: imc-dispatcher-545bcb44c5-t2h5l
12:47:34 ReplicaSet imc-dispatcher-545bcb44c5 11883:	Created pod: imc-dispatcher-545bcb44c5-tcczh
12:21:36 Deployment imc-dispatcher 1268:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:26:17 Deployment imc-dispatcher 3291:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:32:06 Deployment imc-dispatcher 5527:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:38:08 Deployment imc-dispatcher 7691:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:42:53 Deployment imc-dispatcher 9803:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:47:34 Deployment imc-dispatcher 11882:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:21:14 Pod knative-operator-668fb586bb-kz7jh 825:	Successfully assigned knative-eventing/knative-operator-668fb586bb-kz7jh to acto-cluster-3-worker3
12:21:14 Pod knative-operator-668fb586bb-kz7jh 830:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:17 Pod knative-operator-668fb586bb-kz7jh 830:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.875819574s
12:21:17 Pod knative-operator-668fb586bb-kz7jh 830:	Created container knative-operator
12:21:17 Pod knative-operator-668fb586bb-kz7jh 830:	Started container knative-operator
12:30:39 Pod knative-operator-668fb586bb-kz7jh 830:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:36:29 Pod knative-operator-668fb586bb-kz7jh 830:	Back-off restarting failed container
12:21:14 ReplicaSet knative-operator-668fb586bb 823:	Created pod: knative-operator-668fb586bb-kz7jh
12:21:04 Pod knative-operator-79bf74d66d-ztvk8 783:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-ztvk8 to acto-cluster-3-worker2
12:21:04 Pod knative-operator-79bf74d66d-ztvk8 785:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:07 Pod knative-operator-79bf74d66d-ztvk8 None:	Cancelling deletion of Pod knative-eventing/knative-operator-79bf74d66d-ztvk8
12:21:07 Pod knative-operator-79bf74d66d-ztvk8 785:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.977942511s
12:21:07 Pod knative-operator-79bf74d66d-ztvk8 785:	Created container knative-operator
12:21:07 Pod knative-operator-79bf74d66d-ztvk8 785:	Started container knative-operator
12:21:18 Pod knative-operator-79bf74d66d-ztvk8 785:	Stopping container knative-operator
12:21:04 ReplicaSet knative-operator-79bf74d66d 779:	Created pod: knative-operator-79bf74d66d-ztvk8
12:21:18 ReplicaSet knative-operator-79bf74d66d 854:	Deleted pod: knative-operator-79bf74d66d-ztvk8
12:21:04 Deployment knative-operator 777:	Scaled up replica set knative-operator-79bf74d66d to 1
12:21:14 Deployment knative-operator 822:	Scaled up replica set knative-operator-668fb586bb to 1
12:21:18 Deployment knative-operator 834:	Scaled down replica set knative-operator-79bf74d66d to 0
12:21:38 Pod mt-broker-controller-56cc5dc5cc-5njwf 1374:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-5njwf to acto-cluster-3-worker3
12:21:38 Pod mt-broker-controller-56cc5dc5cc-5njwf 1376:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:21:43 Pod mt-broker-controller-56cc5dc5cc-5njwf 1376:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 5.164282841s
12:21:43 Pod mt-broker-controller-56cc5dc5cc-5njwf 1376:	Created container mt-broker-controller
12:21:44 Pod mt-broker-controller-56cc5dc5cc-5njwf 1376:	Started container mt-broker-controller
12:25:39 Pod mt-broker-controller-56cc5dc5cc-5njwf 1376:	Stopping container mt-broker-controller
12:47:35 Pod mt-broker-controller-56cc5dc5cc-6sckb 11977:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-6sckb to acto-cluster-3-worker2
12:47:36 Pod mt-broker-controller-56cc5dc5cc-6sckb 11980:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:47:36 Pod mt-broker-controller-56cc5dc5cc-6sckb 11980:	Created container mt-broker-controller
12:47:36 Pod mt-broker-controller-56cc5dc5cc-6sckb 11980:	Started container mt-broker-controller
12:51:37 Pod mt-broker-controller-56cc5dc5cc-6sckb 11980:	Stopping container mt-broker-controller
12:38:10 Pod mt-broker-controller-56cc5dc5cc-7zwvg 7793:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-7zwvg to acto-cluster-3-worker2
12:38:11 Pod mt-broker-controller-56cc5dc5cc-7zwvg 7796:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:38:13 Pod mt-broker-controller-56cc5dc5cc-7zwvg 7796:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.67247599s
12:38:13 Pod mt-broker-controller-56cc5dc5cc-7zwvg 7796:	Created container mt-broker-controller
12:38:13 Pod mt-broker-controller-56cc5dc5cc-7zwvg 7796:	Started container mt-broker-controller
12:42:15 Pod mt-broker-controller-56cc5dc5cc-7zwvg 7796:	Stopping container mt-broker-controller
12:26:18 Pod mt-broker-controller-56cc5dc5cc-cmjz2 3388:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-cmjz2 to acto-cluster-3-worker
12:26:19 Pod mt-broker-controller-56cc5dc5cc-cmjz2 3391:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:26:24 Pod mt-broker-controller-56cc5dc5cc-cmjz2 3391:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 4.491138366s
12:26:24 Pod mt-broker-controller-56cc5dc5cc-cmjz2 3391:	Created container mt-broker-controller
12:26:24 Pod mt-broker-controller-56cc5dc5cc-cmjz2 3391:	Started container mt-broker-controller
12:30:20 Pod mt-broker-controller-56cc5dc5cc-cmjz2 3391:	Stopping container mt-broker-controller
12:32:08 Pod mt-broker-controller-56cc5dc5cc-f49n2 5614:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-f49n2 to acto-cluster-3-worker
12:32:08 Pod mt-broker-controller-56cc5dc5cc-f49n2 5617:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:32:08 Pod mt-broker-controller-56cc5dc5cc-f49n2 5617:	Created container mt-broker-controller
12:32:09 Pod mt-broker-controller-56cc5dc5cc-f49n2 5617:	Started container mt-broker-controller
12:36:09 Pod mt-broker-controller-56cc5dc5cc-f49n2 5617:	Stopping container mt-broker-controller
12:42:54 Pod mt-broker-controller-56cc5dc5cc-q9cs2 9872:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-q9cs2 to acto-cluster-3-worker3
12:42:55 Pod mt-broker-controller-56cc5dc5cc-q9cs2 9875:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:42:55 Pod mt-broker-controller-56cc5dc5cc-q9cs2 9875:	Created container mt-broker-controller
12:42:55 Pod mt-broker-controller-56cc5dc5cc-q9cs2 9875:	Started container mt-broker-controller
12:46:56 Pod mt-broker-controller-56cc5dc5cc-q9cs2 9875:	Stopping container mt-broker-controller
12:21:38 ReplicaSet mt-broker-controller-56cc5dc5cc 1372:	Created pod: mt-broker-controller-56cc5dc5cc-5njwf
12:26:18 ReplicaSet mt-broker-controller-56cc5dc5cc 3383:	Created pod: mt-broker-controller-56cc5dc5cc-cmjz2
12:32:08 ReplicaSet mt-broker-controller-56cc5dc5cc 5612:	Created pod: mt-broker-controller-56cc5dc5cc-f49n2
12:38:10 ReplicaSet mt-broker-controller-56cc5dc5cc 7791:	Created pod: mt-broker-controller-56cc5dc5cc-7zwvg
12:42:54 ReplicaSet mt-broker-controller-56cc5dc5cc 9870:	Created pod: mt-broker-controller-56cc5dc5cc-q9cs2
12:47:35 ReplicaSet mt-broker-controller-56cc5dc5cc 11975:	Created pod: mt-broker-controller-56cc5dc5cc-6sckb
12:21:38 Deployment mt-broker-controller 1371:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:26:18 Deployment mt-broker-controller 3381:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:32:08 Deployment mt-broker-controller 5611:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:38:10 Deployment mt-broker-controller 7790:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:42:54 Deployment mt-broker-controller 9869:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:47:35 Deployment mt-broker-controller 11974:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:32:07 Pod mt-broker-filter-846dc966c5-4dg4p 5568:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-4dg4p to acto-cluster-3-worker3
12:32:08 Pod mt-broker-filter-846dc966c5-4dg4p 5573:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:32:08 Pod mt-broker-filter-846dc966c5-4dg4p 5573:	Created container filter
12:32:08 Pod mt-broker-filter-846dc966c5-4dg4p 5573:	Started container filter
12:36:09 Pod mt-broker-filter-846dc966c5-4dg4p 5573:	Stopping container filter
12:42:54 Pod mt-broker-filter-846dc966c5-94mql 9835:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-94mql to acto-cluster-3-worker
12:42:54 Pod mt-broker-filter-846dc966c5-94mql 9838:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:42:54 Pod mt-broker-filter-846dc966c5-94mql 9838:	Created container filter
12:42:54 Pod mt-broker-filter-846dc966c5-94mql 9838:	Started container filter
12:42:54 Pod mt-broker-filter-846dc966c5-94mql 9838:	Readiness probe failed: Get "http://10.244.3.14:8080/healthz": dial tcp 10.244.3.14:8080: connect: connection refused
12:46:56 Pod mt-broker-filter-846dc966c5-94mql 9838:	Stopping container filter
12:47:35 Pod mt-broker-filter-846dc966c5-9g8c6 11924:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-9g8c6 to acto-cluster-3-worker
12:47:35 Pod mt-broker-filter-846dc966c5-9g8c6 11927:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:47:35 Pod mt-broker-filter-846dc966c5-9g8c6 11927:	Created container filter
12:47:35 Pod mt-broker-filter-846dc966c5-9g8c6 11927:	Started container filter
12:51:37 Pod mt-broker-filter-846dc966c5-9g8c6 11927:	Stopping container filter
12:21:37 Pod mt-broker-filter-846dc966c5-9rn5n 1330:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-9rn5n to acto-cluster-3-worker3
12:21:37 Pod mt-broker-filter-846dc966c5-9rn5n 1333:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:21:40 Pod mt-broker-filter-846dc966c5-9rn5n 1333:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 3.02927475s
12:21:40 Pod mt-broker-filter-846dc966c5-9rn5n 1333:	Created container filter
12:21:41 Pod mt-broker-filter-846dc966c5-9rn5n 1333:	Started container filter
12:25:39 Pod mt-broker-filter-846dc966c5-9rn5n 1333:	Stopping container filter
12:38:09 Pod mt-broker-filter-846dc966c5-lbdpj 7742:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-lbdpj to acto-cluster-3-worker3
12:38:10 Pod mt-broker-filter-846dc966c5-lbdpj 7745:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:38:10 Pod mt-broker-filter-846dc966c5-lbdpj 7745:	Created container filter
12:38:10 Pod mt-broker-filter-846dc966c5-lbdpj 7745:	Started container filter
12:42:15 Pod mt-broker-filter-846dc966c5-lbdpj 7745:	Stopping container filter
12:42:15 Pod mt-broker-filter-846dc966c5-lbdpj 7745:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:42:15 Pod mt-broker-filter-846dc966c5-lbdpj 7745:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:26:18 Pod mt-broker-filter-846dc966c5-w9z6f 3324:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-w9z6f to acto-cluster-3-worker
12:26:18 Pod mt-broker-filter-846dc966c5-w9z6f 3326:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:26:21 Pod mt-broker-filter-846dc966c5-w9z6f 3326:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 2.73263675s
12:26:21 Pod mt-broker-filter-846dc966c5-w9z6f 3326:	Created container filter
12:26:21 Pod mt-broker-filter-846dc966c5-w9z6f 3326:	Started container filter
12:26:21 Pod mt-broker-filter-846dc966c5-w9z6f 3326:	Readiness probe failed: Get "http://10.244.3.5:8080/healthz": dial tcp 10.244.3.5:8080: connect: connection refused
12:30:20 Pod mt-broker-filter-846dc966c5-w9z6f 3326:	Stopping container filter
12:21:37 ReplicaSet mt-broker-filter-846dc966c5 1317:	Created pod: mt-broker-filter-846dc966c5-9rn5n
12:26:18 ReplicaSet mt-broker-filter-846dc966c5 3322:	Created pod: mt-broker-filter-846dc966c5-w9z6f
12:32:07 ReplicaSet mt-broker-filter-846dc966c5 5566:	Created pod: mt-broker-filter-846dc966c5-4dg4p
12:38:09 ReplicaSet mt-broker-filter-846dc966c5 7740:	Created pod: mt-broker-filter-846dc966c5-lbdpj
12:42:54 ReplicaSet mt-broker-filter-846dc966c5 9833:	Created pod: mt-broker-filter-846dc966c5-94mql
12:47:35 ReplicaSet mt-broker-filter-846dc966c5 11922:	Created pod: mt-broker-filter-846dc966c5-9g8c6
12:21:37 Deployment mt-broker-filter 1312:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:26:18 Deployment mt-broker-filter 3321:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:32:07 Deployment mt-broker-filter 5565:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:38:09 Deployment mt-broker-filter 7739:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:42:54 Deployment mt-broker-filter 9832:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:47:35 Deployment mt-broker-filter 11921:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:21:37 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1348:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-6vd5z to acto-cluster-3-worker
12:21:38 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:21:41 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 3.308847454s
12:21:41 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Created container ingress
12:21:41 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Started container ingress
12:21:41 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Readiness probe failed: Get "http://10.244.3.3:8080/healthz": dial tcp 10.244.3.3:8080: connect: connection refused
12:25:39 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Stopping container ingress
12:25:39 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:25:39 Pod mt-broker-ingress-6dbbfff4b9-6vd5z 1351:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:26:18 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3346:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-85w5l to acto-cluster-3-worker2
12:26:19 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:26:22 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.883007551s
12:26:22 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Created container ingress
12:26:22 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Started container ingress
12:30:20 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Stopping container ingress
12:30:20 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:30:20 Pod mt-broker-ingress-6dbbfff4b9-85w5l 3349:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:32:07 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5587:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-m9kb5 to acto-cluster-3-worker2
12:32:08 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5590:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:32:08 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5590:	Created container ingress
12:32:08 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5590:	Started container ingress
12:36:09 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5590:	Stopping container ingress
12:36:09 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5590:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:36:09 Pod mt-broker-ingress-6dbbfff4b9-m9kb5 5590:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:47:35 Pod mt-broker-ingress-6dbbfff4b9-r9lqf 11943:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-r9lqf to acto-cluster-3-worker3
12:47:36 Pod mt-broker-ingress-6dbbfff4b9-r9lqf 11946:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:47:38 Pod mt-broker-ingress-6dbbfff4b9-r9lqf 11946:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.798046397s
12:47:38 Pod mt-broker-ingress-6dbbfff4b9-r9lqf 11946:	Created container ingress
12:47:39 Pod mt-broker-ingress-6dbbfff4b9-r9lqf 11946:	Started container ingress
12:51:37 Pod mt-broker-ingress-6dbbfff4b9-r9lqf 11946:	Stopping container ingress
12:38:10 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7762:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-wqm5x to acto-cluster-3-worker
12:38:10 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7765:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:38:10 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7765:	Created container ingress
12:38:10 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7765:	Started container ingress
12:42:15 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7765:	Stopping container ingress
12:42:16 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7765:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:42:16 Pod mt-broker-ingress-6dbbfff4b9-wqm5x 7765:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:42:54 Pod mt-broker-ingress-6dbbfff4b9-zrjfg 9853:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-zrjfg to acto-cluster-3-worker2
12:42:54 Pod mt-broker-ingress-6dbbfff4b9-zrjfg 9857:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:42:54 Pod mt-broker-ingress-6dbbfff4b9-zrjfg 9857:	Created container ingress
12:42:55 Pod mt-broker-ingress-6dbbfff4b9-zrjfg 9857:	Started container ingress
12:46:56 Pod mt-broker-ingress-6dbbfff4b9-zrjfg 9857:	Stopping container ingress
12:21:37 ReplicaSet mt-broker-ingress-6dbbfff4b9 1346:	Created pod: mt-broker-ingress-6dbbfff4b9-6vd5z
12:26:18 ReplicaSet mt-broker-ingress-6dbbfff4b9 3344:	Created pod: mt-broker-ingress-6dbbfff4b9-85w5l
12:32:07 ReplicaSet mt-broker-ingress-6dbbfff4b9 5585:	Created pod: mt-broker-ingress-6dbbfff4b9-m9kb5
12:38:10 ReplicaSet mt-broker-ingress-6dbbfff4b9 7760:	Created pod: mt-broker-ingress-6dbbfff4b9-wqm5x
12:42:54 ReplicaSet mt-broker-ingress-6dbbfff4b9 9851:	Created pod: mt-broker-ingress-6dbbfff4b9-zrjfg
12:47:35 ReplicaSet mt-broker-ingress-6dbbfff4b9 11941:	Created pod: mt-broker-ingress-6dbbfff4b9-r9lqf
12:21:37 Deployment mt-broker-ingress 1345:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:26:18 Deployment mt-broker-ingress 3343:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:32:07 Deployment mt-broker-ingress 5584:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:38:10 Deployment mt-broker-ingress 7759:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:42:54 Deployment mt-broker-ingress 9850:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:47:35 Deployment mt-broker-ingress 11940:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:42:55 Pod storage-version-migration-eventing-eventing-1.6.0--1-29cq7 9901:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-29cq7 to acto-cluster-3-worker2
12:42:56 Pod storage-version-migration-eventing-eventing-1.6.0--1-29cq7 9904:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:42:56 Pod storage-version-migration-eventing-eventing-1.6.0--1-29cq7 9904:	Created container migrate
12:42:56 Pod storage-version-migration-eventing-eventing-1.6.0--1-29cq7 9904:	Started container migrate
12:21:39 Pod storage-version-migration-eventing-eventing-1.6.0--1-4zp5m 1402:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-4zp5m to acto-cluster-3-worker3
12:21:39 Pod storage-version-migration-eventing-eventing-1.6.0--1-4zp5m 1404:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:21:46 Pod storage-version-migration-eventing-eventing-1.6.0--1-4zp5m 1404:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 6.860202679s
12:21:46 Pod storage-version-migration-eventing-eventing-1.6.0--1-4zp5m 1404:	Created container migrate
12:21:46 Pod storage-version-migration-eventing-eventing-1.6.0--1-4zp5m 1404:	Started container migrate
12:32:09 Pod storage-version-migration-eventing-eventing-1.6.0--1-6wbxk 5644:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-6wbxk to acto-cluster-3-worker2
12:32:09 Pod storage-version-migration-eventing-eventing-1.6.0--1-6wbxk 5646:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:32:09 Pod storage-version-migration-eventing-eventing-1.6.0--1-6wbxk 5646:	Created container migrate
12:32:10 Pod storage-version-migration-eventing-eventing-1.6.0--1-6wbxk 5646:	Started container migrate
12:26:19 Pod storage-version-migration-eventing-eventing-1.6.0--1-78nxj 3418:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-78nxj to acto-cluster-3-worker2
12:26:20 Pod storage-version-migration-eventing-eventing-1.6.0--1-78nxj 3421:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:26:24 Pod storage-version-migration-eventing-eventing-1.6.0--1-78nxj 3421:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 4.35543636s
12:26:24 Pod storage-version-migration-eventing-eventing-1.6.0--1-78nxj 3421:	Created container migrate
12:26:24 Pod storage-version-migration-eventing-eventing-1.6.0--1-78nxj 3421:	Started container migrate
12:47:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-ckbsh 12003:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-ckbsh to acto-cluster-3-worker3
12:47:37 Pod storage-version-migration-eventing-eventing-1.6.0--1-ckbsh 12005:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:47:37 Pod storage-version-migration-eventing-eventing-1.6.0--1-ckbsh 12005:	Created container migrate
12:47:37 Pod storage-version-migration-eventing-eventing-1.6.0--1-ckbsh 12005:	Started container migrate
12:38:11 Pod storage-version-migration-eventing-eventing-1.6.0--1-ljcg8 7841:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-ljcg8 to acto-cluster-3-worker2
12:38:11 Pod storage-version-migration-eventing-eventing-1.6.0--1-ljcg8 7844:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:38:11 Pod storage-version-migration-eventing-eventing-1.6.0--1-ljcg8 7844:	Created container migrate
12:38:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-ljcg8 7844:	Started container migrate
12:21:39 Job storage-version-migration-eventing-eventing-1.6.0 1400:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-4zp5m
12:21:52 Job storage-version-migration-eventing-eventing-1.6.0 1490:	Job completed
12:26:19 Job storage-version-migration-eventing-eventing-1.6.0 3417:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-78nxj
12:26:30 Job storage-version-migration-eventing-eventing-1.6.0 3422:	Job completed
12:32:09 Job storage-version-migration-eventing-eventing-1.6.0 5643:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-6wbxk
12:32:15 Job storage-version-migration-eventing-eventing-1.6.0 5649:	Job completed
12:38:11 Job storage-version-migration-eventing-eventing-1.6.0 7838:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-ljcg8
12:38:17 Job storage-version-migration-eventing-eventing-1.6.0 7846:	Job completed
12:42:55 Job storage-version-migration-eventing-eventing-1.6.0 9900:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-29cq7
12:43:02 Job storage-version-migration-eventing-eventing-1.6.0 9905:	Job completed
12:47:36 Job storage-version-migration-eventing-eventing-1.6.0 12000:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-ckbsh
12:47:42 Job storage-version-migration-eventing-eventing-1.6.0 12007:	Job completed
12:21:17 KnativeEventing test-cluster 850:	Updated "test-cluster" finalizers
12:25:57 KnativeEventing test-cluster 2679:	Updated "test-cluster" finalizers
12:25:59 KnativeEventing test-cluster 2997:	Updated "test-cluster" finalizers
12:31:49 KnativeEventing test-cluster 5215:	Updated "test-cluster" finalizers
12:37:51 KnativeEventing test-cluster 7404:	Updated "test-cluster" finalizers
12:42:34 KnativeEventing test-cluster 9474:	Updated "test-cluster" finalizers
12:47:15 KnativeEventing test-cluster 11547:	Updated "test-cluster" finalizers
