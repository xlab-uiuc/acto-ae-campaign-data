12:21:49 HorizontalPodAutoscaler broker-filter-hpa 1481:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:49 HorizontalPodAutoscaler broker-filter-hpa 1481:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:29 HorizontalPodAutoscaler broker-filter-hpa 3375:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:29 HorizontalPodAutoscaler broker-filter-hpa 3375:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:19 HorizontalPodAutoscaler broker-filter-hpa 5597:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:19 HorizontalPodAutoscaler broker-filter-hpa 5597:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:21 HorizontalPodAutoscaler broker-filter-hpa 7818:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:21 HorizontalPodAutoscaler broker-filter-hpa 7818:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:45:34 HorizontalPodAutoscaler broker-filter-hpa 10144:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:45:34 HorizontalPodAutoscaler broker-filter-hpa 10144:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:05 HorizontalPodAutoscaler broker-filter-hpa 12365:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:05 HorizontalPodAutoscaler broker-filter-hpa 12365:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:48 HorizontalPodAutoscaler broker-ingress-hpa 1469:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:48 HorizontalPodAutoscaler broker-ingress-hpa 1469:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:29 HorizontalPodAutoscaler broker-ingress-hpa 3367:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:29 HorizontalPodAutoscaler broker-ingress-hpa 3367:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:19 HorizontalPodAutoscaler broker-ingress-hpa 5592:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:19 HorizontalPodAutoscaler broker-ingress-hpa 5592:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:21 HorizontalPodAutoscaler broker-ingress-hpa 7815:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:21 HorizontalPodAutoscaler broker-ingress-hpa 7815:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:45:34 HorizontalPodAutoscaler broker-ingress-hpa 10142:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:45:34 HorizontalPodAutoscaler broker-ingress-hpa 10142:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:05 HorizontalPodAutoscaler broker-ingress-hpa 12361:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:05 HorizontalPodAutoscaler broker-ingress-hpa 12361:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:28 Pod eventing-controller-6b5498ffc8-z4qgt 1159:	Successfully assigned knative-eventing/eventing-controller-6b5498ffc8-z4qgt to acto-cluster-6-worker
12:21:28 Pod eventing-controller-6b5498ffc8-z4qgt 1162:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:21:31 Pod eventing-controller-6b5498ffc8-z4qgt 1162:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.737195105s
12:21:31 Pod eventing-controller-6b5498ffc8-z4qgt 1162:	Created container eventing-controller
12:21:31 Pod eventing-controller-6b5498ffc8-z4qgt 1162:	Started container eventing-controller
12:25:39 Pod eventing-controller-6b5498ffc8-z4qgt 1162:	Stopping container eventing-controller
12:21:28 ReplicaSet eventing-controller-6b5498ffc8 1157:	Created pod: eventing-controller-6b5498ffc8-z4qgt
12:31:58 Pod eventing-controller-6c78bb8c7f-ldjsz 5348:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-ldjsz to acto-cluster-6-worker2
12:31:59 Pod eventing-controller-6c78bb8c7f-ldjsz 5350:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:31:59 Pod eventing-controller-6c78bb8c7f-ldjsz 5350:	Created container eventing-controller
12:31:59 Pod eventing-controller-6c78bb8c7f-ldjsz 5350:	Started container eventing-controller
12:36:10 Pod eventing-controller-6c78bb8c7f-ldjsz 5350:	Stopping container eventing-controller
12:31:58 Pod eventing-controller-6c78bb8c7f-mxlxm 5351:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-mxlxm to acto-cluster-6-worker
12:31:59 Pod eventing-controller-6c78bb8c7f-mxlxm 5355:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:31:59 Pod eventing-controller-6c78bb8c7f-mxlxm 5355:	Created container eventing-controller
12:31:59 Pod eventing-controller-6c78bb8c7f-mxlxm 5355:	Started container eventing-controller
12:36:10 Pod eventing-controller-6c78bb8c7f-mxlxm 5355:	Stopping container eventing-controller
12:38:00 Pod eventing-controller-6c78bb8c7f-w2hmv 7573:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-w2hmv to acto-cluster-6-worker2
12:38:00 Pod eventing-controller-6c78bb8c7f-w2hmv 7575:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:38:00 Pod eventing-controller-6c78bb8c7f-w2hmv 7575:	Created container eventing-controller
12:38:00 Pod eventing-controller-6c78bb8c7f-w2hmv 7575:	Started container eventing-controller
12:42:15 Pod eventing-controller-6c78bb8c7f-w2hmv 7575:	Stopping container eventing-controller
12:31:58 ReplicaSet eventing-controller-6c78bb8c7f 5345:	Created pod: eventing-controller-6c78bb8c7f-ldjsz
12:31:58 ReplicaSet eventing-controller-6c78bb8c7f 5345:	Created pod: eventing-controller-6c78bb8c7f-mxlxm
12:38:00 ReplicaSet eventing-controller-6c78bb8c7f 7570:	Created pod: eventing-controller-6c78bb8c7f-w2hmv
12:51:44 Pod eventing-controller-7688b5fb55-htvl4 12118:	Successfully assigned knative-eventing/eventing-controller-7688b5fb55-htvl4 to acto-cluster-6-worker2
12:51:44 Pod eventing-controller-7688b5fb55-htvl4 12120:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:51:44 Pod eventing-controller-7688b5fb55-htvl4 12120:	Created container eventing-controller
12:51:45 Pod eventing-controller-7688b5fb55-htvl4 12120:	Started container eventing-controller
12:51:44 ReplicaSet eventing-controller-7688b5fb55 12115:	Created pod: eventing-controller-7688b5fb55-htvl4
12:45:13 Pod eventing-controller-779fbf8f65-lbfxb 9896:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-lbfxb to acto-cluster-6-worker
12:45:14 Pod eventing-controller-779fbf8f65-lbfxb 9899:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:45:14 Pod eventing-controller-779fbf8f65-lbfxb 9899:	Created container eventing-controller
12:45:14 Pod eventing-controller-779fbf8f65-lbfxb 9899:	Started container eventing-controller
12:49:25 Pod eventing-controller-779fbf8f65-lbfxb 9899:	Stopping container eventing-controller
12:45:13 ReplicaSet eventing-controller-779fbf8f65 9893:	Created pod: eventing-controller-779fbf8f65-lbfxb
12:26:08 Pod eventing-controller-86d49cf697-nwcc8 3161:	Successfully assigned knative-eventing/eventing-controller-86d49cf697-nwcc8 to acto-cluster-6-worker2
12:26:09 Pod eventing-controller-86d49cf697-nwcc8 3164:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:26:12 Pod eventing-controller-86d49cf697-nwcc8 3164:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.760282446s
12:26:12 Pod eventing-controller-86d49cf697-nwcc8 3164:	Created container eventing-controller
12:26:12 Pod eventing-controller-86d49cf697-nwcc8 3164:	Started container eventing-controller
12:30:20 Pod eventing-controller-86d49cf697-nwcc8 3164:	Stopping container eventing-controller
12:26:08 ReplicaSet eventing-controller-86d49cf697 3158:	Created pod: eventing-controller-86d49cf697-nwcc8
12:21:28 Deployment eventing-controller 1156:	Scaled up replica set eventing-controller-6b5498ffc8 to 1
12:26:08 Deployment eventing-controller 3157:	Scaled up replica set eventing-controller-86d49cf697 to 1
12:31:58 Deployment eventing-controller 5344:	Scaled up replica set eventing-controller-6c78bb8c7f to 2
12:38:00 Deployment eventing-controller 7569:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:45:13 Deployment eventing-controller 9892:	Scaled up replica set eventing-controller-779fbf8f65 to 1
12:51:44 Deployment eventing-controller 12114:	Scaled up replica set eventing-controller-7688b5fb55 to 1
12:51:45 Pod eventing-webhook-5755489569-2kntc 12145:	Successfully assigned knative-eventing/eventing-webhook-5755489569-2kntc to acto-cluster-6-worker
12:51:45 Pod eventing-webhook-5755489569-2kntc 12149:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:51:45 Pod eventing-webhook-5755489569-2kntc 12149:	Created container eventing-webhook
12:51:46 Pod eventing-webhook-5755489569-2kntc 12149:	Started container eventing-webhook
12:51:46 Pod eventing-webhook-5755489569-2kntc 12149:	Readiness probe failed: Get "https://10.244.3.17:8443/": dial tcp 10.244.3.17:8443: connect: connection refused
12:51:47 Pod eventing-webhook-5755489569-2kntc 12149:	Readiness probe failed: Get "https://10.244.3.17:8443/": remote error: tls: unrecognized name
12:38:00 Pod eventing-webhook-5755489569-585d4 7598:	Successfully assigned knative-eventing/eventing-webhook-5755489569-585d4 to acto-cluster-6-worker
12:38:01 Pod eventing-webhook-5755489569-585d4 7601:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:38:01 Pod eventing-webhook-5755489569-585d4 7601:	Created container eventing-webhook
12:38:02 Pod eventing-webhook-5755489569-585d4 7601:	Started container eventing-webhook
12:38:02 Pod eventing-webhook-5755489569-585d4 7601:	Readiness probe failed: Get "https://10.244.3.12:8443/": dial tcp 10.244.3.12:8443: connect: connection refused
12:38:02 Pod eventing-webhook-5755489569-585d4 7601:	Readiness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
12:42:14 Pod eventing-webhook-5755489569-585d4 7601:	Liveness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
12:42:14 Pod eventing-webhook-5755489569-585d4 7601:	Stopping container eventing-webhook
12:26:09 Pod eventing-webhook-5755489569-kqp67 3185:	Successfully assigned knative-eventing/eventing-webhook-5755489569-kqp67 to acto-cluster-6-worker
12:26:10 Pod eventing-webhook-5755489569-kqp67 3188:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:26:13 Pod eventing-webhook-5755489569-kqp67 3188:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.685159127s
12:26:13 Pod eventing-webhook-5755489569-kqp67 3188:	Created container eventing-webhook
12:26:13 Pod eventing-webhook-5755489569-kqp67 3188:	Started container eventing-webhook
12:26:13 Pod eventing-webhook-5755489569-kqp67 3188:	Readiness probe failed: Get "https://10.244.3.7:8443/": dial tcp 10.244.3.7:8443: connect: connection refused
12:30:19 Pod eventing-webhook-5755489569-kqp67 3188:	Liveness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
12:30:19 Pod eventing-webhook-5755489569-kqp67 3188:	Readiness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
12:30:19 Pod eventing-webhook-5755489569-kqp67 3188:	Stopping container eventing-webhook
12:21:28 Pod eventing-webhook-5755489569-p97kf 1186:	Successfully assigned knative-eventing/eventing-webhook-5755489569-p97kf to acto-cluster-6-worker2
12:21:29 Pod eventing-webhook-5755489569-p97kf 1188:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:21:33 Pod eventing-webhook-5755489569-p97kf 1188:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 3.225723572s
12:21:33 Pod eventing-webhook-5755489569-p97kf 1188:	Created container eventing-webhook
12:21:33 Pod eventing-webhook-5755489569-p97kf 1188:	Started container eventing-webhook
12:21:33 Pod eventing-webhook-5755489569-p97kf 1188:	Readiness probe failed: Get "https://10.244.2.3:8443/": dial tcp 10.244.2.3:8443: connect: connection refused
12:25:38 Pod eventing-webhook-5755489569-p97kf 1188:	Readiness probe failed: Get "https://10.244.2.3:8443/": remote error: tls: unrecognized name
12:25:38 Pod eventing-webhook-5755489569-p97kf 1188:	Liveness probe failed: Get "https://10.244.2.3:8443/": remote error: tls: unrecognized name
12:25:39 Pod eventing-webhook-5755489569-p97kf 1188:	Stopping container eventing-webhook
12:45:14 Pod eventing-webhook-5755489569-qpc5f 9921:	Successfully assigned knative-eventing/eventing-webhook-5755489569-qpc5f to acto-cluster-6-worker2
12:45:15 Pod eventing-webhook-5755489569-qpc5f 9925:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:45:15 Pod eventing-webhook-5755489569-qpc5f 9925:	Created container eventing-webhook
12:45:16 Pod eventing-webhook-5755489569-qpc5f 9925:	Started container eventing-webhook
12:45:16 Pod eventing-webhook-5755489569-qpc5f 9925:	Readiness probe failed: Get "https://10.244.2.17:8443/": remote error: tls: unrecognized name
12:49:24 Pod eventing-webhook-5755489569-qpc5f 9925:	Liveness probe failed: Get "https://10.244.2.17:8443/": remote error: tls: unrecognized name
12:49:25 Pod eventing-webhook-5755489569-qpc5f 9925:	Stopping container eventing-webhook
12:31:59 Pod eventing-webhook-5755489569-vn874 5381:	Successfully assigned knative-eventing/eventing-webhook-5755489569-vn874 to acto-cluster-6-worker2
12:32:00 Pod eventing-webhook-5755489569-vn874 5386:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:32:00 Pod eventing-webhook-5755489569-vn874 5386:	Created container eventing-webhook
12:32:01 Pod eventing-webhook-5755489569-vn874 5386:	Started container eventing-webhook
12:32:01 Pod eventing-webhook-5755489569-vn874 5386:	Readiness probe failed: Get "https://10.244.2.11:8443/": remote error: tls: unrecognized name
12:36:09 Pod eventing-webhook-5755489569-vn874 5386:	Liveness probe failed: Get "https://10.244.2.11:8443/": remote error: tls: unrecognized name
12:36:10 Pod eventing-webhook-5755489569-vn874 5386:	Stopping container eventing-webhook
12:21:28 ReplicaSet eventing-webhook-5755489569 1184:	Created pod: eventing-webhook-5755489569-p97kf
12:26:09 ReplicaSet eventing-webhook-5755489569 3183:	Created pod: eventing-webhook-5755489569-kqp67
12:31:59 ReplicaSet eventing-webhook-5755489569 5380:	Created pod: eventing-webhook-5755489569-vn874
12:38:00 ReplicaSet eventing-webhook-5755489569 7596:	Created pod: eventing-webhook-5755489569-585d4
12:45:14 ReplicaSet eventing-webhook-5755489569 9919:	Created pod: eventing-webhook-5755489569-qpc5f
12:51:45 ReplicaSet eventing-webhook-5755489569 12143:	Created pod: eventing-webhook-5755489569-2kntc
12:21:28 PodDisruptionBudget eventing-webhook 1178:	No matching pods found
12:21:28 Deployment eventing-webhook 1183:	Scaled up replica set eventing-webhook-5755489569 to 1
12:21:43 HorizontalPodAutoscaler eventing-webhook 1227:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:43 HorizontalPodAutoscaler eventing-webhook 1227:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:25:39 PodDisruptionBudget eventing-webhook 1429:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:26:09 PodDisruptionBudget eventing-webhook 3177:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:26:09 Deployment eventing-webhook 3182:	Scaled up replica set eventing-webhook-5755489569 to 1
12:26:09 PodDisruptionBudget eventing-webhook 3179:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-p97kf"
12:26:24 HorizontalPodAutoscaler eventing-webhook 3175:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:24 HorizontalPodAutoscaler eventing-webhook 3175:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:31:59 PodDisruptionBudget eventing-webhook 5371:	No matching pods found
12:31:59 Deployment eventing-webhook 5379:	Scaled up replica set eventing-webhook-5755489569 to 1
12:32:14 HorizontalPodAutoscaler eventing-webhook 5370:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:14 HorizontalPodAutoscaler eventing-webhook 5370:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:36:10 PodDisruptionBudget eventing-webhook 5837:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:38:00 PodDisruptionBudget eventing-webhook 7589:	No matching pods found
12:38:00 Deployment eventing-webhook 7595:	Scaled up replica set eventing-webhook-5755489569 to 1
12:38:15 HorizontalPodAutoscaler eventing-webhook 7588:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:15 HorizontalPodAutoscaler eventing-webhook 7588:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:14 PodDisruptionBudget eventing-webhook 8050:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:45:14 PodDisruptionBudget eventing-webhook 9911:	No matching pods found
12:45:14 Deployment eventing-webhook 9918:	Scaled up replica set eventing-webhook-5755489569 to 1
12:45:29 HorizontalPodAutoscaler eventing-webhook 9910:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:45:29 HorizontalPodAutoscaler eventing-webhook 9910:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:49:25 PodDisruptionBudget eventing-webhook 10371:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:51:44 PodDisruptionBudget eventing-webhook 12136:	No matching pods found
12:51:45 Deployment eventing-webhook 12141:	Scaled up replica set eventing-webhook-5755489569 to 1
12:51:59 HorizontalPodAutoscaler eventing-webhook 12134:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:51:59 HorizontalPodAutoscaler eventing-webhook 12134:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:31 Pod imc-controller-567b4f565b-cm4qd 1238:	Successfully assigned knative-eventing/imc-controller-567b4f565b-cm4qd to acto-cluster-6-worker2
12:21:31 Pod imc-controller-567b4f565b-cm4qd 1240:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:21:35 Pod imc-controller-567b4f565b-cm4qd 1240:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 3.977900008s
12:21:35 Pod imc-controller-567b4f565b-cm4qd 1240:	Created container controller
12:21:36 Pod imc-controller-567b4f565b-cm4qd 1240:	Started container controller
12:25:36 Pod imc-controller-567b4f565b-cm4qd 1240:	Liveness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:25:36 Pod imc-controller-567b4f565b-cm4qd 1240:	Readiness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:25:36 Pod imc-controller-567b4f565b-cm4qd 1240:	Stopping container controller
12:45:17 Pod imc-controller-567b4f565b-hzqdm 10002:	Successfully assigned knative-eventing/imc-controller-567b4f565b-hzqdm to acto-cluster-6-worker
12:45:17 Pod imc-controller-567b4f565b-hzqdm 10006:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:45:17 Pod imc-controller-567b4f565b-hzqdm 10006:	Created container controller
12:45:17 Pod imc-controller-567b4f565b-hzqdm 10006:	Started container controller
12:49:22 Pod imc-controller-567b4f565b-hzqdm 10006:	Liveness probe failed: Get "https://10.244.3.16:8443/": remote error: tls: unrecognized name
12:49:22 Pod imc-controller-567b4f565b-hzqdm 10006:	Readiness probe failed: Get "https://10.244.3.16:8443/": remote error: tls: unrecognized name
12:49:22 Pod imc-controller-567b4f565b-hzqdm 10006:	Stopping container controller
12:32:02 Pod imc-controller-567b4f565b-nbmth 5467:	Successfully assigned knative-eventing/imc-controller-567b4f565b-nbmth to acto-cluster-6-worker2
12:32:02 Pod imc-controller-567b4f565b-nbmth 5470:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:32:02 Pod imc-controller-567b4f565b-nbmth 5470:	Created container controller
12:32:03 Pod imc-controller-567b4f565b-nbmth 5470:	Started container controller
12:36:07 Pod imc-controller-567b4f565b-nbmth 5470:	Readiness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:36:07 Pod imc-controller-567b4f565b-nbmth 5470:	Liveness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:36:07 Pod imc-controller-567b4f565b-nbmth 5470:	Stopping container controller
12:26:12 Pod imc-controller-567b4f565b-rxfbq 3224:	Successfully assigned knative-eventing/imc-controller-567b4f565b-rxfbq to acto-cluster-6-worker
12:26:12 Pod imc-controller-567b4f565b-rxfbq 3227:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:26:15 Pod imc-controller-567b4f565b-rxfbq 3227:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.967233563s
12:26:15 Pod imc-controller-567b4f565b-rxfbq 3227:	Created container controller
12:26:15 Pod imc-controller-567b4f565b-rxfbq 3227:	Started container controller
12:30:17 Pod imc-controller-567b4f565b-rxfbq 3227:	Readiness probe failed: Get "https://10.244.3.8:8443/": remote error: tls: unrecognized name
12:30:17 Pod imc-controller-567b4f565b-rxfbq 3227:	Liveness probe failed: Get "https://10.244.3.8:8443/": remote error: tls: unrecognized name
12:30:17 Pod imc-controller-567b4f565b-rxfbq 3227:	Stopping container controller
12:38:03 Pod imc-controller-567b4f565b-sdz7w 7682:	Successfully assigned knative-eventing/imc-controller-567b4f565b-sdz7w to acto-cluster-6-worker
12:38:04 Pod imc-controller-567b4f565b-sdz7w 7685:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:38:04 Pod imc-controller-567b4f565b-sdz7w 7685:	Created container controller
12:38:04 Pod imc-controller-567b4f565b-sdz7w 7685:	Started container controller
12:42:11 Pod imc-controller-567b4f565b-sdz7w 7685:	Liveness probe failed: Get "https://10.244.3.13:8443/": remote error: tls: unrecognized name
12:42:11 Pod imc-controller-567b4f565b-sdz7w 7685:	Readiness probe failed: Get "https://10.244.3.13:8443/": remote error: tls: unrecognized name
12:42:12 Pod imc-controller-567b4f565b-sdz7w 7685:	Stopping container controller
12:51:47 Pod imc-controller-567b4f565b-tj6fm 12227:	Successfully assigned knative-eventing/imc-controller-567b4f565b-tj6fm to acto-cluster-6-worker
12:51:48 Pod imc-controller-567b4f565b-tj6fm 12230:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:51:48 Pod imc-controller-567b4f565b-tj6fm 12230:	Created container controller
12:51:48 Pod imc-controller-567b4f565b-tj6fm 12230:	Started container controller
12:21:31 ReplicaSet imc-controller-567b4f565b 1235:	Created pod: imc-controller-567b4f565b-cm4qd
12:26:12 ReplicaSet imc-controller-567b4f565b 3222:	Created pod: imc-controller-567b4f565b-rxfbq
12:32:02 ReplicaSet imc-controller-567b4f565b 5465:	Created pod: imc-controller-567b4f565b-nbmth
12:38:03 ReplicaSet imc-controller-567b4f565b 7680:	Created pod: imc-controller-567b4f565b-sdz7w
12:45:17 ReplicaSet imc-controller-567b4f565b 10000:	Created pod: imc-controller-567b4f565b-hzqdm
12:51:47 ReplicaSet imc-controller-567b4f565b 12225:	Created pod: imc-controller-567b4f565b-tj6fm
12:21:31 Deployment imc-controller 1234:	Scaled up replica set imc-controller-567b4f565b to 1
12:26:12 Deployment imc-controller 3221:	Scaled up replica set imc-controller-567b4f565b to 1
12:32:02 Deployment imc-controller 5464:	Scaled up replica set imc-controller-567b4f565b to 1
12:38:03 Deployment imc-controller 7679:	Scaled up replica set imc-controller-567b4f565b to 1
12:45:17 Deployment imc-controller 9999:	Scaled up replica set imc-controller-567b4f565b to 1
12:51:47 Deployment imc-controller 12224:	Scaled up replica set imc-controller-567b4f565b to 1
12:21:31 Pod imc-dispatcher-545bcb44c5-5mglq 1263:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-5mglq to acto-cluster-6-worker
12:21:32 Pod imc-dispatcher-545bcb44c5-5mglq 1267:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:21:35 Pod imc-dispatcher-545bcb44c5-5mglq 1267:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.939796913s
12:21:35 Pod imc-dispatcher-545bcb44c5-5mglq 1267:	Created container dispatcher
12:21:35 Pod imc-dispatcher-545bcb44c5-5mglq 1267:	Started container dispatcher
12:25:36 Pod imc-dispatcher-545bcb44c5-5mglq 1267:	Stopping container dispatcher
12:51:48 Pod imc-dispatcher-545bcb44c5-g6mdl 12259:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-g6mdl to acto-cluster-6-worker3
12:51:48 Pod imc-dispatcher-545bcb44c5-g6mdl 12261:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:51:48 Pod imc-dispatcher-545bcb44c5-g6mdl 12261:	Created container dispatcher
12:51:49 Pod imc-dispatcher-545bcb44c5-g6mdl 12261:	Started container dispatcher
12:38:04 Pod imc-dispatcher-545bcb44c5-kmkn9 7710:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-kmkn9 to acto-cluster-6-worker3
12:38:04 Pod imc-dispatcher-545bcb44c5-kmkn9 7714:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:38:04 Pod imc-dispatcher-545bcb44c5-kmkn9 7714:	Created container dispatcher
12:38:05 Pod imc-dispatcher-545bcb44c5-kmkn9 7714:	Started container dispatcher
12:42:11 Pod imc-dispatcher-545bcb44c5-kmkn9 7714:	Stopping container dispatcher
12:45:17 Pod imc-dispatcher-545bcb44c5-lqr5k 10033:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-lqr5k to acto-cluster-6-worker2
12:45:18 Pod imc-dispatcher-545bcb44c5-lqr5k 10037:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:45:18 Pod imc-dispatcher-545bcb44c5-lqr5k 10037:	Created container dispatcher
12:45:18 Pod imc-dispatcher-545bcb44c5-lqr5k 10037:	Started container dispatcher
12:49:22 Pod imc-dispatcher-545bcb44c5-lqr5k 10037:	Stopping container dispatcher
12:32:02 Pod imc-dispatcher-545bcb44c5-nqzh5 5496:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-nqzh5 to acto-cluster-6-worker3
12:32:03 Pod imc-dispatcher-545bcb44c5-nqzh5 5500:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:32:06 Pod imc-dispatcher-545bcb44c5-nqzh5 5500:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.870937077s
12:32:06 Pod imc-dispatcher-545bcb44c5-nqzh5 5500:	Created container dispatcher
12:32:06 Pod imc-dispatcher-545bcb44c5-nqzh5 5500:	Started container dispatcher
12:36:07 Pod imc-dispatcher-545bcb44c5-nqzh5 5500:	Stopping container dispatcher
12:26:12 Pod imc-dispatcher-545bcb44c5-wpv9s 3274:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-wpv9s to acto-cluster-6-worker2
12:26:13 Pod imc-dispatcher-545bcb44c5-wpv9s 3277:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:26:16 Pod imc-dispatcher-545bcb44c5-wpv9s 3277:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.825632311s
12:26:16 Pod imc-dispatcher-545bcb44c5-wpv9s 3277:	Created container dispatcher
12:26:16 Pod imc-dispatcher-545bcb44c5-wpv9s 3277:	Started container dispatcher
12:30:16 Pod imc-dispatcher-545bcb44c5-wpv9s 3277:	Stopping container dispatcher
12:21:31 ReplicaSet imc-dispatcher-545bcb44c5 1261:	Created pod: imc-dispatcher-545bcb44c5-5mglq
12:26:12 ReplicaSet imc-dispatcher-545bcb44c5 3271:	Created pod: imc-dispatcher-545bcb44c5-wpv9s
12:32:02 ReplicaSet imc-dispatcher-545bcb44c5 5494:	Created pod: imc-dispatcher-545bcb44c5-nqzh5
12:38:04 ReplicaSet imc-dispatcher-545bcb44c5 7707:	Created pod: imc-dispatcher-545bcb44c5-kmkn9
12:45:17 ReplicaSet imc-dispatcher-545bcb44c5 10030:	Created pod: imc-dispatcher-545bcb44c5-lqr5k
12:51:48 ReplicaSet imc-dispatcher-545bcb44c5 12256:	Created pod: imc-dispatcher-545bcb44c5-g6mdl
12:21:31 Deployment imc-dispatcher 1260:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:26:12 Deployment imc-dispatcher 3270:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:32:02 Deployment imc-dispatcher 5493:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:38:04 Deployment imc-dispatcher 7706:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:45:17 Deployment imc-dispatcher 10029:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:51:48 Deployment imc-dispatcher 12255:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:21:10 Pod knative-operator-668fb586bb-vssrs 814:	Successfully assigned knative-eventing/knative-operator-668fb586bb-vssrs to acto-cluster-6-worker
12:21:10 Pod knative-operator-668fb586bb-vssrs 819:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:13 Pod knative-operator-668fb586bb-vssrs 819:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.961715833s
12:21:13 Pod knative-operator-668fb586bb-vssrs 819:	Created container knative-operator
12:21:13 Pod knative-operator-668fb586bb-vssrs 819:	Started container knative-operator
12:30:35 Pod knative-operator-668fb586bb-vssrs 819:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:36:25 Pod knative-operator-668fb586bb-vssrs 819:	Back-off restarting failed container
12:21:10 ReplicaSet knative-operator-668fb586bb 813:	Created pod: knative-operator-668fb586bb-vssrs
12:20:59 Pod knative-operator-79bf74d66d-gwn2h 772:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-gwn2h to acto-cluster-6-worker2
12:21:00 Pod knative-operator-79bf74d66d-gwn2h 774:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:03 Pod knative-operator-79bf74d66d-gwn2h 774:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.926924989s
12:21:03 Pod knative-operator-79bf74d66d-gwn2h 774:	Created container knative-operator
12:21:03 Pod knative-operator-79bf74d66d-gwn2h 774:	Started container knative-operator
12:21:14 Pod knative-operator-79bf74d66d-gwn2h 774:	Stopping container knative-operator
12:20:59 ReplicaSet knative-operator-79bf74d66d 768:	Created pod: knative-operator-79bf74d66d-gwn2h
12:21:14 ReplicaSet knative-operator-79bf74d66d 881:	Deleted pod: knative-operator-79bf74d66d-gwn2h
12:20:59 Deployment knative-operator 767:	Scaled up replica set knative-operator-79bf74d66d to 1
12:21:09 Deployment knative-operator 812:	Scaled up replica set knative-operator-668fb586bb to 1
12:21:14 Deployment knative-operator 827:	Scaled down replica set knative-operator-79bf74d66d to 0
12:38:05 Pod mt-broker-controller-56cc5dc5cc-9h6d4 7805:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-9h6d4 to acto-cluster-6-worker2
12:38:06 Pod mt-broker-controller-56cc5dc5cc-9h6d4 7808:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:38:09 Pod mt-broker-controller-56cc5dc5cc-9h6d4 7808:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.728602285s
12:38:09 Pod mt-broker-controller-56cc5dc5cc-9h6d4 7808:	Created container mt-broker-controller
12:38:09 Pod mt-broker-controller-56cc5dc5cc-9h6d4 7808:	Started container mt-broker-controller
12:42:10 Pod mt-broker-controller-56cc5dc5cc-9h6d4 7808:	Stopping container mt-broker-controller
12:51:50 Pod mt-broker-controller-56cc5dc5cc-dz6kk 12342:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-dz6kk to acto-cluster-6-worker
12:51:50 Pod mt-broker-controller-56cc5dc5cc-dz6kk 12345:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:51:50 Pod mt-broker-controller-56cc5dc5cc-dz6kk 12345:	Created container mt-broker-controller
12:51:50 Pod mt-broker-controller-56cc5dc5cc-dz6kk 12345:	Started container mt-broker-controller
12:26:14 Pod mt-broker-controller-56cc5dc5cc-f2b6q 3355:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-f2b6q to acto-cluster-6-worker3
12:26:15 Pod mt-broker-controller-56cc5dc5cc-f2b6q 3359:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:26:17 Pod mt-broker-controller-56cc5dc5cc-f2b6q 3359:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.913892006s
12:26:18 Pod mt-broker-controller-56cc5dc5cc-f2b6q 3359:	Created container mt-broker-controller
12:26:18 Pod mt-broker-controller-56cc5dc5cc-f2b6q 3359:	Started container mt-broker-controller
12:30:15 Pod mt-broker-controller-56cc5dc5cc-f2b6q 3359:	Stopping container mt-broker-controller
12:21:33 Pod mt-broker-controller-56cc5dc5cc-gp4d9 1361:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-gp4d9 to acto-cluster-6-worker
12:21:34 Pod mt-broker-controller-56cc5dc5cc-gp4d9 1364:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:21:41 Pod mt-broker-controller-56cc5dc5cc-gp4d9 1364:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 7.461151175s
12:21:41 Pod mt-broker-controller-56cc5dc5cc-gp4d9 1364:	Created container mt-broker-controller
12:21:42 Pod mt-broker-controller-56cc5dc5cc-gp4d9 1364:	Started container mt-broker-controller
12:25:35 Pod mt-broker-controller-56cc5dc5cc-gp4d9 1364:	Stopping container mt-broker-controller
12:32:04 Pod mt-broker-controller-56cc5dc5cc-pdtv4 5579:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-pdtv4 to acto-cluster-6-worker
12:32:05 Pod mt-broker-controller-56cc5dc5cc-pdtv4 5582:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:32:05 Pod mt-broker-controller-56cc5dc5cc-pdtv4 5582:	Created container mt-broker-controller
12:32:05 Pod mt-broker-controller-56cc5dc5cc-pdtv4 5582:	Started container mt-broker-controller
12:36:06 Pod mt-broker-controller-56cc5dc5cc-pdtv4 5582:	Stopping container mt-broker-controller
12:45:19 Pod mt-broker-controller-56cc5dc5cc-t6rsh 10117:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-t6rsh to acto-cluster-6-worker3
12:45:20 Pod mt-broker-controller-56cc5dc5cc-t6rsh 10120:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:45:20 Pod mt-broker-controller-56cc5dc5cc-t6rsh 10120:	Created container mt-broker-controller
12:45:20 Pod mt-broker-controller-56cc5dc5cc-t6rsh 10120:	Started container mt-broker-controller
12:49:21 Pod mt-broker-controller-56cc5dc5cc-t6rsh 10120:	Stopping container mt-broker-controller
12:21:33 ReplicaSet mt-broker-controller-56cc5dc5cc 1357:	Created pod: mt-broker-controller-56cc5dc5cc-gp4d9
12:26:14 ReplicaSet mt-broker-controller-56cc5dc5cc 3354:	Created pod: mt-broker-controller-56cc5dc5cc-f2b6q
12:32:04 ReplicaSet mt-broker-controller-56cc5dc5cc 5577:	Created pod: mt-broker-controller-56cc5dc5cc-pdtv4
12:38:05 ReplicaSet mt-broker-controller-56cc5dc5cc 7803:	Created pod: mt-broker-controller-56cc5dc5cc-9h6d4
12:45:19 ReplicaSet mt-broker-controller-56cc5dc5cc 10115:	Created pod: mt-broker-controller-56cc5dc5cc-t6rsh
12:51:50 ReplicaSet mt-broker-controller-56cc5dc5cc 12339:	Created pod: mt-broker-controller-56cc5dc5cc-dz6kk
12:21:33 Deployment mt-broker-controller 1356:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:26:14 Deployment mt-broker-controller 3349:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:32:04 Deployment mt-broker-controller 5576:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:38:05 Deployment mt-broker-controller 7801:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:45:19 Deployment mt-broker-controller 10114:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:51:50 Deployment mt-broker-controller 12338:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:26:13 Pod mt-broker-filter-846dc966c5-bnpxp 3298:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-bnpxp to acto-cluster-6-worker2
12:26:14 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:26:18 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 4.588366258s
12:26:18 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Created container filter
12:26:19 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Started container filter
12:30:15 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Stopping container filter
12:30:17 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:30:17 Pod mt-broker-filter-846dc966c5-bnpxp 3301:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:21:32 Pod mt-broker-filter-846dc966c5-crzbd 1319:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-crzbd to acto-cluster-6-worker
12:21:33 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:21:38 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 5.212306637s
12:21:38 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Created container filter
12:21:38 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Started container filter
12:25:35 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Stopping container filter
12:25:36 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:25:36 Pod mt-broker-filter-846dc966c5-crzbd 1322:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:51:49 Pod mt-broker-filter-846dc966c5-k8mnw 12298:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-k8mnw to acto-cluster-6-worker2
12:51:49 Pod mt-broker-filter-846dc966c5-k8mnw 12301:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:51:49 Pod mt-broker-filter-846dc966c5-k8mnw 12301:	Created container filter
12:51:50 Pod mt-broker-filter-846dc966c5-k8mnw 12301:	Started container filter
12:45:18 Pod mt-broker-filter-846dc966c5-sdtn8 10068:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-sdtn8 to acto-cluster-6-worker2
12:45:19 Pod mt-broker-filter-846dc966c5-sdtn8 10071:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:45:19 Pod mt-broker-filter-846dc966c5-sdtn8 10071:	Created container filter
12:45:19 Pod mt-broker-filter-846dc966c5-sdtn8 10071:	Started container filter
12:45:19 Pod mt-broker-filter-846dc966c5-sdtn8 10071:	Readiness probe failed: Get "http://10.244.2.19:8080/healthz": dial tcp 10.244.2.19:8080: connect: connection refused
12:49:21 Pod mt-broker-filter-846dc966c5-sdtn8 10071:	Stopping container filter
12:38:05 Pod mt-broker-filter-846dc966c5-zcffb 7750:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-zcffb to acto-cluster-6-worker
12:38:05 Pod mt-broker-filter-846dc966c5-zcffb 7753:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:38:05 Pod mt-broker-filter-846dc966c5-zcffb 7753:	Created container filter
12:38:05 Pod mt-broker-filter-846dc966c5-zcffb 7753:	Started container filter
12:42:10 Pod mt-broker-filter-846dc966c5-zcffb 7753:	Stopping container filter
12:32:03 Pod mt-broker-filter-846dc966c5-zqnxd 5537:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-zqnxd to acto-cluster-6-worker2
12:32:04 Pod mt-broker-filter-846dc966c5-zqnxd 5540:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:32:04 Pod mt-broker-filter-846dc966c5-zqnxd 5540:	Created container filter
12:32:04 Pod mt-broker-filter-846dc966c5-zqnxd 5540:	Started container filter
12:36:06 Pod mt-broker-filter-846dc966c5-zqnxd 5540:	Stopping container filter
12:36:07 Pod mt-broker-filter-846dc966c5-zqnxd 5540:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:36:07 Pod mt-broker-filter-846dc966c5-zqnxd 5540:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:21:32 ReplicaSet mt-broker-filter-846dc966c5 1317:	Created pod: mt-broker-filter-846dc966c5-crzbd
12:26:13 ReplicaSet mt-broker-filter-846dc966c5 3296:	Created pod: mt-broker-filter-846dc966c5-bnpxp
12:32:03 ReplicaSet mt-broker-filter-846dc966c5 5535:	Created pod: mt-broker-filter-846dc966c5-zqnxd
12:38:05 ReplicaSet mt-broker-filter-846dc966c5 7748:	Created pod: mt-broker-filter-846dc966c5-zcffb
12:45:18 ReplicaSet mt-broker-filter-846dc966c5 10066:	Created pod: mt-broker-filter-846dc966c5-sdtn8
12:51:49 ReplicaSet mt-broker-filter-846dc966c5 12296:	Created pod: mt-broker-filter-846dc966c5-k8mnw
12:21:32 Deployment mt-broker-filter 1316:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:26:13 Deployment mt-broker-filter 3295:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:32:03 Deployment mt-broker-filter 5534:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:38:05 Deployment mt-broker-filter 7747:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:45:18 Deployment mt-broker-filter 10065:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:51:49 Deployment mt-broker-filter 12295:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:45:19 Pod mt-broker-ingress-6dbbfff4b9-6lp2r 10096:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-6lp2r to acto-cluster-6-worker3
12:45:19 Pod mt-broker-ingress-6dbbfff4b9-6lp2r 10099:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:45:19 Pod mt-broker-ingress-6dbbfff4b9-6lp2r 10099:	Created container ingress
12:45:19 Pod mt-broker-ingress-6dbbfff4b9-6lp2r 10099:	Started container ingress
12:45:19 Pod mt-broker-ingress-6dbbfff4b9-6lp2r 10099:	Readiness probe failed: Get "http://10.244.1.12:8080/healthz": dial tcp 10.244.1.12:8080: connect: connection refused
12:49:21 Pod mt-broker-ingress-6dbbfff4b9-6lp2r 10099:	Stopping container ingress
12:38:05 Pod mt-broker-ingress-6dbbfff4b9-968pc 7769:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-968pc to acto-cluster-6-worker2
12:38:06 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:38:06 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Created container ingress
12:38:06 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Started container ingress
12:38:06 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Readiness probe failed: Get "http://10.244.2.15:8080/healthz": dial tcp 10.244.2.15:8080: connect: connection refused
12:42:10 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Stopping container ingress
12:42:11 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:42:11 Pod mt-broker-ingress-6dbbfff4b9-968pc 7772:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:51:49 Pod mt-broker-ingress-6dbbfff4b9-fkptn 12317:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-fkptn to acto-cluster-6-worker3
12:51:50 Pod mt-broker-ingress-6dbbfff4b9-fkptn 12320:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:51:50 Pod mt-broker-ingress-6dbbfff4b9-fkptn 12320:	Created container ingress
12:51:50 Pod mt-broker-ingress-6dbbfff4b9-fkptn 12320:	Started container ingress
12:21:33 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1340:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-ftknm to acto-cluster-6-worker3
12:21:33 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:21:37 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 3.57266373s
12:21:37 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Created container ingress
12:21:37 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Started container ingress
12:25:35 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Stopping container ingress
12:25:35 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:25:35 Pod mt-broker-ingress-6dbbfff4b9-ftknm 1343:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:26:14 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3323:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-lnt8t to acto-cluster-6-worker2
12:26:14 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:26:21 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 6.896378183s
12:26:21 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Created container ingress
12:26:21 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Started container ingress
12:30:15 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Stopping container ingress
12:30:16 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:30:16 Pod mt-broker-ingress-6dbbfff4b9-lnt8t 3326:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:32:04 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5554:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-r9xl2 to acto-cluster-6-worker3
12:32:04 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5557:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:32:04 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5557:	Created container ingress
12:32:04 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5557:	Started container ingress
12:36:06 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5557:	Stopping container ingress
12:36:06 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5557:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:36:06 Pod mt-broker-ingress-6dbbfff4b9-r9xl2 5557:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:21:33 ReplicaSet mt-broker-ingress-6dbbfff4b9 1338:	Created pod: mt-broker-ingress-6dbbfff4b9-ftknm
12:26:14 ReplicaSet mt-broker-ingress-6dbbfff4b9 3321:	Created pod: mt-broker-ingress-6dbbfff4b9-lnt8t
12:32:04 ReplicaSet mt-broker-ingress-6dbbfff4b9 5552:	Created pod: mt-broker-ingress-6dbbfff4b9-r9xl2
12:38:05 ReplicaSet mt-broker-ingress-6dbbfff4b9 7767:	Created pod: mt-broker-ingress-6dbbfff4b9-968pc
12:45:19 ReplicaSet mt-broker-ingress-6dbbfff4b9 10094:	Created pod: mt-broker-ingress-6dbbfff4b9-6lp2r
12:51:49 ReplicaSet mt-broker-ingress-6dbbfff4b9 12315:	Created pod: mt-broker-ingress-6dbbfff4b9-fkptn
12:21:33 Deployment mt-broker-ingress 1337:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:26:14 Deployment mt-broker-ingress 3320:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:32:04 Deployment mt-broker-ingress 5551:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:38:05 Deployment mt-broker-ingress 7766:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:45:19 Deployment mt-broker-ingress 10093:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:51:49 Deployment mt-broker-ingress 12314:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:45:20 Pod storage-version-migration-eventing-eventing-1.6.0--1-8knvd 10157:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-8knvd to acto-cluster-6-worker3
12:45:20 Pod storage-version-migration-eventing-eventing-1.6.0--1-8knvd 10159:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:45:20 Pod storage-version-migration-eventing-eventing-1.6.0--1-8knvd 10159:	Created container migrate
12:45:21 Pod storage-version-migration-eventing-eventing-1.6.0--1-8knvd 10159:	Started container migrate
12:51:50 Pod storage-version-migration-eventing-eventing-1.6.0--1-98xnh 12383:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-98xnh to acto-cluster-6-worker2
12:51:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-98xnh 12385:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:51:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-98xnh 12385:	Created container migrate
12:51:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-98xnh 12385:	Started container migrate
12:21:34 Pod storage-version-migration-eventing-eventing-1.6.0--1-mwpnj 1409:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-mwpnj to acto-cluster-6-worker2
12:21:35 Pod storage-version-migration-eventing-eventing-1.6.0--1-mwpnj 1411:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:21:38 Pod storage-version-migration-eventing-eventing-1.6.0--1-mwpnj 1411:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 3.717820807s
12:21:38 Pod storage-version-migration-eventing-eventing-1.6.0--1-mwpnj 1411:	Created container migrate
12:21:39 Pod storage-version-migration-eventing-eventing-1.6.0--1-mwpnj 1411:	Started container migrate
12:26:15 Pod storage-version-migration-eventing-eventing-1.6.0--1-rhqg7 3383:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-rhqg7 to acto-cluster-6-worker
12:26:15 Pod storage-version-migration-eventing-eventing-1.6.0--1-rhqg7 3385:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:26:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-rhqg7 3385:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.479585061s
12:26:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-rhqg7 3385:	Created container migrate
12:26:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-rhqg7 3385:	Started container migrate
12:32:05 Pod storage-version-migration-eventing-eventing-1.6.0--1-st58m 5605:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-st58m to acto-cluster-6-worker3
12:32:05 Pod storage-version-migration-eventing-eventing-1.6.0--1-st58m 5608:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:32:09 Pod storage-version-migration-eventing-eventing-1.6.0--1-st58m 5608:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 3.144321344s
12:32:09 Pod storage-version-migration-eventing-eventing-1.6.0--1-st58m 5608:	Created container migrate
12:32:09 Pod storage-version-migration-eventing-eventing-1.6.0--1-st58m 5608:	Started container migrate
12:38:06 Pod storage-version-migration-eventing-eventing-1.6.0--1-xf95n 7830:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-xf95n to acto-cluster-6-worker3
12:38:07 Pod storage-version-migration-eventing-eventing-1.6.0--1-xf95n 7832:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:38:07 Pod storage-version-migration-eventing-eventing-1.6.0--1-xf95n 7832:	Created container migrate
12:38:07 Pod storage-version-migration-eventing-eventing-1.6.0--1-xf95n 7832:	Started container migrate
12:21:34 Job storage-version-migration-eventing-eventing-1.6.0 1402:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-mwpnj
12:21:44 Job storage-version-migration-eventing-eventing-1.6.0 1484:	Job completed
12:26:15 Job storage-version-migration-eventing-eventing-1.6.0 3381:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-rhqg7
12:26:23 Job storage-version-migration-eventing-eventing-1.6.0 3387:	Job completed
12:32:05 Job storage-version-migration-eventing-eventing-1.6.0 5604:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-st58m
12:32:14 Job storage-version-migration-eventing-eventing-1.6.0 5611:	Job completed
12:38:06 Job storage-version-migration-eventing-eventing-1.6.0 7829:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-xf95n
12:38:12 Job storage-version-migration-eventing-eventing-1.6.0 7834:	Job completed
12:45:20 Job storage-version-migration-eventing-eventing-1.6.0 10156:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-8knvd
12:45:26 Job storage-version-migration-eventing-eventing-1.6.0 10160:	Job completed
12:51:50 Job storage-version-migration-eventing-eventing-1.6.0 12381:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-98xnh
12:51:57 Job storage-version-migration-eventing-eventing-1.6.0 12388:	Job completed
12:21:13 KnativeEventing test-cluster 840:	Updated "test-cluster" finalizers
12:25:53 KnativeEventing test-cluster 2649:	Updated "test-cluster" finalizers
12:25:55 KnativeEventing test-cluster 2972:	Updated "test-cluster" finalizers
12:31:45 KnativeEventing test-cluster 5168:	Updated "test-cluster" finalizers
12:37:46 KnativeEventing test-cluster 7394:	Updated "test-cluster" finalizers
12:45:00 KnativeEventing test-cluster 9715:	Updated "test-cluster" finalizers
12:51:30 KnativeEventing test-cluster 11943:	Updated "test-cluster" finalizers
