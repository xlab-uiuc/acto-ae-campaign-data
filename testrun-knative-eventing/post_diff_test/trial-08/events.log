12:21:36 HorizontalPodAutoscaler broker-filter-hpa 1309:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:36 HorizontalPodAutoscaler broker-filter-hpa 1309:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:26 HorizontalPodAutoscaler broker-filter-hpa 3493:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:26 HorizontalPodAutoscaler broker-filter-hpa 3493:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:32 HorizontalPodAutoscaler broker-filter-hpa 5732:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:32 HorizontalPodAutoscaler broker-filter-hpa 5732:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:13 HorizontalPodAutoscaler broker-filter-hpa 7811:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:13 HorizontalPodAutoscaler broker-filter-hpa 7811:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:56 HorizontalPodAutoscaler broker-filter-hpa 9882:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:56 HorizontalPodAutoscaler broker-filter-hpa 9882:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:45 HorizontalPodAutoscaler broker-filter-hpa 12066:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:45 HorizontalPodAutoscaler broker-filter-hpa 12066:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:28 HorizontalPodAutoscaler broker-filter-hpa 14144:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:28 HorizontalPodAutoscaler broker-filter-hpa 14144:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:36 HorizontalPodAutoscaler broker-ingress-hpa 1305:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:36 HorizontalPodAutoscaler broker-ingress-hpa 1305:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:26 HorizontalPodAutoscaler broker-ingress-hpa 3487:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:26 HorizontalPodAutoscaler broker-ingress-hpa 3487:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:32 HorizontalPodAutoscaler broker-ingress-hpa 5729:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:32 HorizontalPodAutoscaler broker-ingress-hpa 5729:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:13 HorizontalPodAutoscaler broker-ingress-hpa 7808:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:13 HorizontalPodAutoscaler broker-ingress-hpa 7808:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:55 HorizontalPodAutoscaler broker-ingress-hpa 9879:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:55 HorizontalPodAutoscaler broker-ingress-hpa 9879:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:45 HorizontalPodAutoscaler broker-ingress-hpa 12055:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:45 HorizontalPodAutoscaler broker-ingress-hpa 12055:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:28 HorizontalPodAutoscaler broker-ingress-hpa 14134:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:28 HorizontalPodAutoscaler broker-ingress-hpa 14134:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:37:52 Pod eventing-controller-5d88d6d755-5pzpk 7560:	Successfully assigned knative-eventing/eventing-controller-5d88d6d755-5pzpk to acto-cluster-8-worker
12:37:52 Pod eventing-controller-5d88d6d755-5pzpk 7562:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:37:52 Pod eventing-controller-5d88d6d755-5pzpk 7562:	Created container eventing-controller
12:37:52 Pod eventing-controller-5d88d6d755-5pzpk 7562:	Started container eventing-controller
12:42:06 Pod eventing-controller-5d88d6d755-5pzpk 7562:	Stopping container eventing-controller
12:37:52 ReplicaSet eventing-controller-5d88d6d755 7557:	Created pod: eventing-controller-5d88d6d755-5pzpk
12:48:24 Pod eventing-controller-6c78bb8c7f-6n5rd 11817:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-6n5rd to acto-cluster-8-worker3
12:48:24 Pod eventing-controller-6c78bb8c7f-6n5rd 11819:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:48:24 Pod eventing-controller-6c78bb8c7f-6n5rd 11819:	Created container eventing-controller
12:48:25 Pod eventing-controller-6c78bb8c7f-6n5rd 11819:	Started container eventing-controller
12:52:38 Pod eventing-controller-6c78bb8c7f-6n5rd 11819:	Stopping container eventing-controller
12:42:34 Pod eventing-controller-6c78bb8c7f-8l629 9632:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-8l629 to acto-cluster-8-worker3
12:42:35 Pod eventing-controller-6c78bb8c7f-8l629 9634:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:42:35 Pod eventing-controller-6c78bb8c7f-8l629 9634:	Created container eventing-controller
12:42:35 Pod eventing-controller-6c78bb8c7f-8l629 9634:	Started container eventing-controller
12:46:47 Pod eventing-controller-6c78bb8c7f-8l629 9634:	Stopping container eventing-controller
12:27:05 Pod eventing-controller-6c78bb8c7f-t4hvl 3279:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-t4hvl to acto-cluster-8-worker
12:27:05 Pod eventing-controller-6c78bb8c7f-t4hvl 3281:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:27:08 Pod eventing-controller-6c78bb8c7f-t4hvl 3281:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.741803422s
12:27:08 Pod eventing-controller-6c78bb8c7f-t4hvl 3281:	Created container eventing-controller
12:27:08 Pod eventing-controller-6c78bb8c7f-t4hvl 3281:	Started container eventing-controller
12:31:20 Pod eventing-controller-6c78bb8c7f-t4hvl 3281:	Stopping container eventing-controller
12:33:11 Pod eventing-controller-6c78bb8c7f-whndp 5502:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-whndp to acto-cluster-8-worker
12:33:11 Pod eventing-controller-6c78bb8c7f-whndp 5504:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:33:11 Pod eventing-controller-6c78bb8c7f-whndp 5504:	Created container eventing-controller
12:33:11 Pod eventing-controller-6c78bb8c7f-whndp 5504:	Started container eventing-controller
12:37:23 Pod eventing-controller-6c78bb8c7f-whndp 5504:	Stopping container eventing-controller
12:27:05 ReplicaSet eventing-controller-6c78bb8c7f 3276:	Created pod: eventing-controller-6c78bb8c7f-t4hvl
12:33:11 ReplicaSet eventing-controller-6c78bb8c7f 5499:	Created pod: eventing-controller-6c78bb8c7f-whndp
12:42:34 ReplicaSet eventing-controller-6c78bb8c7f 9629:	Created pod: eventing-controller-6c78bb8c7f-8l629
12:48:24 ReplicaSet eventing-controller-6c78bb8c7f 11814:	Created pod: eventing-controller-6c78bb8c7f-6n5rd
12:21:14 Pod eventing-controller-78d5f57d4-fn8zn 1077:	Successfully assigned knative-eventing/eventing-controller-78d5f57d4-fn8zn to acto-cluster-8-worker3
12:21:14 Pod eventing-controller-78d5f57d4-fn8zn 1079:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:21:18 Pod eventing-controller-78d5f57d4-fn8zn 1079:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.667367014s
12:21:18 Pod eventing-controller-78d5f57d4-fn8zn 1079:	Created container eventing-controller
12:21:18 Pod eventing-controller-78d5f57d4-fn8zn 1079:	Started container eventing-controller
12:25:27 Pod eventing-controller-78d5f57d4-fn8zn 1079:	Stopping container eventing-controller
12:21:14 ReplicaSet eventing-controller-78d5f57d4 1074:	Created pod: eventing-controller-78d5f57d4-fn8zn
12:53:07 Pod eventing-controller-86d49cf697-s7clx 13890:	Successfully assigned knative-eventing/eventing-controller-86d49cf697-s7clx to acto-cluster-8-worker3
12:53:07 Pod eventing-controller-86d49cf697-s7clx 13892:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:53:07 Pod eventing-controller-86d49cf697-s7clx 13892:	Created container eventing-controller
12:53:08 Pod eventing-controller-86d49cf697-s7clx 13892:	Started container eventing-controller
12:53:07 ReplicaSet eventing-controller-86d49cf697 13887:	Created pod: eventing-controller-86d49cf697-s7clx
12:21:14 Deployment eventing-controller 1073:	Scaled up replica set eventing-controller-78d5f57d4 to 1
12:27:05 Deployment eventing-controller 3275:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:33:11 Deployment eventing-controller 5498:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:37:52 Deployment eventing-controller 7556:	Scaled up replica set eventing-controller-5d88d6d755 to 1
12:42:34 Deployment eventing-controller 9628:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:48:24 Deployment eventing-controller 11813:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:53:07 Deployment eventing-controller 13886:	Scaled up replica set eventing-controller-86d49cf697 to 1
12:21:15 Pod eventing-webhook-5755489569-28qsx 1100:	Successfully assigned knative-eventing/eventing-webhook-5755489569-28qsx to acto-cluster-8-worker2
12:21:15 Pod eventing-webhook-5755489569-28qsx 1104:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:21:18 Pod eventing-webhook-5755489569-28qsx 1104:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.735571688s
12:21:18 Pod eventing-webhook-5755489569-28qsx 1104:	Created container eventing-webhook
12:21:19 Pod eventing-webhook-5755489569-28qsx 1104:	Started container eventing-webhook
12:21:19 Pod eventing-webhook-5755489569-28qsx 1104:	Readiness probe failed: Get "https://10.244.3.3:8443/": dial tcp 10.244.3.3:8443: connect: connection refused
12:25:26 Pod eventing-webhook-5755489569-28qsx 1104:	Readiness probe failed: Get "https://10.244.3.3:8443/": remote error: tls: unrecognized name
12:25:26 Pod eventing-webhook-5755489569-28qsx 1104:	Liveness probe failed: Get "https://10.244.3.3:8443/": remote error: tls: unrecognized name
12:25:26 Pod eventing-webhook-5755489569-28qsx 1104:	Stopping container eventing-webhook
12:42:35 Pod eventing-webhook-5755489569-2cklt 9658:	Successfully assigned knative-eventing/eventing-webhook-5755489569-2cklt to acto-cluster-8-worker
12:42:36 Pod eventing-webhook-5755489569-2cklt 9661:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:42:39 Pod eventing-webhook-5755489569-2cklt 9661:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.712989671s
12:42:39 Pod eventing-webhook-5755489569-2cklt 9661:	Created container eventing-webhook
12:42:40 Pod eventing-webhook-5755489569-2cklt 9661:	Started container eventing-webhook
12:46:45 Pod eventing-webhook-5755489569-2cklt 9661:	Liveness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:46:45 Pod eventing-webhook-5755489569-2cklt 9661:	Readiness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:46:46 Pod eventing-webhook-5755489569-2cklt 9661:	Stopping container eventing-webhook
12:53:08 Pod eventing-webhook-5755489569-dx8wh 13916:	Successfully assigned knative-eventing/eventing-webhook-5755489569-dx8wh to acto-cluster-8-worker2
12:53:09 Pod eventing-webhook-5755489569-dx8wh 13919:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:53:09 Pod eventing-webhook-5755489569-dx8wh 13919:	Created container eventing-webhook
12:53:09 Pod eventing-webhook-5755489569-dx8wh 13919:	Started container eventing-webhook
12:53:10 Pod eventing-webhook-5755489569-dx8wh 13919:	Readiness probe failed: Get "https://10.244.3.19:8443/": remote error: tls: unrecognized name
12:37:52 Pod eventing-webhook-5755489569-fmdpb 7585:	Successfully assigned knative-eventing/eventing-webhook-5755489569-fmdpb to acto-cluster-8-worker2
12:37:53 Pod eventing-webhook-5755489569-fmdpb 7588:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:37:53 Pod eventing-webhook-5755489569-fmdpb 7588:	Created container eventing-webhook
12:37:54 Pod eventing-webhook-5755489569-fmdpb 7588:	Started container eventing-webhook
12:37:54 Pod eventing-webhook-5755489569-fmdpb 7588:	Readiness probe failed: Get "https://10.244.3.10:8443/": dial tcp 10.244.3.10:8443: connect: connection refused
12:42:04 Pod eventing-webhook-5755489569-fmdpb 7588:	Liveness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:42:04 Pod eventing-webhook-5755489569-fmdpb 7588:	Readiness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:42:05 Pod eventing-webhook-5755489569-fmdpb 7588:	Stopping container eventing-webhook
12:33:11 Pod eventing-webhook-5755489569-hfddj 5527:	Successfully assigned knative-eventing/eventing-webhook-5755489569-hfddj to acto-cluster-8-worker3
12:33:12 Pod eventing-webhook-5755489569-hfddj 5530:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:33:12 Pod eventing-webhook-5755489569-hfddj 5530:	Created container eventing-webhook
12:33:13 Pod eventing-webhook-5755489569-hfddj 5530:	Started container eventing-webhook
12:33:14 Pod eventing-webhook-5755489569-hfddj 5530:	Readiness probe failed: Get "https://10.244.2.8:8443/": remote error: tls: unrecognized name
12:37:21 Pod eventing-webhook-5755489569-hfddj 5530:	Liveness probe failed: Get "https://10.244.2.8:8443/": remote error: tls: unrecognized name
12:37:22 Pod eventing-webhook-5755489569-hfddj 5530:	Stopping container eventing-webhook
12:48:25 Pod eventing-webhook-5755489569-nlqqg 11844:	Successfully assigned knative-eventing/eventing-webhook-5755489569-nlqqg to acto-cluster-8-worker
12:48:26 Pod eventing-webhook-5755489569-nlqqg 11847:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:48:26 Pod eventing-webhook-5755489569-nlqqg 11847:	Created container eventing-webhook
12:48:26 Pod eventing-webhook-5755489569-nlqqg 11847:	Started container eventing-webhook
12:48:27 Pod eventing-webhook-5755489569-nlqqg 11847:	Readiness probe failed: Get "https://10.244.1.14:8443/": remote error: tls: unrecognized name
12:52:37 Pod eventing-webhook-5755489569-nlqqg 11847:	Liveness probe failed: Get "https://10.244.1.14:8443/": remote error: tls: unrecognized name
12:52:37 Pod eventing-webhook-5755489569-nlqqg 11847:	Stopping container eventing-webhook
12:27:06 Pod eventing-webhook-5755489569-sjl65 3303:	Successfully assigned knative-eventing/eventing-webhook-5755489569-sjl65 to acto-cluster-8-worker3
12:27:06 Pod eventing-webhook-5755489569-sjl65 3307:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:27:09 Pod eventing-webhook-5755489569-sjl65 3307:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.728425757s
12:27:09 Pod eventing-webhook-5755489569-sjl65 3307:	Created container eventing-webhook
12:27:10 Pod eventing-webhook-5755489569-sjl65 3307:	Started container eventing-webhook
12:31:19 Pod eventing-webhook-5755489569-sjl65 3307:	Liveness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:31:19 Pod eventing-webhook-5755489569-sjl65 3307:	Readiness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:31:19 Pod eventing-webhook-5755489569-sjl65 3307:	Stopping container eventing-webhook
12:21:15 ReplicaSet eventing-webhook-5755489569 1098:	Created pod: eventing-webhook-5755489569-28qsx
12:27:06 ReplicaSet eventing-webhook-5755489569 3301:	Created pod: eventing-webhook-5755489569-sjl65
12:33:11 ReplicaSet eventing-webhook-5755489569 5525:	Created pod: eventing-webhook-5755489569-hfddj
12:37:52 ReplicaSet eventing-webhook-5755489569 7583:	Created pod: eventing-webhook-5755489569-fmdpb
12:42:35 ReplicaSet eventing-webhook-5755489569 9656:	Created pod: eventing-webhook-5755489569-2cklt
12:48:25 ReplicaSet eventing-webhook-5755489569 11842:	Created pod: eventing-webhook-5755489569-nlqqg
12:53:08 ReplicaSet eventing-webhook-5755489569 13913:	Created pod: eventing-webhook-5755489569-dx8wh
12:21:14 PodDisruptionBudget eventing-webhook 1093:	No matching pods found
12:21:15 Deployment eventing-webhook 1097:	Scaled up replica set eventing-webhook-5755489569 to 1
12:21:29 HorizontalPodAutoscaler eventing-webhook 1091:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:29 HorizontalPodAutoscaler eventing-webhook 1091:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:25:26 PodDisruptionBudget eventing-webhook 1568:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:27:05 PodDisruptionBudget eventing-webhook 3296:	No matching pods found
12:27:06 Deployment eventing-webhook 3300:	Scaled up replica set eventing-webhook-5755489569 to 1
12:27:20 HorizontalPodAutoscaler eventing-webhook 3293:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:20 HorizontalPodAutoscaler eventing-webhook 3293:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:31:19 PodDisruptionBudget eventing-webhook 3760:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:33:11 PodDisruptionBudget eventing-webhook 5518:	No matching pods found
12:33:11 Deployment eventing-webhook 5524:	Scaled up replica set eventing-webhook-5755489569 to 1
12:33:26 HorizontalPodAutoscaler eventing-webhook 5516:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:26 HorizontalPodAutoscaler eventing-webhook 5516:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:37:22 PodDisruptionBudget eventing-webhook 5981:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:37:52 PodDisruptionBudget eventing-webhook 7576:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:37:52 Deployment eventing-webhook 7582:	Scaled up replica set eventing-webhook-5755489569 to 1
12:37:52 PodDisruptionBudget eventing-webhook 7578:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-hfddj"
12:38:07 HorizontalPodAutoscaler eventing-webhook 7575:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:07 HorizontalPodAutoscaler eventing-webhook 7575:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:35 PodDisruptionBudget eventing-webhook 9649:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:42:35 Deployment eventing-webhook 9655:	Scaled up replica set eventing-webhook-5755489569 to 1
12:42:35 PodDisruptionBudget eventing-webhook 9651:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-fmdpb"
12:42:50 HorizontalPodAutoscaler eventing-webhook 9648:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:50 HorizontalPodAutoscaler eventing-webhook 9648:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:25 PodDisruptionBudget eventing-webhook 11835:	No matching pods found
12:48:25 Deployment eventing-webhook 11841:	Scaled up replica set eventing-webhook-5755489569 to 1
12:48:39 HorizontalPodAutoscaler eventing-webhook 11831:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:39 HorizontalPodAutoscaler eventing-webhook 11831:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:37 PodDisruptionBudget eventing-webhook 12294:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:53:07 PodDisruptionBudget eventing-webhook 13907:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:53:08 Deployment eventing-webhook 13912:	Scaled up replica set eventing-webhook-5755489569 to 1
12:53:08 PodDisruptionBudget eventing-webhook 13910:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-nlqqg"
12:53:22 HorizontalPodAutoscaler eventing-webhook 13904:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:22 HorizontalPodAutoscaler eventing-webhook 13904:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:27 Pod imc-controller-567b4f565b-bw2bv 11924:	Successfully assigned knative-eventing/imc-controller-567b4f565b-bw2bv to acto-cluster-8-worker2
12:48:28 Pod imc-controller-567b4f565b-bw2bv 11927:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:48:28 Pod imc-controller-567b4f565b-bw2bv 11927:	Created container controller
12:48:28 Pod imc-controller-567b4f565b-bw2bv 11927:	Started container controller
12:52:34 Pod imc-controller-567b4f565b-bw2bv 11927:	Liveness probe failed: Get "https://10.244.3.16:8443/": remote error: tls: unrecognized name
12:52:34 Pod imc-controller-567b4f565b-bw2bv 11927:	Readiness probe failed: Get "https://10.244.3.16:8443/": remote error: tls: unrecognized name
12:52:35 Pod imc-controller-567b4f565b-bw2bv 11927:	Stopping container controller
12:21:18 Pod imc-controller-567b4f565b-clpv4 1150:	Successfully assigned knative-eventing/imc-controller-567b4f565b-clpv4 to acto-cluster-8-worker
12:21:19 Pod imc-controller-567b4f565b-clpv4 1153:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:21:22 Pod imc-controller-567b4f565b-clpv4 1153:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 3.588411446s
12:21:22 Pod imc-controller-567b4f565b-clpv4 1153:	Created container controller
12:21:23 Pod imc-controller-567b4f565b-clpv4 1153:	Started container controller
12:25:23 Pod imc-controller-567b4f565b-clpv4 1153:	Readiness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
12:25:23 Pod imc-controller-567b4f565b-clpv4 1153:	Liveness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
12:25:24 Pod imc-controller-567b4f565b-clpv4 1153:	Stopping container controller
12:42:38 Pod imc-controller-567b4f565b-d5xfj 9723:	Successfully assigned knative-eventing/imc-controller-567b4f565b-d5xfj to acto-cluster-8-worker2
12:42:39 Pod imc-controller-567b4f565b-d5xfj 9726:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:42:39 Pod imc-controller-567b4f565b-d5xfj 9726:	Created container controller
12:42:39 Pod imc-controller-567b4f565b-d5xfj 9726:	Started container controller
12:46:43 Pod imc-controller-567b4f565b-d5xfj 9726:	Readiness probe failed: Get "https://10.244.3.13:8443/": remote error: tls: unrecognized name
12:46:43 Pod imc-controller-567b4f565b-d5xfj 9726:	Liveness probe failed: Get "https://10.244.3.13:8443/": remote error: tls: unrecognized name
12:46:44 Pod imc-controller-567b4f565b-d5xfj 9726:	Stopping container controller
12:53:10 Pod imc-controller-567b4f565b-dtwtr 14004:	Successfully assigned knative-eventing/imc-controller-567b4f565b-dtwtr to acto-cluster-8-worker
12:53:11 Pod imc-controller-567b4f565b-dtwtr 14007:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:53:11 Pod imc-controller-567b4f565b-dtwtr 14007:	Created container controller
12:53:11 Pod imc-controller-567b4f565b-dtwtr 14007:	Started container controller
12:33:14 Pod imc-controller-567b4f565b-h2kdz 5608:	Successfully assigned knative-eventing/imc-controller-567b4f565b-h2kdz to acto-cluster-8-worker2
12:33:15 Pod imc-controller-567b4f565b-h2kdz 5611:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:33:15 Pod imc-controller-567b4f565b-h2kdz 5611:	Created container controller
12:33:15 Pod imc-controller-567b4f565b-h2kdz 5611:	Started container controller
12:37:19 Pod imc-controller-567b4f565b-h2kdz 5611:	Readiness probe failed: Get "https://10.244.3.8:8443/": remote error: tls: unrecognized name
12:37:19 Pod imc-controller-567b4f565b-h2kdz 5611:	Liveness probe failed: Get "https://10.244.3.8:8443/": remote error: tls: unrecognized name
12:37:20 Pod imc-controller-567b4f565b-h2kdz 5611:	Stopping container controller
12:27:08 Pod imc-controller-567b4f565b-nmlsf 3342:	Successfully assigned knative-eventing/imc-controller-567b4f565b-nmlsf to acto-cluster-8-worker2
12:27:09 Pod imc-controller-567b4f565b-nmlsf 3346:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:27:12 Pod imc-controller-567b4f565b-nmlsf 3346:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.731792382s
12:27:12 Pod imc-controller-567b4f565b-nmlsf 3346:	Created container controller
12:27:12 Pod imc-controller-567b4f565b-nmlsf 3346:	Started container controller
12:27:12 Pod imc-controller-567b4f565b-nmlsf 3346:	Readiness probe failed: Get "https://10.244.3.6:8443/": dial tcp 10.244.3.6:8443: connect: connection refused
12:31:16 Pod imc-controller-567b4f565b-nmlsf 3346:	Liveness probe failed: Get "https://10.244.3.6:8443/": remote error: tls: unrecognized name
12:31:16 Pod imc-controller-567b4f565b-nmlsf 3346:	Readiness probe failed: Get "https://10.244.3.6:8443/": remote error: tls: unrecognized name
12:31:17 Pod imc-controller-567b4f565b-nmlsf 3346:	Stopping container controller
12:37:55 Pod imc-controller-567b4f565b-qjrqn 7671:	Successfully assigned knative-eventing/imc-controller-567b4f565b-qjrqn to acto-cluster-8-worker
12:37:56 Pod imc-controller-567b4f565b-qjrqn 7674:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:37:56 Pod imc-controller-567b4f565b-qjrqn 7674:	Created container controller
12:37:56 Pod imc-controller-567b4f565b-qjrqn 7674:	Started container controller
12:42:02 Pod imc-controller-567b4f565b-qjrqn 7674:	Liveness probe failed: Get "https://10.244.1.10:8443/": remote error: tls: unrecognized name
12:42:02 Pod imc-controller-567b4f565b-qjrqn 7674:	Readiness probe failed: Get "https://10.244.1.10:8443/": remote error: tls: unrecognized name
12:42:03 Pod imc-controller-567b4f565b-qjrqn 7674:	Stopping container controller
12:21:18 ReplicaSet imc-controller-567b4f565b 1148:	Created pod: imc-controller-567b4f565b-clpv4
12:27:08 ReplicaSet imc-controller-567b4f565b 3340:	Created pod: imc-controller-567b4f565b-nmlsf
12:33:14 ReplicaSet imc-controller-567b4f565b 5606:	Created pod: imc-controller-567b4f565b-h2kdz
12:37:55 ReplicaSet imc-controller-567b4f565b 7669:	Created pod: imc-controller-567b4f565b-qjrqn
12:42:38 ReplicaSet imc-controller-567b4f565b 9721:	Created pod: imc-controller-567b4f565b-d5xfj
12:48:27 ReplicaSet imc-controller-567b4f565b 11922:	Created pod: imc-controller-567b4f565b-bw2bv
12:53:10 ReplicaSet imc-controller-567b4f565b 14002:	Created pod: imc-controller-567b4f565b-dtwtr
12:21:18 Deployment imc-controller 1147:	Scaled up replica set imc-controller-567b4f565b to 1
12:27:08 Deployment imc-controller 3339:	Scaled up replica set imc-controller-567b4f565b to 1
12:33:14 Deployment imc-controller 5603:	Scaled up replica set imc-controller-567b4f565b to 1
12:37:55 Deployment imc-controller 7668:	Scaled up replica set imc-controller-567b4f565b to 1
12:42:38 Deployment imc-controller 9720:	Scaled up replica set imc-controller-567b4f565b to 1
12:48:27 Deployment imc-controller 11921:	Scaled up replica set imc-controller-567b4f565b to 1
12:53:10 Deployment imc-controller 14001:	Scaled up replica set imc-controller-567b4f565b to 1
12:48:28 Pod imc-dispatcher-545bcb44c5-b5vgv 11954:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-b5vgv to acto-cluster-8-worker
12:48:29 Pod imc-dispatcher-545bcb44c5-b5vgv 11957:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:48:29 Pod imc-dispatcher-545bcb44c5-b5vgv 11957:	Created container dispatcher
12:48:29 Pod imc-dispatcher-545bcb44c5-b5vgv 11957:	Started container dispatcher
12:52:34 Pod imc-dispatcher-545bcb44c5-b5vgv 11957:	Stopping container dispatcher
12:42:39 Pod imc-dispatcher-545bcb44c5-d2jrm 9747:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-d2jrm to acto-cluster-8-worker
12:42:39 Pod imc-dispatcher-545bcb44c5-d2jrm 9751:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:42:39 Pod imc-dispatcher-545bcb44c5-d2jrm 9751:	Created container dispatcher
12:42:40 Pod imc-dispatcher-545bcb44c5-d2jrm 9751:	Started container dispatcher
12:46:43 Pod imc-dispatcher-545bcb44c5-d2jrm 9751:	Stopping container dispatcher
12:21:19 Pod imc-dispatcher-545bcb44c5-dqnjq 1197:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-dqnjq to acto-cluster-8-worker
12:21:20 Pod imc-dispatcher-545bcb44c5-dqnjq 1201:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:21:26 Pod imc-dispatcher-545bcb44c5-dqnjq 1201:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 6.645451811s
12:21:26 Pod imc-dispatcher-545bcb44c5-dqnjq 1201:	Created container dispatcher
12:21:26 Pod imc-dispatcher-545bcb44c5-dqnjq 1201:	Started container dispatcher
12:25:23 Pod imc-dispatcher-545bcb44c5-dqnjq 1201:	Stopping container dispatcher
12:33:15 Pod imc-dispatcher-545bcb44c5-svs6r 5637:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-svs6r to acto-cluster-8-worker2
12:33:15 Pod imc-dispatcher-545bcb44c5-svs6r 5641:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:33:18 Pod imc-dispatcher-545bcb44c5-svs6r 5641:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.765678192s
12:33:18 Pod imc-dispatcher-545bcb44c5-svs6r 5641:	Created container dispatcher
12:33:18 Pod imc-dispatcher-545bcb44c5-svs6r 5641:	Started container dispatcher
12:37:19 Pod imc-dispatcher-545bcb44c5-svs6r 5641:	Stopping container dispatcher
12:37:56 Pod imc-dispatcher-545bcb44c5-tcrpb 7699:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-tcrpb to acto-cluster-8-worker
12:37:56 Pod imc-dispatcher-545bcb44c5-tcrpb 7703:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:37:56 Pod imc-dispatcher-545bcb44c5-tcrpb 7703:	Created container dispatcher
12:37:56 Pod imc-dispatcher-545bcb44c5-tcrpb 7703:	Started container dispatcher
12:37:56 Pod imc-dispatcher-545bcb44c5-tcrpb 7703:	Readiness probe failed: Get "http://10.244.1.11:8080/healthz": dial tcp 10.244.1.11:8080: connect: connection refused
12:42:02 Pod imc-dispatcher-545bcb44c5-tcrpb 7703:	Stopping container dispatcher
12:53:11 Pod imc-dispatcher-545bcb44c5-tw2kt 14034:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-tw2kt to acto-cluster-8-worker
12:53:12 Pod imc-dispatcher-545bcb44c5-tw2kt 14038:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:53:12 Pod imc-dispatcher-545bcb44c5-tw2kt 14038:	Created container dispatcher
12:53:12 Pod imc-dispatcher-545bcb44c5-tw2kt 14038:	Started container dispatcher
12:27:09 Pod imc-dispatcher-545bcb44c5-wrb9f 3388:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-wrb9f to acto-cluster-8-worker3
12:27:09 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:27:12 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.840398666s
12:27:12 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Created container dispatcher
12:27:12 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Started container dispatcher
12:31:16 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Stopping container dispatcher
12:31:17 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Readiness probe failed: Get "http://10.244.2.5:8080/healthz": dial tcp 10.244.2.5:8080: connect: network is unreachable
12:31:17 Pod imc-dispatcher-545bcb44c5-wrb9f 3391:	Liveness probe failed: Get "http://10.244.2.5:8080/healthz": dial tcp 10.244.2.5:8080: connect: network is unreachable
12:21:19 ReplicaSet imc-dispatcher-545bcb44c5 1194:	Created pod: imc-dispatcher-545bcb44c5-dqnjq
12:27:09 ReplicaSet imc-dispatcher-545bcb44c5 3386:	Created pod: imc-dispatcher-545bcb44c5-wrb9f
12:33:15 ReplicaSet imc-dispatcher-545bcb44c5 5635:	Created pod: imc-dispatcher-545bcb44c5-svs6r
12:37:56 ReplicaSet imc-dispatcher-545bcb44c5 7697:	Created pod: imc-dispatcher-545bcb44c5-tcrpb
12:42:39 ReplicaSet imc-dispatcher-545bcb44c5 9745:	Created pod: imc-dispatcher-545bcb44c5-d2jrm
12:48:28 ReplicaSet imc-dispatcher-545bcb44c5 11951:	Created pod: imc-dispatcher-545bcb44c5-b5vgv
12:53:11 ReplicaSet imc-dispatcher-545bcb44c5 14032:	Created pod: imc-dispatcher-545bcb44c5-tw2kt
12:21:19 Deployment imc-dispatcher 1193:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:27:09 Deployment imc-dispatcher 3385:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:33:15 Deployment imc-dispatcher 5634:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:37:56 Deployment imc-dispatcher 7696:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:42:39 Deployment imc-dispatcher 9744:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:48:28 Deployment imc-dispatcher 11950:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:53:11 Deployment imc-dispatcher 14031:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:20:53 Pod knative-operator-668fb586bb-d2zjh 806:	Successfully assigned knative-eventing/knative-operator-668fb586bb-d2zjh to acto-cluster-8-worker2
12:20:53 Pod knative-operator-668fb586bb-d2zjh 810:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:20:56 Pod knative-operator-668fb586bb-d2zjh 810:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.007031585s
12:20:56 Pod knative-operator-668fb586bb-d2zjh 810:	Created container knative-operator
12:20:57 Pod knative-operator-668fb586bb-d2zjh 810:	Started container knative-operator
12:25:42 Pod knative-operator-668fb586bb-d2zjh 810:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:31:35 Pod knative-operator-668fb586bb-d2zjh 810:	Back-off restarting failed container
12:20:53 ReplicaSet knative-operator-668fb586bb 804:	Created pod: knative-operator-668fb586bb-d2zjh
12:20:42 Pod knative-operator-79bf74d66d-wxd9q 764:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-wxd9q to acto-cluster-8-worker
12:20:43 Pod knative-operator-79bf74d66d-wxd9q 766:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:20:46 Pod knative-operator-79bf74d66d-wxd9q 766:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.391152593s
12:20:46 Pod knative-operator-79bf74d66d-wxd9q 766:	Created container knative-operator
12:20:47 Pod knative-operator-79bf74d66d-wxd9q 766:	Started container knative-operator
12:20:57 Pod knative-operator-79bf74d66d-wxd9q 766:	Stopping container knative-operator
12:20:42 ReplicaSet knative-operator-79bf74d66d 761:	Created pod: knative-operator-79bf74d66d-wxd9q
12:20:57 ReplicaSet knative-operator-79bf74d66d 831:	Deleted pod: knative-operator-79bf74d66d-wxd9q
12:20:42 Deployment knative-operator 760:	Scaled up replica set knative-operator-79bf74d66d to 1
12:20:53 Deployment knative-operator 802:	Scaled up replica set knative-operator-668fb586bb to 1
12:20:57 Deployment knative-operator 818:	Scaled down replica set knative-operator-79bf74d66d to 0
12:48:30 Pod mt-broker-controller-56cc5dc5cc-2wr2s 12044:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-2wr2s to acto-cluster-8-worker
12:48:30 Pod mt-broker-controller-56cc5dc5cc-2wr2s 12047:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:48:30 Pod mt-broker-controller-56cc5dc5cc-2wr2s 12047:	Created container mt-broker-controller
12:48:31 Pod mt-broker-controller-56cc5dc5cc-2wr2s 12047:	Started container mt-broker-controller
12:52:33 Pod mt-broker-controller-56cc5dc5cc-2wr2s 12047:	Stopping container mt-broker-controller
12:27:11 Pod mt-broker-controller-56cc5dc5cc-6ddqd 3473:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-6ddqd to acto-cluster-8-worker
12:27:11 Pod mt-broker-controller-56cc5dc5cc-6ddqd 3475:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:27:14 Pod mt-broker-controller-56cc5dc5cc-6ddqd 3475:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.723562345s
12:27:14 Pod mt-broker-controller-56cc5dc5cc-6ddqd 3475:	Created container mt-broker-controller
12:27:14 Pod mt-broker-controller-56cc5dc5cc-6ddqd 3475:	Started container mt-broker-controller
12:31:15 Pod mt-broker-controller-56cc5dc5cc-6ddqd 3475:	Stopping container mt-broker-controller
12:33:16 Pod mt-broker-controller-56cc5dc5cc-fs77m 5719:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-fs77m to acto-cluster-8-worker3
12:33:17 Pod mt-broker-controller-56cc5dc5cc-fs77m 5722:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:33:22 Pod mt-broker-controller-56cc5dc5cc-fs77m 5722:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 4.798306918s
12:33:22 Pod mt-broker-controller-56cc5dc5cc-fs77m 5722:	Created container mt-broker-controller
12:33:22 Pod mt-broker-controller-56cc5dc5cc-fs77m 5722:	Started container mt-broker-controller
12:37:18 Pod mt-broker-controller-56cc5dc5cc-fs77m 5722:	Stopping container mt-broker-controller
12:21:21 Pod mt-broker-controller-56cc5dc5cc-ldbq4 1294:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-ldbq4 to acto-cluster-8-worker2
12:21:21 Pod mt-broker-controller-56cc5dc5cc-ldbq4 1297:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:21:28 Pod mt-broker-controller-56cc5dc5cc-ldbq4 1297:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 6.193925287s
12:21:28 Pod mt-broker-controller-56cc5dc5cc-ldbq4 1297:	Created container mt-broker-controller
12:21:28 Pod mt-broker-controller-56cc5dc5cc-ldbq4 1297:	Started container mt-broker-controller
12:25:22 Pod mt-broker-controller-56cc5dc5cc-ldbq4 1297:	Stopping container mt-broker-controller
12:42:40 Pod mt-broker-controller-56cc5dc5cc-qttcz 9867:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-qttcz to acto-cluster-8-worker2
12:42:41 Pod mt-broker-controller-56cc5dc5cc-qttcz 9872:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:42:41 Pod mt-broker-controller-56cc5dc5cc-qttcz 9872:	Created container mt-broker-controller
12:42:41 Pod mt-broker-controller-56cc5dc5cc-qttcz 9872:	Started container mt-broker-controller
12:46:42 Pod mt-broker-controller-56cc5dc5cc-qttcz 9872:	Stopping container mt-broker-controller
12:53:13 Pod mt-broker-controller-56cc5dc5cc-rg52m 14119:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-rg52m to acto-cluster-8-worker
12:53:13 Pod mt-broker-controller-56cc5dc5cc-rg52m 14124:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:53:13 Pod mt-broker-controller-56cc5dc5cc-rg52m 14124:	Created container mt-broker-controller
12:53:13 Pod mt-broker-controller-56cc5dc5cc-rg52m 14124:	Started container mt-broker-controller
12:37:57 Pod mt-broker-controller-56cc5dc5cc-zc47r 7789:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-zc47r to acto-cluster-8-worker2
12:37:58 Pod mt-broker-controller-56cc5dc5cc-zc47r 7792:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:37:58 Pod mt-broker-controller-56cc5dc5cc-zc47r 7792:	Created container mt-broker-controller
12:37:58 Pod mt-broker-controller-56cc5dc5cc-zc47r 7792:	Started container mt-broker-controller
12:42:01 Pod mt-broker-controller-56cc5dc5cc-zc47r 7792:	Stopping container mt-broker-controller
12:21:21 ReplicaSet mt-broker-controller-56cc5dc5cc 1292:	Created pod: mt-broker-controller-56cc5dc5cc-ldbq4
12:27:11 ReplicaSet mt-broker-controller-56cc5dc5cc 3470:	Created pod: mt-broker-controller-56cc5dc5cc-6ddqd
12:33:16 ReplicaSet mt-broker-controller-56cc5dc5cc 5717:	Created pod: mt-broker-controller-56cc5dc5cc-fs77m
12:37:57 ReplicaSet mt-broker-controller-56cc5dc5cc 7787:	Created pod: mt-broker-controller-56cc5dc5cc-zc47r
12:42:40 ReplicaSet mt-broker-controller-56cc5dc5cc 9866:	Created pod: mt-broker-controller-56cc5dc5cc-qttcz
12:48:30 ReplicaSet mt-broker-controller-56cc5dc5cc 12042:	Created pod: mt-broker-controller-56cc5dc5cc-2wr2s
12:53:13 ReplicaSet mt-broker-controller-56cc5dc5cc 14116:	Created pod: mt-broker-controller-56cc5dc5cc-rg52m
12:21:21 Deployment mt-broker-controller 1291:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:27:11 Deployment mt-broker-controller 3469:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:33:16 Deployment mt-broker-controller 5716:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:37:57 Deployment mt-broker-controller 7784:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:42:40 Deployment mt-broker-controller 9865:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:48:30 Deployment mt-broker-controller 12041:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:53:13 Deployment mt-broker-controller 14115:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:42:39 Pod mt-broker-filter-846dc966c5-8zsgp 9793:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-8zsgp to acto-cluster-8-worker3
12:42:40 Pod mt-broker-filter-846dc966c5-8zsgp 9796:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:42:40 Pod mt-broker-filter-846dc966c5-8zsgp 9796:	Created container filter
12:42:40 Pod mt-broker-filter-846dc966c5-8zsgp 9796:	Started container filter
12:46:42 Pod mt-broker-filter-846dc966c5-8zsgp 9796:	Stopping container filter
12:46:43 Pod mt-broker-filter-846dc966c5-8zsgp 9796:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:46:43 Pod mt-broker-filter-846dc966c5-8zsgp 9796:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:37:57 Pod mt-broker-filter-846dc966c5-927nw 7749:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-927nw to acto-cluster-8-worker3
12:37:57 Pod mt-broker-filter-846dc966c5-927nw 7752:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:37:57 Pod mt-broker-filter-846dc966c5-927nw 7752:	Created container filter
12:37:57 Pod mt-broker-filter-846dc966c5-927nw 7752:	Started container filter
12:37:57 Pod mt-broker-filter-846dc966c5-927nw 7752:	Readiness probe failed: Get "http://10.244.2.13:8080/healthz": dial tcp 10.244.2.13:8080: connect: connection refused
12:42:01 Pod mt-broker-filter-846dc966c5-927nw 7752:	Stopping container filter
12:53:12 Pod mt-broker-filter-846dc966c5-mpzdx 14081:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-mpzdx to acto-cluster-8-worker2
12:53:12 Pod mt-broker-filter-846dc966c5-mpzdx 14082:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:53:13 Pod mt-broker-filter-846dc966c5-mpzdx 14082:	Created container filter
12:53:13 Pod mt-broker-filter-846dc966c5-mpzdx 14082:	Started container filter
12:53:13 Pod mt-broker-filter-846dc966c5-mpzdx 14082:	Readiness probe failed: Get "http://10.244.3.20:8080/healthz": dial tcp 10.244.3.20:8080: connect: connection refused
12:33:16 Pod mt-broker-filter-846dc966c5-psth5 5673:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-psth5 to acto-cluster-8-worker3
12:33:16 Pod mt-broker-filter-846dc966c5-psth5 5676:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:33:19 Pod mt-broker-filter-846dc966c5-psth5 5676:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 2.716425182s
12:33:19 Pod mt-broker-filter-846dc966c5-psth5 5676:	Created container filter
12:33:19 Pod mt-broker-filter-846dc966c5-psth5 5676:	Started container filter
12:37:18 Pod mt-broker-filter-846dc966c5-psth5 5676:	Stopping container filter
12:37:20 Pod mt-broker-filter-846dc966c5-psth5 5676:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:37:20 Pod mt-broker-filter-846dc966c5-psth5 5676:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:27:10 Pod mt-broker-filter-846dc966c5-qb8f7 3419:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-qb8f7 to acto-cluster-8-worker2
12:27:10 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:27:14 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 3.858834135s
12:27:14 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Created container filter
12:27:14 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Started container filter
12:31:15 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Stopping container filter
12:31:16 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:31:16 Pod mt-broker-filter-846dc966c5-qb8f7 3422:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:21:20 Pod mt-broker-filter-846dc966c5-vcwdl 1257:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-vcwdl to acto-cluster-8-worker
12:21:20 Pod mt-broker-filter-846dc966c5-vcwdl 1261:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:21:30 Pod mt-broker-filter-846dc966c5-vcwdl 1261:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 9.275665072s
12:21:30 Pod mt-broker-filter-846dc966c5-vcwdl 1261:	Created container filter
12:21:30 Pod mt-broker-filter-846dc966c5-vcwdl 1261:	Started container filter
12:25:22 Pod mt-broker-filter-846dc966c5-vcwdl 1261:	Stopping container filter
12:48:29 Pod mt-broker-filter-846dc966c5-xhtdl 11992:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-xhtdl to acto-cluster-8-worker2
12:48:30 Pod mt-broker-filter-846dc966c5-xhtdl 11995:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:48:30 Pod mt-broker-filter-846dc966c5-xhtdl 11995:	Created container filter
12:48:30 Pod mt-broker-filter-846dc966c5-xhtdl 11995:	Started container filter
12:52:33 Pod mt-broker-filter-846dc966c5-xhtdl 11995:	Stopping container filter
12:21:20 ReplicaSet mt-broker-filter-846dc966c5 1255:	Created pod: mt-broker-filter-846dc966c5-vcwdl
12:27:10 ReplicaSet mt-broker-filter-846dc966c5 3417:	Created pod: mt-broker-filter-846dc966c5-qb8f7
12:33:16 ReplicaSet mt-broker-filter-846dc966c5 5671:	Created pod: mt-broker-filter-846dc966c5-psth5
12:37:57 ReplicaSet mt-broker-filter-846dc966c5 7747:	Created pod: mt-broker-filter-846dc966c5-927nw
12:42:39 ReplicaSet mt-broker-filter-846dc966c5 9791:	Created pod: mt-broker-filter-846dc966c5-8zsgp
12:48:29 ReplicaSet mt-broker-filter-846dc966c5 11990:	Created pod: mt-broker-filter-846dc966c5-xhtdl
12:53:12 ReplicaSet mt-broker-filter-846dc966c5 14078:	Created pod: mt-broker-filter-846dc966c5-mpzdx
12:21:20 Deployment mt-broker-filter 1254:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:27:10 Deployment mt-broker-filter 3416:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:33:16 Deployment mt-broker-filter 5670:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:37:57 Deployment mt-broker-filter 7746:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:42:39 Deployment mt-broker-filter 9790:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:48:29 Deployment mt-broker-filter 11989:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:53:12 Deployment mt-broker-filter 14077:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:21:20 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1275:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-6hqbv to acto-cluster-8-worker2
12:21:21 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:21:25 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 3.725180329s
12:21:25 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Created container ingress
12:21:25 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Started container ingress
12:21:25 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Readiness probe failed: Get "http://10.244.3.4:8080/healthz": dial tcp 10.244.3.4:8080: connect: connection refused
12:25:22 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Stopping container ingress
12:25:22 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:25:22 Pod mt-broker-ingress-6dbbfff4b9-6hqbv 1278:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:33:16 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5699:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-7bxvg to acto-cluster-8-worker3
12:33:17 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5702:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:33:17 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5702:	Created container ingress
12:33:17 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5702:	Started container ingress
12:37:18 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5702:	Stopping container ingress
12:37:18 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5702:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:37:18 Pod mt-broker-ingress-6dbbfff4b9-7bxvg 5702:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:53:12 Pod mt-broker-ingress-6dbbfff4b9-8v2tg 14099:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-8v2tg to acto-cluster-8-worker3
12:53:13 Pod mt-broker-ingress-6dbbfff4b9-8v2tg 14102:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:53:13 Pod mt-broker-ingress-6dbbfff4b9-8v2tg 14102:	Created container ingress
12:53:13 Pod mt-broker-ingress-6dbbfff4b9-8v2tg 14102:	Started container ingress
12:42:40 Pod mt-broker-ingress-6dbbfff4b9-b2k6r 9812:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-b2k6r to acto-cluster-8-worker3
12:42:40 Pod mt-broker-ingress-6dbbfff4b9-b2k6r 9816:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:42:40 Pod mt-broker-ingress-6dbbfff4b9-b2k6r 9816:	Created container ingress
12:42:41 Pod mt-broker-ingress-6dbbfff4b9-b2k6r 9816:	Started container ingress
12:46:42 Pod mt-broker-ingress-6dbbfff4b9-b2k6r 9816:	Stopping container ingress
12:48:29 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12022:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-np2r7 to acto-cluster-8-worker
12:48:30 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12025:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:48:33 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12025:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.681244533s
12:48:33 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12025:	Created container ingress
12:48:33 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12025:	Started container ingress
12:48:33 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12025:	Readiness probe failed: Get "http://10.244.1.16:8080/healthz": dial tcp 10.244.1.16:8080: connect: connection refused
12:52:33 Pod mt-broker-ingress-6dbbfff4b9-np2r7 12025:	Stopping container ingress
12:27:10 Pod mt-broker-ingress-6dbbfff4b9-pqdqh 3438:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-pqdqh to acto-cluster-8-worker3
12:27:11 Pod mt-broker-ingress-6dbbfff4b9-pqdqh 3441:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:27:15 Pod mt-broker-ingress-6dbbfff4b9-pqdqh 3441:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 4.135747169s
12:27:15 Pod mt-broker-ingress-6dbbfff4b9-pqdqh 3441:	Created container ingress
12:27:15 Pod mt-broker-ingress-6dbbfff4b9-pqdqh 3441:	Started container ingress
12:31:15 Pod mt-broker-ingress-6dbbfff4b9-pqdqh 3441:	Stopping container ingress
12:37:57 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7768:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-xvmfq to acto-cluster-8-worker3
12:37:58 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7772:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:37:58 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7772:	Created container ingress
12:37:58 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7772:	Started container ingress
12:42:01 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7772:	Stopping container ingress
12:42:01 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7772:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:42:01 Pod mt-broker-ingress-6dbbfff4b9-xvmfq 7772:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:21:20 ReplicaSet mt-broker-ingress-6dbbfff4b9 1273:	Created pod: mt-broker-ingress-6dbbfff4b9-6hqbv
12:27:10 ReplicaSet mt-broker-ingress-6dbbfff4b9 3436:	Created pod: mt-broker-ingress-6dbbfff4b9-pqdqh
12:33:16 ReplicaSet mt-broker-ingress-6dbbfff4b9 5697:	Created pod: mt-broker-ingress-6dbbfff4b9-7bxvg
12:37:57 ReplicaSet mt-broker-ingress-6dbbfff4b9 7766:	Created pod: mt-broker-ingress-6dbbfff4b9-xvmfq
12:42:40 ReplicaSet mt-broker-ingress-6dbbfff4b9 9810:	Created pod: mt-broker-ingress-6dbbfff4b9-b2k6r
12:48:29 ReplicaSet mt-broker-ingress-6dbbfff4b9 12020:	Created pod: mt-broker-ingress-6dbbfff4b9-np2r7
12:53:12 ReplicaSet mt-broker-ingress-6dbbfff4b9 14097:	Created pod: mt-broker-ingress-6dbbfff4b9-8v2tg
12:21:20 Deployment mt-broker-ingress 1272:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:27:10 Deployment mt-broker-ingress 3435:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:33:16 Deployment mt-broker-ingress 5696:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:37:57 Deployment mt-broker-ingress 7765:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:42:40 Deployment mt-broker-ingress 9809:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:48:29 Deployment mt-broker-ingress 12019:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:53:12 Deployment mt-broker-ingress 14096:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:48:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-cr4vs 12077:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-cr4vs to acto-cluster-8-worker2
12:48:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-cr4vs 12079:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:48:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-cr4vs 12079:	Created container migrate
12:48:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-cr4vs 12079:	Started container migrate
12:53:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-f977z 14153:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-f977z to acto-cluster-8-worker2
12:53:14 Pod storage-version-migration-eventing-eventing-1.6.0--1-f977z 14155:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:53:14 Pod storage-version-migration-eventing-eventing-1.6.0--1-f977z 14155:	Created container migrate
12:53:14 Pod storage-version-migration-eventing-eventing-1.6.0--1-f977z 14155:	Started container migrate
12:37:58 Pod storage-version-migration-eventing-eventing-1.6.0--1-hvwfx 7821:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-hvwfx to acto-cluster-8-worker2
12:37:59 Pod storage-version-migration-eventing-eventing-1.6.0--1-hvwfx 7823:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:38:01 Pod storage-version-migration-eventing-eventing-1.6.0--1-hvwfx 7823:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.520660988s
12:38:01 Pod storage-version-migration-eventing-eventing-1.6.0--1-hvwfx 7823:	Created container migrate
12:38:02 Pod storage-version-migration-eventing-eventing-1.6.0--1-hvwfx 7823:	Started container migrate
12:21:21 Pod storage-version-migration-eventing-eventing-1.6.0--1-kx9d7 1317:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-kx9d7 to acto-cluster-8-worker3
12:21:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-kx9d7 1319:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:21:26 Pod storage-version-migration-eventing-eventing-1.6.0--1-kx9d7 1319:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 3.906046201s
12:21:26 Pod storage-version-migration-eventing-eventing-1.6.0--1-kx9d7 1319:	Created container migrate
12:21:26 Pod storage-version-migration-eventing-eventing-1.6.0--1-kx9d7 1319:	Started container migrate
12:42:41 Pod storage-version-migration-eventing-eventing-1.6.0--1-l6tfk 9893:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-l6tfk to acto-cluster-8-worker2
12:42:42 Pod storage-version-migration-eventing-eventing-1.6.0--1-l6tfk 9895:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:42:42 Pod storage-version-migration-eventing-eventing-1.6.0--1-l6tfk 9895:	Created container migrate
12:42:42 Pod storage-version-migration-eventing-eventing-1.6.0--1-l6tfk 9895:	Started container migrate
12:33:17 Pod storage-version-migration-eventing-eventing-1.6.0--1-pv5gp 5741:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-pv5gp to acto-cluster-8-worker3
12:33:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-pv5gp 5744:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:33:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-pv5gp 5744:	Created container migrate
12:33:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-pv5gp 5744:	Started container migrate
12:27:11 Pod storage-version-migration-eventing-eventing-1.6.0--1-svbgb 3501:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-svbgb to acto-cluster-8-worker3
12:27:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-svbgb 3504:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:27:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-svbgb 3504:	Created container migrate
12:27:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-svbgb 3504:	Started container migrate
12:21:21 Job storage-version-migration-eventing-eventing-1.6.0 1315:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-kx9d7
12:21:32 Job storage-version-migration-eventing-eventing-1.6.0 1322:	Job completed
12:27:11 Job storage-version-migration-eventing-eventing-1.6.0 3500:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-svbgb
12:27:18 Job storage-version-migration-eventing-eventing-1.6.0 3505:	Job completed
12:33:17 Job storage-version-migration-eventing-eventing-1.6.0 5740:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-pv5gp
12:33:24 Job storage-version-migration-eventing-eventing-1.6.0 5746:	Job completed
12:37:58 Job storage-version-migration-eventing-eventing-1.6.0 7820:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-hvwfx
12:38:07 Job storage-version-migration-eventing-eventing-1.6.0 7826:	Job completed
12:42:41 Job storage-version-migration-eventing-eventing-1.6.0 9892:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-l6tfk
12:42:47 Job storage-version-migration-eventing-eventing-1.6.0 9897:	Job completed
12:48:31 Job storage-version-migration-eventing-eventing-1.6.0 12075:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-cr4vs
12:48:37 Job storage-version-migration-eventing-eventing-1.6.0 12081:	Job completed
12:53:13 Job storage-version-migration-eventing-eventing-1.6.0 14151:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-f977z
12:53:20 Job storage-version-migration-eventing-eventing-1.6.0 14157:	Job completed
12:20:59 KnativeEventing test-cluster 853:	Updated "test-cluster" finalizers
12:26:51 KnativeEventing test-cluster 3102:	Updated "test-cluster" finalizers
12:32:57 KnativeEventing test-cluster 5324:	Updated "test-cluster" finalizers
12:37:37 KnativeEventing test-cluster 7364:	Updated "test-cluster" finalizers
12:42:20 KnativeEventing test-cluster 9439:	Updated "test-cluster" finalizers
12:48:11 KnativeEventing test-cluster 11635:	Updated "test-cluster" finalizers
12:52:52 KnativeEventing test-cluster 13699:	Updated "test-cluster" finalizers
