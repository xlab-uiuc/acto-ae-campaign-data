12:21:55 HorizontalPodAutoscaler broker-filter-hpa 1290:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:55 HorizontalPodAutoscaler broker-filter-hpa 1290:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:45 HorizontalPodAutoscaler broker-filter-hpa 3493:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:45 HorizontalPodAutoscaler broker-filter-hpa 3493:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:05 HorizontalPodAutoscaler broker-filter-hpa 6246:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:05 HorizontalPodAutoscaler broker-filter-hpa 6246:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:46 HorizontalPodAutoscaler broker-filter-hpa 8327:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:46 HorizontalPodAutoscaler broker-filter-hpa 8327:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:36 HorizontalPodAutoscaler broker-filter-hpa 10532:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:36 HorizontalPodAutoscaler broker-filter-hpa 10532:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:18 HorizontalPodAutoscaler broker-filter-hpa 12609:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:18 HorizontalPodAutoscaler broker-filter-hpa 12609:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:55 HorizontalPodAutoscaler broker-ingress-hpa 1289:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:55 HorizontalPodAutoscaler broker-ingress-hpa 1289:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:45 HorizontalPodAutoscaler broker-ingress-hpa 3492:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:45 HorizontalPodAutoscaler broker-ingress-hpa 3492:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:05 HorizontalPodAutoscaler broker-ingress-hpa 6244:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:38:05 HorizontalPodAutoscaler broker-ingress-hpa 6244:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:46 HorizontalPodAutoscaler broker-ingress-hpa 8323:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:46 HorizontalPodAutoscaler broker-ingress-hpa 8323:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:35 HorizontalPodAutoscaler broker-ingress-hpa 10529:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:35 HorizontalPodAutoscaler broker-ingress-hpa 10529:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:18 HorizontalPodAutoscaler broker-ingress-hpa 12602:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:18 HorizontalPodAutoscaler broker-ingress-hpa 12602:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:24 Pod eventing-controller-58f99d9cf9-vwg46 3299:	0/4 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 3 node(s) didn't match Pod's node affinity/selector.
12:36:08 Pod eventing-controller-58f99d9cf9-vwg46 5539:	skip schedule deleting pod: knative-eventing/eventing-controller-58f99d9cf9-vwg46
12:27:24 ReplicaSet eventing-controller-58f99d9cf9 3296:	Created pod: eventing-controller-58f99d9cf9-vwg46
12:37:44 Pod eventing-controller-6c78bb8c7f-fh8px 6020:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-fh8px to acto-cluster-9-worker2
12:37:44 Pod eventing-controller-6c78bb8c7f-fh8px 6022:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:37:44 Pod eventing-controller-6c78bb8c7f-fh8px 6022:	Created container eventing-controller
12:37:45 Pod eventing-controller-6c78bb8c7f-fh8px 6022:	Started container eventing-controller
12:41:56 Pod eventing-controller-6c78bb8c7f-fh8px 6022:	Stopping container eventing-controller
12:52:57 Pod eventing-controller-6c78bb8c7f-nz5xx 12367:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-nz5xx to acto-cluster-9-worker3
12:52:57 Pod eventing-controller-6c78bb8c7f-nz5xx 12369:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:52:57 Pod eventing-controller-6c78bb8c7f-nz5xx 12369:	Created container eventing-controller
12:52:57 Pod eventing-controller-6c78bb8c7f-nz5xx 12369:	Started container eventing-controller
12:48:14 Pod eventing-controller-6c78bb8c7f-wpjx7 10296:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-wpjx7 to acto-cluster-9-worker3
12:48:15 Pod eventing-controller-6c78bb8c7f-wpjx7 10298:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:48:18 Pod eventing-controller-6c78bb8c7f-wpjx7 10298:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.773096656s
12:48:18 Pod eventing-controller-6c78bb8c7f-wpjx7 10298:	Created container eventing-controller
12:48:18 Pod eventing-controller-6c78bb8c7f-wpjx7 10298:	Started container eventing-controller
12:52:28 Pod eventing-controller-6c78bb8c7f-wpjx7 10298:	Stopping container eventing-controller
12:42:25 Pod eventing-controller-6c78bb8c7f-zkd8q 8091:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-zkd8q to acto-cluster-9-worker2
12:42:25 Pod eventing-controller-6c78bb8c7f-zkd8q 8093:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:42:25 Pod eventing-controller-6c78bb8c7f-zkd8q 8093:	Created container eventing-controller
12:42:25 Pod eventing-controller-6c78bb8c7f-zkd8q 8093:	Started container eventing-controller
12:46:39 Pod eventing-controller-6c78bb8c7f-zkd8q 8093:	Stopping container eventing-controller
12:37:44 ReplicaSet eventing-controller-6c78bb8c7f 6017:	Created pod: eventing-controller-6c78bb8c7f-fh8px
12:42:25 ReplicaSet eventing-controller-6c78bb8c7f 8088:	Created pod: eventing-controller-6c78bb8c7f-zkd8q
12:48:14 ReplicaSet eventing-controller-6c78bb8c7f 10293:	Created pod: eventing-controller-6c78bb8c7f-wpjx7
12:52:57 ReplicaSet eventing-controller-6c78bb8c7f 12364:	Created pod: eventing-controller-6c78bb8c7f-nz5xx
12:21:33 Pod eventing-controller-86d49cf697-wmss4 1092:	Successfully assigned knative-eventing/eventing-controller-86d49cf697-wmss4 to acto-cluster-9-worker2
12:21:33 Pod eventing-controller-86d49cf697-wmss4 1095:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:21:37 Pod eventing-controller-86d49cf697-wmss4 1095:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.98421546s
12:21:37 Pod eventing-controller-86d49cf697-wmss4 1095:	Created container eventing-controller
12:21:38 Pod eventing-controller-86d49cf697-wmss4 1095:	Started container eventing-controller
12:25:46 Pod eventing-controller-86d49cf697-wmss4 1095:	Stopping container eventing-controller
12:21:33 ReplicaSet eventing-controller-86d49cf697 1090:	Created pod: eventing-controller-86d49cf697-wmss4
12:21:33 Deployment eventing-controller 1089:	Scaled up replica set eventing-controller-86d49cf697 to 1
12:27:24 Deployment eventing-controller 3295:	Scaled up replica set eventing-controller-58f99d9cf9 to 1
12:37:44 Deployment eventing-controller 6016:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:42:25 Deployment eventing-controller 8087:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:48:14 Deployment eventing-controller 10292:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:52:57 Deployment eventing-controller 12363:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:27:25 Pod eventing-webhook-5755489569-5p2mf 3320:	Successfully assigned knative-eventing/eventing-webhook-5755489569-5p2mf to acto-cluster-9-worker3
12:27:25 Pod eventing-webhook-5755489569-5p2mf 3322:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:27:28 Pod eventing-webhook-5755489569-5p2mf 3322:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.656590054s
12:27:28 Pod eventing-webhook-5755489569-5p2mf 3322:	Created container eventing-webhook
12:27:29 Pod eventing-webhook-5755489569-5p2mf 3322:	Started container eventing-webhook
12:36:08 Pod eventing-webhook-5755489569-5p2mf 3322:	Liveness probe failed: Get "https://10.244.1.6:8443/": remote error: tls: unrecognized name
12:36:08 Pod eventing-webhook-5755489569-5p2mf 3322:	Readiness probe failed: Get "https://10.244.1.6:8443/": remote error: tls: unrecognized name
12:36:08 Pod eventing-webhook-5755489569-5p2mf 3322:	Stopping container eventing-webhook
12:21:34 Pod eventing-webhook-5755489569-6qfjs 1117:	Successfully assigned knative-eventing/eventing-webhook-5755489569-6qfjs to acto-cluster-9-worker
12:21:34 Pod eventing-webhook-5755489569-6qfjs 1121:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:21:42 Pod eventing-webhook-5755489569-6qfjs 1121:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 7.894280335s
12:21:42 Pod eventing-webhook-5755489569-6qfjs 1121:	Created container eventing-webhook
12:21:43 Pod eventing-webhook-5755489569-6qfjs 1121:	Started container eventing-webhook
12:25:45 Pod eventing-webhook-5755489569-6qfjs 1121:	Liveness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:25:45 Pod eventing-webhook-5755489569-6qfjs 1121:	Readiness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:25:45 Pod eventing-webhook-5755489569-6qfjs 1121:	Stopping container eventing-webhook
12:48:15 Pod eventing-webhook-5755489569-jcfmh 10319:	Successfully assigned knative-eventing/eventing-webhook-5755489569-jcfmh to acto-cluster-9-worker2
12:48:16 Pod eventing-webhook-5755489569-jcfmh 10322:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:48:19 Pod eventing-webhook-5755489569-jcfmh 10322:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.725484942s
12:48:19 Pod eventing-webhook-5755489569-jcfmh 10322:	Created container eventing-webhook
12:48:19 Pod eventing-webhook-5755489569-jcfmh 10322:	Started container eventing-webhook
12:48:20 Pod eventing-webhook-5755489569-jcfmh 10322:	Readiness probe failed: Get "https://10.244.3.11:8443/": dial tcp 10.244.3.11:8443: connect: connection refused
12:52:27 Pod eventing-webhook-5755489569-jcfmh 10322:	Readiness probe failed: Get "https://10.244.3.11:8443/": remote error: tls: unrecognized name
12:52:27 Pod eventing-webhook-5755489569-jcfmh 10322:	Liveness probe failed: Get "https://10.244.3.11:8443/": remote error: tls: unrecognized name
12:52:27 Pod eventing-webhook-5755489569-jcfmh 10322:	Stopping container eventing-webhook
12:52:58 Pod eventing-webhook-5755489569-kgfz4 12390:	Successfully assigned knative-eventing/eventing-webhook-5755489569-kgfz4 to acto-cluster-9-worker
12:52:58 Pod eventing-webhook-5755489569-kgfz4 12394:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:52:58 Pod eventing-webhook-5755489569-kgfz4 12394:	Created container eventing-webhook
12:52:59 Pod eventing-webhook-5755489569-kgfz4 12394:	Started container eventing-webhook
12:53:00 Pod eventing-webhook-5755489569-kgfz4 12394:	Readiness probe failed: Get "https://10.244.2.17:8443/": dial tcp 10.244.2.17:8443: connect: connection refused
12:42:25 Pod eventing-webhook-5755489569-kp9kl 8119:	Successfully assigned knative-eventing/eventing-webhook-5755489569-kp9kl to acto-cluster-9-worker
12:42:26 Pod eventing-webhook-5755489569-kp9kl 8122:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:42:26 Pod eventing-webhook-5755489569-kp9kl 8122:	Created container eventing-webhook
12:42:27 Pod eventing-webhook-5755489569-kp9kl 8122:	Started container eventing-webhook
12:46:37 Pod eventing-webhook-5755489569-kp9kl 8122:	Readiness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:46:37 Pod eventing-webhook-5755489569-kp9kl 8122:	Liveness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:46:38 Pod eventing-webhook-5755489569-kp9kl 8122:	Stopping container eventing-webhook
12:21:34 ReplicaSet eventing-webhook-5755489569 1115:	Created pod: eventing-webhook-5755489569-6qfjs
12:27:25 ReplicaSet eventing-webhook-5755489569 3318:	Created pod: eventing-webhook-5755489569-5p2mf
12:42:25 ReplicaSet eventing-webhook-5755489569 8117:	Created pod: eventing-webhook-5755489569-kp9kl
12:48:15 ReplicaSet eventing-webhook-5755489569 10317:	Created pod: eventing-webhook-5755489569-jcfmh
12:52:58 ReplicaSet eventing-webhook-5755489569 12388:	Created pod: eventing-webhook-5755489569-kgfz4
12:37:45 Pod eventing-webhook-796779bd9-75rtw 6048:	Successfully assigned knative-eventing/eventing-webhook-796779bd9-75rtw to acto-cluster-9-worker3
12:37:46 Pod eventing-webhook-796779bd9-75rtw 6052:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:37:46 Pod eventing-webhook-796779bd9-75rtw 6052:	Created container eventing-webhook
12:37:46 Pod eventing-webhook-796779bd9-75rtw 6052:	Started container eventing-webhook
12:37:47 Pod eventing-webhook-796779bd9-75rtw 6052:	Readiness probe failed: Get "https://10.244.1.8:8443/": remote error: tls: unrecognized name
12:41:55 Pod eventing-webhook-796779bd9-75rtw 6052:	Liveness probe failed: Get "https://10.244.1.8:8443/": remote error: tls: unrecognized name
12:41:55 Pod eventing-webhook-796779bd9-75rtw 6052:	Stopping container eventing-webhook
12:37:45 ReplicaSet eventing-webhook-796779bd9 6046:	Created pod: eventing-webhook-796779bd9-75rtw
12:21:33 PodDisruptionBudget eventing-webhook 1109:	No matching pods found
12:21:34 Deployment eventing-webhook 1114:	Scaled up replica set eventing-webhook-5755489569 to 1
12:21:48 HorizontalPodAutoscaler eventing-webhook 1108:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:48 HorizontalPodAutoscaler eventing-webhook 1108:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:25:45 PodDisruptionBudget eventing-webhook 1572:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:27:24 PodDisruptionBudget eventing-webhook 3313:	No matching pods found
12:27:25 Deployment eventing-webhook 3317:	Scaled up replica set eventing-webhook-5755489569 to 1
12:27:39 HorizontalPodAutoscaler eventing-webhook 3312:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:39 HorizontalPodAutoscaler eventing-webhook 3312:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:36:08 PodDisruptionBudget eventing-webhook 3716:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:37:44 PodDisruptionBudget eventing-webhook 6038:	No matching pods found
12:37:45 Deployment eventing-webhook 6045:	Scaled up replica set eventing-webhook-796779bd9 to 1
12:37:59 HorizontalPodAutoscaler eventing-webhook 6035:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:37:59 HorizontalPodAutoscaler eventing-webhook 6035:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:41:55 PodDisruptionBudget eventing-webhook 6498:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:42:25 PodDisruptionBudget eventing-webhook 8111:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:42:25 Deployment eventing-webhook 8116:	Scaled up replica set eventing-webhook-5755489569 to 1
12:42:40 HorizontalPodAutoscaler eventing-webhook 8107:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:40 HorizontalPodAutoscaler eventing-webhook 8107:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:15 PodDisruptionBudget eventing-webhook 10312:	No matching pods found
12:48:15 Deployment eventing-webhook 10316:	Scaled up replica set eventing-webhook-5755489569 to 1
12:48:30 HorizontalPodAutoscaler eventing-webhook 10310:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:30 HorizontalPodAutoscaler eventing-webhook 10310:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:27 PodDisruptionBudget eventing-webhook 10769:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:52:58 Deployment eventing-webhook 12387:	Scaled up replica set eventing-webhook-5755489569 to 1
12:53:12 HorizontalPodAutoscaler eventing-webhook 12381:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:12 HorizontalPodAutoscaler eventing-webhook 12381:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:48:18 Pod imc-controller-567b4f565b-869wh 10356:	Successfully assigned knative-eventing/imc-controller-567b4f565b-869wh to acto-cluster-9-worker
12:48:18 Pod imc-controller-567b4f565b-869wh 10359:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:48:18 Pod imc-controller-567b4f565b-869wh 10359:	Created container controller
12:48:19 Pod imc-controller-567b4f565b-869wh 10359:	Started container controller
12:48:19 Pod imc-controller-567b4f565b-869wh 10359:	Readiness probe failed: Get "https://10.244.2.13:8443/": dial tcp 10.244.2.13:8443: connect: connection refused
12:48:19 Pod imc-controller-567b4f565b-869wh 10359:	Readiness probe failed: Get "https://10.244.2.13:8443/": remote error: tls: unrecognized name
12:52:24 Pod imc-controller-567b4f565b-869wh 10359:	Liveness probe failed: Get "https://10.244.2.13:8443/": remote error: tls: unrecognized name
12:52:25 Pod imc-controller-567b4f565b-869wh 10359:	Stopping container controller
12:37:47 Pod imc-controller-567b4f565b-ch8nb 6126:	Successfully assigned knative-eventing/imc-controller-567b4f565b-ch8nb to acto-cluster-9-worker
12:37:48 Pod imc-controller-567b4f565b-ch8nb 6129:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:37:51 Pod imc-controller-567b4f565b-ch8nb 6129:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.694214848s
12:37:51 Pod imc-controller-567b4f565b-ch8nb 6129:	Created container controller
12:37:51 Pod imc-controller-567b4f565b-ch8nb 6129:	Started container controller
12:41:52 Pod imc-controller-567b4f565b-ch8nb 6129:	Readiness probe failed: Get "https://10.244.2.9:8443/": remote error: tls: unrecognized name
12:41:52 Pod imc-controller-567b4f565b-ch8nb 6129:	Liveness probe failed: Get "https://10.244.2.9:8443/": remote error: tls: unrecognized name
12:41:53 Pod imc-controller-567b4f565b-ch8nb 6129:	Stopping container controller
12:21:37 Pod imc-controller-567b4f565b-gz2js 1163:	Successfully assigned knative-eventing/imc-controller-567b4f565b-gz2js to acto-cluster-9-worker3
12:21:38 Pod imc-controller-567b4f565b-gz2js 1165:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:21:41 Pod imc-controller-567b4f565b-gz2js 1165:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.934293233s
12:21:41 Pod imc-controller-567b4f565b-gz2js 1165:	Created container controller
12:21:41 Pod imc-controller-567b4f565b-gz2js 1165:	Started container controller
12:25:42 Pod imc-controller-567b4f565b-gz2js 1165:	Readiness probe failed: Get "https://10.244.1.2:8443/": remote error: tls: unrecognized name
12:25:42 Pod imc-controller-567b4f565b-gz2js 1165:	Liveness probe failed: Get "https://10.244.1.2:8443/": remote error: tls: unrecognized name
12:25:43 Pod imc-controller-567b4f565b-gz2js 1165:	Stopping container controller
12:42:28 Pod imc-controller-567b4f565b-sq6r7 8207:	Successfully assigned knative-eventing/imc-controller-567b4f565b-sq6r7 to acto-cluster-9-worker3
12:42:29 Pod imc-controller-567b4f565b-sq6r7 8210:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:42:29 Pod imc-controller-567b4f565b-sq6r7 8210:	Created container controller
12:42:29 Pod imc-controller-567b4f565b-sq6r7 8210:	Started container controller
12:46:35 Pod imc-controller-567b4f565b-sq6r7 8210:	Liveness probe failed: Get "https://10.244.1.11:8443/": remote error: tls: unrecognized name
12:46:35 Pod imc-controller-567b4f565b-sq6r7 8210:	Readiness probe failed: Get "https://10.244.1.11:8443/": remote error: tls: unrecognized name
12:46:36 Pod imc-controller-567b4f565b-sq6r7 8210:	Stopping container controller
12:53:00 Pod imc-controller-567b4f565b-t5sl8 12474:	Successfully assigned knative-eventing/imc-controller-567b4f565b-t5sl8 to acto-cluster-9-worker2
12:53:01 Pod imc-controller-567b4f565b-t5sl8 12477:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:53:01 Pod imc-controller-567b4f565b-t5sl8 12477:	Created container controller
12:53:01 Pod imc-controller-567b4f565b-t5sl8 12477:	Started container controller
12:53:01 Pod imc-controller-567b4f565b-t5sl8 12477:	Readiness probe failed: Get "https://10.244.3.14:8443/": remote error: tls: unrecognized name
12:27:27 Pod imc-controller-567b4f565b-xgjf7 3351:	Successfully assigned knative-eventing/imc-controller-567b4f565b-xgjf7 to acto-cluster-9-worker2
12:27:28 Pod imc-controller-567b4f565b-xgjf7 3355:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:27:31 Pod imc-controller-567b4f565b-xgjf7 3355:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.744710597s
12:27:31 Pod imc-controller-567b4f565b-xgjf7 3355:	Created container controller
12:27:31 Pod imc-controller-567b4f565b-xgjf7 3355:	Started container controller
12:36:04 Pod imc-controller-567b4f565b-xgjf7 3355:	Readiness probe failed: Get "https://10.244.3.3:8443/": remote error: tls: unrecognized name
12:36:04 Pod imc-controller-567b4f565b-xgjf7 3355:	Liveness probe failed: Get "https://10.244.3.3:8443/": remote error: tls: unrecognized name
12:36:05 Pod imc-controller-567b4f565b-xgjf7 3355:	Stopping container controller
12:21:37 ReplicaSet imc-controller-567b4f565b 1160:	Created pod: imc-controller-567b4f565b-gz2js
12:27:27 ReplicaSet imc-controller-567b4f565b 3349:	Created pod: imc-controller-567b4f565b-xgjf7
12:37:47 ReplicaSet imc-controller-567b4f565b 6125:	Created pod: imc-controller-567b4f565b-ch8nb
12:42:28 ReplicaSet imc-controller-567b4f565b 8205:	Created pod: imc-controller-567b4f565b-sq6r7
12:48:18 ReplicaSet imc-controller-567b4f565b 10354:	Created pod: imc-controller-567b4f565b-869wh
12:53:00 ReplicaSet imc-controller-567b4f565b 12472:	Created pod: imc-controller-567b4f565b-t5sl8
12:21:37 Deployment imc-controller 1159:	Scaled up replica set imc-controller-567b4f565b to 1
12:27:27 Deployment imc-controller 3348:	Scaled up replica set imc-controller-567b4f565b to 1
12:37:47 Deployment imc-controller 6124:	Scaled up replica set imc-controller-567b4f565b to 1
12:42:28 Deployment imc-controller 8204:	Scaled up replica set imc-controller-567b4f565b to 1
12:48:18 Deployment imc-controller 10353:	Scaled up replica set imc-controller-567b4f565b to 1
12:53:00 Deployment imc-controller 12471:	Scaled up replica set imc-controller-567b4f565b to 1
12:42:29 Pod imc-dispatcher-545bcb44c5-9x5t9 8229:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-9x5t9 to acto-cluster-9-worker3
12:42:29 Pod imc-dispatcher-545bcb44c5-9x5t9 8233:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:42:32 Pod imc-dispatcher-545bcb44c5-9x5t9 8233:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.779739461s
12:42:32 Pod imc-dispatcher-545bcb44c5-9x5t9 8233:	Created container dispatcher
12:42:32 Pod imc-dispatcher-545bcb44c5-9x5t9 8233:	Started container dispatcher
12:46:35 Pod imc-dispatcher-545bcb44c5-9x5t9 8233:	Stopping container dispatcher
12:27:28 Pod imc-dispatcher-545bcb44c5-hp4mh 3375:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-hp4mh to acto-cluster-9-worker
12:27:28 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:27:28 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Created container dispatcher
12:27:29 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Started container dispatcher
12:27:29 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Readiness probe failed: Get "http://10.244.2.7:8080/healthz": dial tcp 10.244.2.7:8080: connect: connection refused
12:36:05 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Stopping container dispatcher
12:36:07 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Readiness probe failed: Get "http://10.244.2.7:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:36:07 Pod imc-dispatcher-545bcb44c5-hp4mh 3379:	Liveness probe failed: Get "http://10.244.2.7:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:21:38 Pod imc-dispatcher-545bcb44c5-qtb9w 1192:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-qtb9w to acto-cluster-9-worker
12:21:38 Pod imc-dispatcher-545bcb44c5-qtb9w 1195:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:21:45 Pod imc-dispatcher-545bcb44c5-qtb9w 1195:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 6.503467524s
12:21:45 Pod imc-dispatcher-545bcb44c5-qtb9w 1195:	Created container dispatcher
12:21:45 Pod imc-dispatcher-545bcb44c5-qtb9w 1195:	Started container dispatcher
12:25:42 Pod imc-dispatcher-545bcb44c5-qtb9w 1195:	Stopping container dispatcher
12:53:01 Pod imc-dispatcher-545bcb44c5-rhq4s 12504:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-rhq4s to acto-cluster-9-worker2
12:53:01 Pod imc-dispatcher-545bcb44c5-rhq4s 12507:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:53:01 Pod imc-dispatcher-545bcb44c5-rhq4s 12507:	Created container dispatcher
12:53:02 Pod imc-dispatcher-545bcb44c5-rhq4s 12507:	Started container dispatcher
12:48:18 Pod imc-dispatcher-545bcb44c5-rj2qf 10402:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-rj2qf to acto-cluster-9-worker2
12:48:19 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:48:22 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.743271384s
12:48:22 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Created container dispatcher
12:48:22 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Started container dispatcher
12:52:24 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Stopping container dispatcher
12:52:24 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Readiness probe failed: Get "http://10.244.3.12:8080/healthz": dial tcp 10.244.3.12:8080: connect: connection refused
12:52:24 Pod imc-dispatcher-545bcb44c5-rj2qf 10406:	Liveness probe failed: Get "http://10.244.3.12:8080/healthz": dial tcp 10.244.3.12:8080: connect: connection refused
12:37:48 Pod imc-dispatcher-545bcb44c5-xnqpt 6155:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-xnqpt to acto-cluster-9-worker
12:37:48 Pod imc-dispatcher-545bcb44c5-xnqpt 6159:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:37:48 Pod imc-dispatcher-545bcb44c5-xnqpt 6159:	Created container dispatcher
12:37:49 Pod imc-dispatcher-545bcb44c5-xnqpt 6159:	Started container dispatcher
12:41:52 Pod imc-dispatcher-545bcb44c5-xnqpt 6159:	Stopping container dispatcher
12:21:38 ReplicaSet imc-dispatcher-545bcb44c5 1190:	Created pod: imc-dispatcher-545bcb44c5-qtb9w
12:27:28 ReplicaSet imc-dispatcher-545bcb44c5 3373:	Created pod: imc-dispatcher-545bcb44c5-hp4mh
12:37:48 ReplicaSet imc-dispatcher-545bcb44c5 6152:	Created pod: imc-dispatcher-545bcb44c5-xnqpt
12:42:29 ReplicaSet imc-dispatcher-545bcb44c5 8227:	Created pod: imc-dispatcher-545bcb44c5-9x5t9
12:48:18 ReplicaSet imc-dispatcher-545bcb44c5 10399:	Created pod: imc-dispatcher-545bcb44c5-rj2qf
12:53:01 ReplicaSet imc-dispatcher-545bcb44c5 12500:	Created pod: imc-dispatcher-545bcb44c5-rhq4s
12:21:38 Deployment imc-dispatcher 1189:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:27:28 Deployment imc-dispatcher 3372:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:37:48 Deployment imc-dispatcher 6151:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:42:29 Deployment imc-dispatcher 8226:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:48:18 Deployment imc-dispatcher 10398:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:53:01 Deployment imc-dispatcher 12499:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:21:14 Pod knative-operator-668fb586bb-qkw72 827:	Successfully assigned knative-eventing/knative-operator-668fb586bb-qkw72 to acto-cluster-9-worker
12:21:15 Pod knative-operator-668fb586bb-qkw72 831:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:21:15 Pod knative-operator-668fb586bb-qkw72 831:	Created container knative-operator
12:21:15 Pod knative-operator-668fb586bb-qkw72 831:	Started container knative-operator
12:21:14 ReplicaSet knative-operator-668fb586bb 824:	Created pod: knative-operator-668fb586bb-qkw72
12:21:04 Pod knative-operator-79bf74d66d-t95vl 785:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-t95vl to acto-cluster-9-worker
12:21:05 Pod knative-operator-79bf74d66d-t95vl 787:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:08 Pod knative-operator-79bf74d66d-t95vl 787:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.031780453s
12:21:08 Pod knative-operator-79bf74d66d-t95vl 787:	Created container knative-operator
12:21:08 Pod knative-operator-79bf74d66d-t95vl 787:	Started container knative-operator
12:21:16 Pod knative-operator-79bf74d66d-t95vl 787:	Stopping container knative-operator
12:21:04 ReplicaSet knative-operator-79bf74d66d 782:	Created pod: knative-operator-79bf74d66d-t95vl
12:21:16 ReplicaSet knative-operator-79bf74d66d 849:	Deleted pod: knative-operator-79bf74d66d-t95vl
12:21:04 Deployment knative-operator 781:	Scaled up replica set knative-operator-79bf74d66d to 1
12:21:14 Deployment knative-operator 823:	Scaled up replica set knative-operator-668fb586bb to 1
12:21:16 Deployment knative-operator 837:	Scaled down replica set knative-operator-79bf74d66d to 0
12:48:20 Pod mt-broker-controller-56cc5dc5cc-n9h2c 10510:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-n9h2c to acto-cluster-9-worker
12:48:21 Pod mt-broker-controller-56cc5dc5cc-n9h2c 10513:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:48:21 Pod mt-broker-controller-56cc5dc5cc-n9h2c 10513:	Created container mt-broker-controller
12:48:21 Pod mt-broker-controller-56cc5dc5cc-n9h2c 10513:	Started container mt-broker-controller
12:52:23 Pod mt-broker-controller-56cc5dc5cc-n9h2c 10513:	Stopping container mt-broker-controller
12:21:40 Pod mt-broker-controller-56cc5dc5cc-qm4zq 1278:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-qm4zq to acto-cluster-9-worker3
12:21:40 Pod mt-broker-controller-56cc5dc5cc-qm4zq 1282:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:21:49 Pod mt-broker-controller-56cc5dc5cc-qm4zq 1282:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 8.668614563s
12:21:49 Pod mt-broker-controller-56cc5dc5cc-qm4zq 1282:	Created container mt-broker-controller
12:21:49 Pod mt-broker-controller-56cc5dc5cc-qm4zq 1282:	Started container mt-broker-controller
12:25:41 Pod mt-broker-controller-56cc5dc5cc-qm4zq 1282:	Stopping container mt-broker-controller
12:53:03 Pod mt-broker-controller-56cc5dc5cc-r8zsj 12591:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-r8zsj to acto-cluster-9-worker2
12:53:03 Pod mt-broker-controller-56cc5dc5cc-r8zsj 12594:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:53:06 Pod mt-broker-controller-56cc5dc5cc-r8zsj 12594:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.704757786s
12:53:06 Pod mt-broker-controller-56cc5dc5cc-r8zsj 12594:	Created container mt-broker-controller
12:53:06 Pod mt-broker-controller-56cc5dc5cc-r8zsj 12594:	Started container mt-broker-controller
12:27:30 Pod mt-broker-controller-56cc5dc5cc-rqd2j 3467:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-rqd2j to acto-cluster-9-worker3
12:27:30 Pod mt-broker-controller-56cc5dc5cc-rqd2j 3470:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:27:30 Pod mt-broker-controller-56cc5dc5cc-rqd2j 3470:	Created container mt-broker-controller
12:27:30 Pod mt-broker-controller-56cc5dc5cc-rqd2j 3470:	Started container mt-broker-controller
12:36:04 Pod mt-broker-controller-56cc5dc5cc-rqd2j 3470:	Stopping container mt-broker-controller
12:42:30 Pod mt-broker-controller-56cc5dc5cc-t8q4g 8311:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-t8q4g to acto-cluster-9-worker3
12:42:31 Pod mt-broker-controller-56cc5dc5cc-t8q4g 8315:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:42:31 Pod mt-broker-controller-56cc5dc5cc-t8q4g 8315:	Created container mt-broker-controller
12:42:31 Pod mt-broker-controller-56cc5dc5cc-t8q4g 8315:	Started container mt-broker-controller
12:46:34 Pod mt-broker-controller-56cc5dc5cc-t8q4g 8315:	Stopping container mt-broker-controller
12:37:50 Pod mt-broker-controller-56cc5dc5cc-vzjfb 6230:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-vzjfb to acto-cluster-9-worker
12:37:50 Pod mt-broker-controller-56cc5dc5cc-vzjfb 6233:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:37:53 Pod mt-broker-controller-56cc5dc5cc-vzjfb 6233:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 3.232623482s
12:37:54 Pod mt-broker-controller-56cc5dc5cc-vzjfb 6233:	Created container mt-broker-controller
12:37:54 Pod mt-broker-controller-56cc5dc5cc-vzjfb 6233:	Started container mt-broker-controller
12:41:51 Pod mt-broker-controller-56cc5dc5cc-vzjfb 6233:	Stopping container mt-broker-controller
12:21:40 ReplicaSet mt-broker-controller-56cc5dc5cc 1276:	Created pod: mt-broker-controller-56cc5dc5cc-qm4zq
12:27:30 ReplicaSet mt-broker-controller-56cc5dc5cc 3465:	Created pod: mt-broker-controller-56cc5dc5cc-rqd2j
12:37:50 ReplicaSet mt-broker-controller-56cc5dc5cc 6228:	Created pod: mt-broker-controller-56cc5dc5cc-vzjfb
12:42:30 ReplicaSet mt-broker-controller-56cc5dc5cc 8310:	Created pod: mt-broker-controller-56cc5dc5cc-t8q4g
12:48:20 ReplicaSet mt-broker-controller-56cc5dc5cc 10508:	Created pod: mt-broker-controller-56cc5dc5cc-n9h2c
12:53:03 ReplicaSet mt-broker-controller-56cc5dc5cc 12589:	Created pod: mt-broker-controller-56cc5dc5cc-r8zsj
12:21:40 Deployment mt-broker-controller 1275:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:27:30 Deployment mt-broker-controller 3464:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:37:50 Deployment mt-broker-controller 6227:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:42:30 Deployment mt-broker-controller 8309:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:48:20 Deployment mt-broker-controller 10507:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:53:03 Deployment mt-broker-controller 12588:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:42:30 Pod mt-broker-filter-846dc966c5-dzftf 8266:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-dzftf to acto-cluster-9-worker3
12:42:30 Pod mt-broker-filter-846dc966c5-dzftf 8268:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:42:30 Pod mt-broker-filter-846dc966c5-dzftf 8268:	Created container filter
12:42:30 Pod mt-broker-filter-846dc966c5-dzftf 8268:	Started container filter
12:46:34 Pod mt-broker-filter-846dc966c5-dzftf 8268:	Stopping container filter
12:21:39 Pod mt-broker-filter-846dc966c5-hg9p8 1242:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-hg9p8 to acto-cluster-9-worker3
12:21:39 Pod mt-broker-filter-846dc966c5-hg9p8 1245:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:21:43 Pod mt-broker-filter-846dc966c5-hg9p8 1245:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 4.040811731s
12:21:43 Pod mt-broker-filter-846dc966c5-hg9p8 1245:	Created container filter
12:21:44 Pod mt-broker-filter-846dc966c5-hg9p8 1245:	Started container filter
12:21:44 Pod mt-broker-filter-846dc966c5-hg9p8 1245:	Readiness probe failed: Get "http://10.244.1.3:8080/healthz": dial tcp 10.244.1.3:8080: connect: connection refused
12:25:41 Pod mt-broker-filter-846dc966c5-hg9p8 1245:	Stopping container filter
12:53:02 Pod mt-broker-filter-846dc966c5-kmrz8 12544:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-kmrz8 to acto-cluster-9-worker
12:53:02 Pod mt-broker-filter-846dc966c5-kmrz8 12547:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:53:05 Pod mt-broker-filter-846dc966c5-kmrz8 12547:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 2.695140954s
12:53:05 Pod mt-broker-filter-846dc966c5-kmrz8 12547:	Created container filter
12:53:05 Pod mt-broker-filter-846dc966c5-kmrz8 12547:	Started container filter
12:48:19 Pod mt-broker-filter-846dc966c5-l6fnx 10447:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-l6fnx to acto-cluster-9-worker2
12:48:20 Pod mt-broker-filter-846dc966c5-l6fnx 10450:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:48:20 Pod mt-broker-filter-846dc966c5-l6fnx 10450:	Created container filter
12:48:20 Pod mt-broker-filter-846dc966c5-l6fnx 10450:	Started container filter
12:52:23 Pod mt-broker-filter-846dc966c5-l6fnx 10450:	Stopping container filter
12:52:23 Pod mt-broker-filter-846dc966c5-l6fnx 10450:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:52:23 Pod mt-broker-filter-846dc966c5-l6fnx 10450:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:37:49 Pod mt-broker-filter-846dc966c5-wdvtx 6184:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-wdvtx to acto-cluster-9-worker3
12:37:49 Pod mt-broker-filter-846dc966c5-wdvtx 6187:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:37:49 Pod mt-broker-filter-846dc966c5-wdvtx 6187:	Created container filter
12:37:50 Pod mt-broker-filter-846dc966c5-wdvtx 6187:	Started container filter
12:41:51 Pod mt-broker-filter-846dc966c5-wdvtx 6187:	Stopping container filter
12:27:29 Pod mt-broker-filter-846dc966c5-xwz5j 3411:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-xwz5j to acto-cluster-9-worker2
12:27:29 Pod mt-broker-filter-846dc966c5-xwz5j 3414:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:27:33 Pod mt-broker-filter-846dc966c5-xwz5j 3414:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 3.956148781s
12:27:33 Pod mt-broker-filter-846dc966c5-xwz5j 3414:	Created container filter
12:27:33 Pod mt-broker-filter-846dc966c5-xwz5j 3414:	Started container filter
12:36:04 Pod mt-broker-filter-846dc966c5-xwz5j 3414:	Stopping container filter
12:21:39 ReplicaSet mt-broker-filter-846dc966c5 1240:	Created pod: mt-broker-filter-846dc966c5-hg9p8
12:27:29 ReplicaSet mt-broker-filter-846dc966c5 3409:	Created pod: mt-broker-filter-846dc966c5-xwz5j
12:37:49 ReplicaSet mt-broker-filter-846dc966c5 6182:	Created pod: mt-broker-filter-846dc966c5-wdvtx
12:42:30 ReplicaSet mt-broker-filter-846dc966c5 8264:	Created pod: mt-broker-filter-846dc966c5-dzftf
12:48:19 ReplicaSet mt-broker-filter-846dc966c5 10444:	Created pod: mt-broker-filter-846dc966c5-l6fnx
12:53:02 ReplicaSet mt-broker-filter-846dc966c5 12542:	Created pod: mt-broker-filter-846dc966c5-kmrz8
12:21:39 Deployment mt-broker-filter 1239:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:27:29 Deployment mt-broker-filter 3408:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:37:49 Deployment mt-broker-filter 6181:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:42:30 Deployment mt-broker-filter 8263:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:48:19 Deployment mt-broker-filter 10443:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:53:02 Deployment mt-broker-filter 12541:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:42:30 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8291:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-4qnd7 to acto-cluster-9-worker2
12:42:30 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8294:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:42:33 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8294:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.6914657s
12:42:33 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8294:	Created container ingress
12:42:33 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8294:	Started container ingress
12:42:34 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8294:	Readiness probe failed: Get "http://10.244.3.9:8080/healthz": dial tcp 10.244.3.9:8080: connect: connection refused
12:46:34 Pod mt-broker-ingress-6dbbfff4b9-4qnd7 8294:	Stopping container ingress
12:21:39 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1260:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-bqwdl to acto-cluster-9-worker3
12:21:40 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:21:46 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 6.352839008s
12:21:46 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Created container ingress
12:21:46 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Started container ingress
12:25:41 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Stopping container ingress
12:25:41 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:25:41 Pod mt-broker-ingress-6dbbfff4b9-bqwdl 1263:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:37:49 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6203:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-dq24r to acto-cluster-9-worker3
12:37:50 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6206:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:37:50 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6206:	Created container ingress
12:37:50 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6206:	Started container ingress
12:41:51 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6206:	Stopping container ingress
12:41:51 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6206:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:41:51 Pod mt-broker-ingress-6dbbfff4b9-dq24r 6206:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:48:20 Pod mt-broker-ingress-6dbbfff4b9-h597l 10471:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-h597l to acto-cluster-9-worker
12:48:20 Pod mt-broker-ingress-6dbbfff4b9-h597l 10474:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:48:20 Pod mt-broker-ingress-6dbbfff4b9-h597l 10474:	Created container ingress
12:48:21 Pod mt-broker-ingress-6dbbfff4b9-h597l 10474:	Started container ingress
12:52:23 Pod mt-broker-ingress-6dbbfff4b9-h597l 10474:	Stopping container ingress
12:52:24 Pod mt-broker-ingress-6dbbfff4b9-h597l 10474:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:52:24 Pod mt-broker-ingress-6dbbfff4b9-h597l 10474:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:27:29 Pod mt-broker-ingress-6dbbfff4b9-x87rm 3438:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-x87rm to acto-cluster-9-worker
12:27:30 Pod mt-broker-ingress-6dbbfff4b9-x87rm 3446:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:27:33 Pod mt-broker-ingress-6dbbfff4b9-x87rm 3446:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.823633797s
12:27:33 Pod mt-broker-ingress-6dbbfff4b9-x87rm 3446:	Created container ingress
12:27:33 Pod mt-broker-ingress-6dbbfff4b9-x87rm 3446:	Started container ingress
12:36:04 Pod mt-broker-ingress-6dbbfff4b9-x87rm 3446:	Stopping container ingress
12:53:02 Pod mt-broker-ingress-6dbbfff4b9-xtzm6 12565:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-xtzm6 to acto-cluster-9-worker
12:53:03 Pod mt-broker-ingress-6dbbfff4b9-xtzm6 12569:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:53:03 Pod mt-broker-ingress-6dbbfff4b9-xtzm6 12569:	Created container ingress
12:53:03 Pod mt-broker-ingress-6dbbfff4b9-xtzm6 12569:	Started container ingress
12:21:39 ReplicaSet mt-broker-ingress-6dbbfff4b9 1258:	Created pod: mt-broker-ingress-6dbbfff4b9-bqwdl
12:27:29 ReplicaSet mt-broker-ingress-6dbbfff4b9 3435:	Created pod: mt-broker-ingress-6dbbfff4b9-x87rm
12:37:49 ReplicaSet mt-broker-ingress-6dbbfff4b9 6201:	Created pod: mt-broker-ingress-6dbbfff4b9-dq24r
12:42:30 ReplicaSet mt-broker-ingress-6dbbfff4b9 8289:	Created pod: mt-broker-ingress-6dbbfff4b9-4qnd7
12:48:20 ReplicaSet mt-broker-ingress-6dbbfff4b9 10469:	Created pod: mt-broker-ingress-6dbbfff4b9-h597l
12:53:02 ReplicaSet mt-broker-ingress-6dbbfff4b9 12563:	Created pod: mt-broker-ingress-6dbbfff4b9-xtzm6
12:21:39 Deployment mt-broker-ingress 1257:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:27:29 Deployment mt-broker-ingress 3428:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:37:49 Deployment mt-broker-ingress 6200:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:42:30 Deployment mt-broker-ingress 8288:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:48:20 Deployment mt-broker-ingress 10468:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:53:02 Deployment mt-broker-ingress 12562:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:48:21 Pod storage-version-migration-eventing-eventing-1.6.0--1-fdrrt 10555:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-fdrrt to acto-cluster-9-worker
12:48:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-fdrrt 10557:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:48:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-fdrrt 10557:	Created container migrate
12:48:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-fdrrt 10557:	Started container migrate
12:53:03 Pod storage-version-migration-eventing-eventing-1.6.0--1-jfbj2 12616:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-jfbj2 to acto-cluster-9-worker3
12:53:04 Pod storage-version-migration-eventing-eventing-1.6.0--1-jfbj2 12619:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:53:06 Pod storage-version-migration-eventing-eventing-1.6.0--1-jfbj2 12619:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.484416569s
12:53:06 Pod storage-version-migration-eventing-eventing-1.6.0--1-jfbj2 12619:	Created container migrate
12:53:07 Pod storage-version-migration-eventing-eventing-1.6.0--1-jfbj2 12619:	Started container migrate
12:27:30 Pod storage-version-migration-eventing-eventing-1.6.0--1-ml2fm 3503:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-ml2fm to acto-cluster-9-worker2
12:27:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-ml2fm 3505:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:27:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-ml2fm 3505:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 4.880243715s
12:27:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-ml2fm 3505:	Created container migrate
12:27:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-ml2fm 3505:	Started container migrate
12:21:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-nl9b5 1298:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-nl9b5 to acto-cluster-9-worker
12:21:41 Pod storage-version-migration-eventing-eventing-1.6.0--1-nl9b5 1300:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:21:48 Pod storage-version-migration-eventing-eventing-1.6.0--1-nl9b5 1300:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 6.994961571s
12:21:48 Pod storage-version-migration-eventing-eventing-1.6.0--1-nl9b5 1300:	Created container migrate
12:21:48 Pod storage-version-migration-eventing-eventing-1.6.0--1-nl9b5 1300:	Started container migrate
12:42:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-nr8ks 8337:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-nr8ks to acto-cluster-9-worker2
12:42:32 Pod storage-version-migration-eventing-eventing-1.6.0--1-nr8ks 8339:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:42:32 Pod storage-version-migration-eventing-eventing-1.6.0--1-nr8ks 8339:	Created container migrate
12:42:32 Pod storage-version-migration-eventing-eventing-1.6.0--1-nr8ks 8339:	Started container migrate
12:37:50 Pod storage-version-migration-eventing-eventing-1.6.0--1-x6587 6260:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-x6587 to acto-cluster-9-worker2
12:37:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-x6587 6262:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:37:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-x6587 6262:	Created container migrate
12:37:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-x6587 6262:	Started container migrate
12:21:40 Job storage-version-migration-eventing-eventing-1.6.0 1296:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-nl9b5
12:21:54 Job storage-version-migration-eventing-eventing-1.6.0 1301:	Job completed
12:27:30 Job storage-version-migration-eventing-eventing-1.6.0 3502:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-ml2fm
12:27:42 Job storage-version-migration-eventing-eventing-1.6.0 3506:	Job completed
12:37:50 Job storage-version-migration-eventing-eventing-1.6.0 6259:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-x6587
12:37:57 Job storage-version-migration-eventing-eventing-1.6.0 6265:	Job completed
12:42:31 Job storage-version-migration-eventing-eventing-1.6.0 8336:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-nr8ks
12:42:38 Job storage-version-migration-eventing-eventing-1.6.0 8341:	Job completed
12:48:21 Job storage-version-migration-eventing-eventing-1.6.0 10554:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-fdrrt
12:48:27 Job storage-version-migration-eventing-eventing-1.6.0 10559:	Job completed
12:53:03 Job storage-version-migration-eventing-eventing-1.6.0 12615:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-jfbj2
12:53:12 Job storage-version-migration-eventing-eventing-1.6.0 12620:	Job completed
12:21:18 KnativeEventing test-cluster 871:	Updated "test-cluster" finalizers
12:27:10 KnativeEventing test-cluster 3119:	Updated "test-cluster" finalizers
12:37:30 KnativeEventing test-cluster 5839:	Updated "test-cluster" finalizers
12:42:10 KnativeEventing test-cluster 7898:	Updated "test-cluster" finalizers
12:48:01 KnativeEventing test-cluster 10118:	Updated "test-cluster" finalizers
12:52:42 KnativeEventing test-cluster 12172:	Updated "test-cluster" finalizers
