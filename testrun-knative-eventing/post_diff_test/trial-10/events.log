12:21:43 HorizontalPodAutoscaler broker-filter-hpa 1284:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:43 HorizontalPodAutoscaler broker-filter-hpa 1284:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:30:22 HorizontalPodAutoscaler broker-filter-hpa 4375:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:30:22 HorizontalPodAutoscaler broker-filter-hpa 4375:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:35:04 HorizontalPodAutoscaler broker-filter-hpa 6452:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:35:05 HorizontalPodAutoscaler broker-filter-hpa 6452:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:45 HorizontalPodAutoscaler broker-filter-hpa 8511:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:45 HorizontalPodAutoscaler broker-filter-hpa 8511:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:26 HorizontalPodAutoscaler broker-filter-hpa 10617:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:26 HorizontalPodAutoscaler broker-filter-hpa 10617:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:50:20 HorizontalPodAutoscaler broker-filter-hpa 12831:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:50:20 HorizontalPodAutoscaler broker-filter-hpa 12831:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:43 HorizontalPodAutoscaler broker-ingress-hpa 1273:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:43 HorizontalPodAutoscaler broker-ingress-hpa 1273:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:30:22 HorizontalPodAutoscaler broker-ingress-hpa 4372:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:30:22 HorizontalPodAutoscaler broker-ingress-hpa 4372:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:35:04 HorizontalPodAutoscaler broker-ingress-hpa 6449:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:35:04 HorizontalPodAutoscaler broker-ingress-hpa 6449:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:45 HorizontalPodAutoscaler broker-ingress-hpa 8510:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:45 HorizontalPodAutoscaler broker-ingress-hpa 8510:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:26 HorizontalPodAutoscaler broker-ingress-hpa 10615:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:26 HorizontalPodAutoscaler broker-ingress-hpa 10615:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:50:19 HorizontalPodAutoscaler broker-ingress-hpa 12828:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:50:19 HorizontalPodAutoscaler broker-ingress-hpa 12828:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:05 Pod eventing-controller-578f9ff97f-9zjfk 10370:	Successfully assigned knative-eventing/eventing-controller-578f9ff97f-9zjfk to acto-cluster-10-worker
12:44:06 Pod eventing-controller-578f9ff97f-9zjfk 10372:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:44:06 Pod eventing-controller-578f9ff97f-9zjfk 10372:	Created container eventing-controller
12:44:06 Pod eventing-controller-578f9ff97f-9zjfk 10372:	Started container eventing-controller
12:48:21 Pod eventing-controller-578f9ff97f-9zjfk 10372:	Stopping container eventing-controller
12:44:05 ReplicaSet eventing-controller-578f9ff97f 10367:	Created pod: eventing-controller-578f9ff97f-9zjfk
12:30:01 Pod eventing-controller-5d88d6d755-fw7dd 4139:	Successfully assigned knative-eventing/eventing-controller-5d88d6d755-fw7dd to acto-cluster-10-worker2
12:30:01 Pod eventing-controller-5d88d6d755-fw7dd 4140:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:30:04 Pod eventing-controller-5d88d6d755-fw7dd 4140:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.788635995s
12:30:04 Pod eventing-controller-5d88d6d755-fw7dd 4140:	Created container eventing-controller
12:30:04 Pod eventing-controller-5d88d6d755-fw7dd 4140:	Started container eventing-controller
12:34:15 Pod eventing-controller-5d88d6d755-fw7dd 4140:	Stopping container eventing-controller
12:30:01 ReplicaSet eventing-controller-5d88d6d755 4136:	Created pod: eventing-controller-5d88d6d755-fw7dd
12:34:43 Pod eventing-controller-6c78bb8c7f-hjgjs 6225:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-hjgjs to acto-cluster-10-worker3
12:34:44 Pod eventing-controller-6c78bb8c7f-hjgjs 6228:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:34:47 Pod eventing-controller-6c78bb8c7f-hjgjs 6228:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.792953189s
12:34:47 Pod eventing-controller-6c78bb8c7f-hjgjs 6228:	Created container eventing-controller
12:34:47 Pod eventing-controller-6c78bb8c7f-hjgjs 6228:	Started container eventing-controller
12:38:55 Pod eventing-controller-6c78bb8c7f-hjgjs 6228:	Stopping container eventing-controller
12:49:58 Pod eventing-controller-6c78bb8c7f-hsq9p 12595:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-hsq9p to acto-cluster-10-worker2
12:49:59 Pod eventing-controller-6c78bb8c7f-hsq9p 12597:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:49:59 Pod eventing-controller-6c78bb8c7f-hsq9p 12597:	Created container eventing-controller
12:49:59 Pod eventing-controller-6c78bb8c7f-hsq9p 12597:	Started container eventing-controller
12:39:24 Pod eventing-controller-6c78bb8c7f-r457b 8283:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-r457b to acto-cluster-10-worker2
12:39:25 Pod eventing-controller-6c78bb8c7f-r457b 8285:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:39:25 Pod eventing-controller-6c78bb8c7f-r457b 8285:	Created container eventing-controller
12:39:25 Pod eventing-controller-6c78bb8c7f-r457b 8285:	Started container eventing-controller
12:43:36 Pod eventing-controller-6c78bb8c7f-r457b 8285:	Stopping container eventing-controller
12:21:21 Pod eventing-controller-6c78bb8c7f-vjlcz 1059:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-vjlcz to acto-cluster-10-worker
12:21:22 Pod eventing-controller-6c78bb8c7f-vjlcz 1062:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:21:25 Pod eventing-controller-6c78bb8c7f-vjlcz 1062:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.560586424s
12:21:25 Pod eventing-controller-6c78bb8c7f-vjlcz 1062:	Created container eventing-controller
12:21:25 Pod eventing-controller-6c78bb8c7f-vjlcz 1062:	Started container eventing-controller
12:25:34 Pod eventing-controller-6c78bb8c7f-vjlcz 1062:	Stopping container eventing-controller
12:21:21 ReplicaSet eventing-controller-6c78bb8c7f 1056:	Created pod: eventing-controller-6c78bb8c7f-vjlcz
12:34:43 ReplicaSet eventing-controller-6c78bb8c7f 6222:	Created pod: eventing-controller-6c78bb8c7f-hjgjs
12:39:24 ReplicaSet eventing-controller-6c78bb8c7f 8280:	Created pod: eventing-controller-6c78bb8c7f-r457b
12:49:58 ReplicaSet eventing-controller-6c78bb8c7f 12592:	Created pod: eventing-controller-6c78bb8c7f-hsq9p
12:21:21 Deployment eventing-controller 1055:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:30:01 Deployment eventing-controller 4135:	Scaled up replica set eventing-controller-5d88d6d755 to 1
12:34:43 Deployment eventing-controller 6221:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:39:24 Deployment eventing-controller 8279:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:44:05 Deployment eventing-controller 10366:	Scaled up replica set eventing-controller-578f9ff97f to 1
12:49:58 Deployment eventing-controller 12591:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:49:59 Pod eventing-webhook-5755489569-2r99w 12621:	Successfully assigned knative-eventing/eventing-webhook-5755489569-2r99w to acto-cluster-10-worker
12:50:00 Pod eventing-webhook-5755489569-2r99w 12626:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:50:00 Pod eventing-webhook-5755489569-2r99w 12626:	Created container eventing-webhook
12:50:01 Pod eventing-webhook-5755489569-2r99w 12626:	Started container eventing-webhook
12:50:01 Pod eventing-webhook-5755489569-2r99w 12626:	Readiness probe failed: Get "https://10.244.3.15:8443/": remote error: tls: unrecognized name
12:21:22 Pod eventing-webhook-5755489569-2sh57 1083:	Successfully assigned knative-eventing/eventing-webhook-5755489569-2sh57 to acto-cluster-10-worker2
12:21:23 Pod eventing-webhook-5755489569-2sh57 1088:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:21:27 Pod eventing-webhook-5755489569-2sh57 1088:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 4.105376131s
12:21:27 Pod eventing-webhook-5755489569-2sh57 1088:	Created container eventing-webhook
12:21:28 Pod eventing-webhook-5755489569-2sh57 1088:	Started container eventing-webhook
12:21:28 Pod eventing-webhook-5755489569-2sh57 1088:	Readiness probe failed: Get "https://10.244.1.2:8443/": dial tcp 10.244.1.2:8443: connect: connection refused
12:25:33 Pod eventing-webhook-5755489569-2sh57 1088:	Liveness probe failed: Get "https://10.244.1.2:8443/": remote error: tls: unrecognized name
12:25:33 Pod eventing-webhook-5755489569-2sh57 1088:	Readiness probe failed: Get "https://10.244.1.2:8443/": remote error: tls: unrecognized name
12:25:33 Pod eventing-webhook-5755489569-2sh57 1088:	Stopping container eventing-webhook
12:44:06 Pod eventing-webhook-5755489569-7t9hx 10396:	Successfully assigned knative-eventing/eventing-webhook-5755489569-7t9hx to acto-cluster-10-worker2
12:44:07 Pod eventing-webhook-5755489569-7t9hx 10399:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:44:07 Pod eventing-webhook-5755489569-7t9hx 10399:	Created container eventing-webhook
12:44:07 Pod eventing-webhook-5755489569-7t9hx 10399:	Started container eventing-webhook
12:44:08 Pod eventing-webhook-5755489569-7t9hx 10399:	Readiness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:48:19 Pod eventing-webhook-5755489569-7t9hx 10399:	Liveness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:48:20 Pod eventing-webhook-5755489569-7t9hx 10399:	Stopping container eventing-webhook
12:39:25 Pod eventing-webhook-5755489569-ftlzg 8307:	Successfully assigned knative-eventing/eventing-webhook-5755489569-ftlzg to acto-cluster-10-worker
12:39:26 Pod eventing-webhook-5755489569-ftlzg 8310:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:39:26 Pod eventing-webhook-5755489569-ftlzg 8310:	Created container eventing-webhook
12:39:27 Pod eventing-webhook-5755489569-ftlzg 8310:	Started container eventing-webhook
12:43:35 Pod eventing-webhook-5755489569-ftlzg 8310:	Readiness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:43:35 Pod eventing-webhook-5755489569-ftlzg 8310:	Liveness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:43:36 Pod eventing-webhook-5755489569-ftlzg 8310:	Stopping container eventing-webhook
12:30:02 Pod eventing-webhook-5755489569-kz9ks 4164:	Successfully assigned knative-eventing/eventing-webhook-5755489569-kz9ks to acto-cluster-10-worker
12:30:02 Pod eventing-webhook-5755489569-kz9ks 4168:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:30:05 Pod eventing-webhook-5755489569-kz9ks 4168:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.735678601s
12:30:05 Pod eventing-webhook-5755489569-kz9ks 4168:	Created container eventing-webhook
12:30:06 Pod eventing-webhook-5755489569-kz9ks 4168:	Started container eventing-webhook
12:30:06 Pod eventing-webhook-5755489569-kz9ks 4168:	Readiness probe failed: Get "https://10.244.3.4:8443/": dial tcp 10.244.3.4:8443: connect: connection refused
12:34:14 Pod eventing-webhook-5755489569-kz9ks 4168:	Liveness probe failed: Get "https://10.244.3.4:8443/": remote error: tls: unrecognized name
12:34:14 Pod eventing-webhook-5755489569-kz9ks 4168:	Readiness probe failed: Get "https://10.244.3.4:8443/": remote error: tls: unrecognized name
12:34:14 Pod eventing-webhook-5755489569-kz9ks 4168:	Stopping container eventing-webhook
12:34:44 Pod eventing-webhook-5755489569-zjdsr 6248:	Successfully assigned knative-eventing/eventing-webhook-5755489569-zjdsr to acto-cluster-10-worker2
12:34:45 Pod eventing-webhook-5755489569-zjdsr 6251:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:34:45 Pod eventing-webhook-5755489569-zjdsr 6251:	Created container eventing-webhook
12:34:46 Pod eventing-webhook-5755489569-zjdsr 6251:	Started container eventing-webhook
12:38:54 Pod eventing-webhook-5755489569-zjdsr 6251:	Readiness probe failed: Get "https://10.244.1.8:8443/": remote error: tls: unrecognized name
12:38:54 Pod eventing-webhook-5755489569-zjdsr 6251:	Liveness probe failed: Get "https://10.244.1.8:8443/": remote error: tls: unrecognized name
12:38:55 Pod eventing-webhook-5755489569-zjdsr 6251:	Stopping container eventing-webhook
12:21:22 ReplicaSet eventing-webhook-5755489569 1081:	Created pod: eventing-webhook-5755489569-2sh57
12:30:02 ReplicaSet eventing-webhook-5755489569 4162:	Created pod: eventing-webhook-5755489569-kz9ks
12:34:44 ReplicaSet eventing-webhook-5755489569 6246:	Created pod: eventing-webhook-5755489569-zjdsr
12:39:25 ReplicaSet eventing-webhook-5755489569 8305:	Created pod: eventing-webhook-5755489569-ftlzg
12:44:06 ReplicaSet eventing-webhook-5755489569 10394:	Created pod: eventing-webhook-5755489569-7t9hx
12:49:59 ReplicaSet eventing-webhook-5755489569 12619:	Created pod: eventing-webhook-5755489569-2r99w
12:21:22 PodDisruptionBudget eventing-webhook 1074:	No matching pods found
12:21:22 Deployment eventing-webhook 1080:	Scaled up replica set eventing-webhook-5755489569 to 1
12:21:36 HorizontalPodAutoscaler eventing-webhook 1073:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:36 HorizontalPodAutoscaler eventing-webhook 1073:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:25:33 PodDisruptionBudget eventing-webhook 1554:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:30:01 PodDisruptionBudget eventing-webhook 4156:	No matching pods found
12:30:02 Deployment eventing-webhook 4161:	Scaled up replica set eventing-webhook-5755489569 to 1
12:30:16 HorizontalPodAutoscaler eventing-webhook 4155:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:30:16 HorizontalPodAutoscaler eventing-webhook 4155:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:34:14 PodDisruptionBudget eventing-webhook 4615:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:34:44 PodDisruptionBudget eventing-webhook 6240:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:34:44 Deployment eventing-webhook 6245:	Scaled up replica set eventing-webhook-5755489569 to 1
12:34:44 PodDisruptionBudget eventing-webhook 6242:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-kz9ks"
12:34:59 HorizontalPodAutoscaler eventing-webhook 6239:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:34:59 HorizontalPodAutoscaler eventing-webhook 6239:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:25 PodDisruptionBudget eventing-webhook 8298:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:39:25 Deployment eventing-webhook 8304:	Scaled up replica set eventing-webhook-5755489569 to 1
12:39:25 PodDisruptionBudget eventing-webhook 8301:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-zjdsr"
12:39:40 HorizontalPodAutoscaler eventing-webhook 8297:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:40 HorizontalPodAutoscaler eventing-webhook 8297:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:06 PodDisruptionBudget eventing-webhook 10387:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:44:06 Deployment eventing-webhook 10393:	Scaled up replica set eventing-webhook-5755489569 to 1
12:44:06 PodDisruptionBudget eventing-webhook 10390:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-ftlzg"
12:44:21 HorizontalPodAutoscaler eventing-webhook 10384:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:44:21 HorizontalPodAutoscaler eventing-webhook 10384:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:49:59 PodDisruptionBudget eventing-webhook 12613:	No matching pods found
12:49:59 Deployment eventing-webhook 12618:	Scaled up replica set eventing-webhook-5755489569 to 1
12:50:14 HorizontalPodAutoscaler eventing-webhook 12611:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:50:14 HorizontalPodAutoscaler eventing-webhook 12611:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:30:04 Pod imc-controller-567b4f565b-b4p2n 4199:	Successfully assigned knative-eventing/imc-controller-567b4f565b-b4p2n to acto-cluster-10-worker2
12:30:05 Pod imc-controller-567b4f565b-b4p2n 4202:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:30:05 Pod imc-controller-567b4f565b-b4p2n 4202:	Created container controller
12:30:05 Pod imc-controller-567b4f565b-b4p2n 4202:	Started container controller
12:34:10 Pod imc-controller-567b4f565b-b4p2n 4202:	Readiness probe failed: Get "https://10.244.1.6:8443/": remote error: tls: unrecognized name
12:34:10 Pod imc-controller-567b4f565b-b4p2n 4202:	Liveness probe failed: Get "https://10.244.1.6:8443/": remote error: tls: unrecognized name
12:34:11 Pod imc-controller-567b4f565b-b4p2n 4202:	Stopping container controller
12:39:28 Pod imc-controller-567b4f565b-b9l8q 8400:	Successfully assigned knative-eventing/imc-controller-567b4f565b-b9l8q to acto-cluster-10-worker3
12:39:28 Pod imc-controller-567b4f565b-b9l8q 8403:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:39:31 Pod imc-controller-567b4f565b-b9l8q 8403:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.711265256s
12:39:31 Pod imc-controller-567b4f565b-b9l8q 8403:	Created container controller
12:39:31 Pod imc-controller-567b4f565b-b9l8q 8403:	Started container controller
12:43:33 Pod imc-controller-567b4f565b-b9l8q 8403:	Readiness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:43:33 Pod imc-controller-567b4f565b-b9l8q 8403:	Liveness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:43:33 Pod imc-controller-567b4f565b-b9l8q 8403:	Stopping container controller
12:34:47 Pod imc-controller-567b4f565b-jld8c 6313:	Successfully assigned knative-eventing/imc-controller-567b4f565b-jld8c to acto-cluster-10-worker
12:34:47 Pod imc-controller-567b4f565b-jld8c 6316:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:34:50 Pod imc-controller-567b4f565b-jld8c 6316:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.771214109s
12:34:50 Pod imc-controller-567b4f565b-jld8c 6316:	Created container controller
12:34:50 Pod imc-controller-567b4f565b-jld8c 6316:	Started container controller
12:38:52 Pod imc-controller-567b4f565b-jld8c 6316:	Readiness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
12:38:52 Pod imc-controller-567b4f565b-jld8c 6316:	Liveness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
12:38:52 Pod imc-controller-567b4f565b-jld8c 6316:	Stopping container controller
12:50:02 Pod imc-controller-567b4f565b-nphgw 12705:	Successfully assigned knative-eventing/imc-controller-567b4f565b-nphgw to acto-cluster-10-worker3
12:50:02 Pod imc-controller-567b4f565b-nphgw 12708:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:50:02 Pod imc-controller-567b4f565b-nphgw 12708:	Created container controller
12:50:03 Pod imc-controller-567b4f565b-nphgw 12708:	Started container controller
12:44:09 Pod imc-controller-567b4f565b-sp9ml 10481:	Successfully assigned knative-eventing/imc-controller-567b4f565b-sp9ml to acto-cluster-10-worker
12:44:09 Pod imc-controller-567b4f565b-sp9ml 10484:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:44:09 Pod imc-controller-567b4f565b-sp9ml 10484:	Created container controller
12:44:09 Pod imc-controller-567b4f565b-sp9ml 10484:	Started container controller
12:48:17 Pod imc-controller-567b4f565b-sp9ml 10484:	Readiness probe failed: Get "https://10.244.3.14:8443/": remote error: tls: unrecognized name
12:48:17 Pod imc-controller-567b4f565b-sp9ml 10484:	Liveness probe failed: Get "https://10.244.3.14:8443/": remote error: tls: unrecognized name
12:48:17 Pod imc-controller-567b4f565b-sp9ml 10484:	Stopping container controller
12:21:25 Pod imc-controller-567b4f565b-tzjq2 1136:	Successfully assigned knative-eventing/imc-controller-567b4f565b-tzjq2 to acto-cluster-10-worker2
12:21:26 Pod imc-controller-567b4f565b-tzjq2 1139:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:21:33 Pod imc-controller-567b4f565b-tzjq2 1139:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 7.125654625s
12:21:33 Pod imc-controller-567b4f565b-tzjq2 1139:	Created container controller
12:21:33 Pod imc-controller-567b4f565b-tzjq2 1139:	Started container controller
12:21:34 Pod imc-controller-567b4f565b-tzjq2 1139:	Readiness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
12:25:30 Pod imc-controller-567b4f565b-tzjq2 1139:	Liveness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
12:25:31 Pod imc-controller-567b4f565b-tzjq2 1139:	Stopping container controller
12:21:25 ReplicaSet imc-controller-567b4f565b 1134:	Created pod: imc-controller-567b4f565b-tzjq2
12:30:04 ReplicaSet imc-controller-567b4f565b 4197:	Created pod: imc-controller-567b4f565b-b4p2n
12:34:47 ReplicaSet imc-controller-567b4f565b 6311:	Created pod: imc-controller-567b4f565b-jld8c
12:39:28 ReplicaSet imc-controller-567b4f565b 8398:	Created pod: imc-controller-567b4f565b-b9l8q
12:44:09 ReplicaSet imc-controller-567b4f565b 10479:	Created pod: imc-controller-567b4f565b-sp9ml
12:50:02 ReplicaSet imc-controller-567b4f565b 12703:	Created pod: imc-controller-567b4f565b-nphgw
12:21:25 Deployment imc-controller 1133:	Scaled up replica set imc-controller-567b4f565b to 1
12:30:04 Deployment imc-controller 4196:	Scaled up replica set imc-controller-567b4f565b to 1
12:34:47 Deployment imc-controller 6310:	Scaled up replica set imc-controller-567b4f565b to 1
12:39:28 Deployment imc-controller 8397:	Scaled up replica set imc-controller-567b4f565b to 1
12:44:09 Deployment imc-controller 10478:	Scaled up replica set imc-controller-567b4f565b to 1
12:50:02 Deployment imc-controller 12701:	Scaled up replica set imc-controller-567b4f565b to 1
12:34:47 Pod imc-dispatcher-545bcb44c5-29gwl 6363:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-29gwl to acto-cluster-10-worker2
12:34:48 Pod imc-dispatcher-545bcb44c5-29gwl 6367:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:34:48 Pod imc-dispatcher-545bcb44c5-29gwl 6367:	Created container dispatcher
12:34:48 Pod imc-dispatcher-545bcb44c5-29gwl 6367:	Started container dispatcher
12:38:52 Pod imc-dispatcher-545bcb44c5-29gwl 6367:	Stopping container dispatcher
12:30:05 Pod imc-dispatcher-545bcb44c5-g77w6 4245:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-g77w6 to acto-cluster-10-worker2
12:30:05 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:30:08 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.820578603s
12:30:08 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Created container dispatcher
12:30:08 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Started container dispatcher
12:34:11 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Stopping container dispatcher
12:34:11 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Readiness probe failed: Get "http://10.244.1.7:8080/healthz": dial tcp 10.244.1.7:8080: connect: connection refused
12:34:11 Pod imc-dispatcher-545bcb44c5-g77w6 4248:	Liveness probe failed: Get "http://10.244.1.7:8080/healthz": dial tcp 10.244.1.7:8080: connect: connection refused
12:44:09 Pod imc-dispatcher-545bcb44c5-lncfj 10508:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-lncfj to acto-cluster-10-worker3
12:44:10 Pod imc-dispatcher-545bcb44c5-lncfj 10513:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:44:10 Pod imc-dispatcher-545bcb44c5-lncfj 10513:	Created container dispatcher
12:44:10 Pod imc-dispatcher-545bcb44c5-lncfj 10513:	Started container dispatcher
12:48:17 Pod imc-dispatcher-545bcb44c5-lncfj 10513:	Stopping container dispatcher
12:50:02 Pod imc-dispatcher-545bcb44c5-svcd5 12735:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-svcd5 to acto-cluster-10-worker
12:50:03 Pod imc-dispatcher-545bcb44c5-svcd5 12740:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:50:06 Pod imc-dispatcher-545bcb44c5-svcd5 12740:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.760026789s
12:50:06 Pod imc-dispatcher-545bcb44c5-svcd5 12740:	Created container dispatcher
12:50:06 Pod imc-dispatcher-545bcb44c5-svcd5 12740:	Started container dispatcher
12:39:28 Pod imc-dispatcher-545bcb44c5-x7t6s 8421:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-x7t6s to acto-cluster-10-worker3
12:39:29 Pod imc-dispatcher-545bcb44c5-x7t6s 8427:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:39:29 Pod imc-dispatcher-545bcb44c5-x7t6s 8427:	Created container dispatcher
12:39:29 Pod imc-dispatcher-545bcb44c5-x7t6s 8427:	Started container dispatcher
12:43:33 Pod imc-dispatcher-545bcb44c5-x7t6s 8427:	Stopping container dispatcher
12:21:26 Pod imc-dispatcher-545bcb44c5-xh49t 1182:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-xh49t to acto-cluster-10-worker3
12:21:27 Pod imc-dispatcher-545bcb44c5-xh49t 1187:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:21:30 Pod imc-dispatcher-545bcb44c5-xh49t 1187:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 3.382396855s
12:21:30 Pod imc-dispatcher-545bcb44c5-xh49t 1187:	Created container dispatcher
12:21:30 Pod imc-dispatcher-545bcb44c5-xh49t 1187:	Started container dispatcher
12:25:30 Pod imc-dispatcher-545bcb44c5-xh49t 1187:	Stopping container dispatcher
12:21:26 ReplicaSet imc-dispatcher-545bcb44c5 1181:	Created pod: imc-dispatcher-545bcb44c5-xh49t
12:30:05 ReplicaSet imc-dispatcher-545bcb44c5 4243:	Created pod: imc-dispatcher-545bcb44c5-g77w6
12:34:47 ReplicaSet imc-dispatcher-545bcb44c5 6361:	Created pod: imc-dispatcher-545bcb44c5-29gwl
12:39:28 ReplicaSet imc-dispatcher-545bcb44c5 8419:	Created pod: imc-dispatcher-545bcb44c5-x7t6s
12:44:09 ReplicaSet imc-dispatcher-545bcb44c5 10506:	Created pod: imc-dispatcher-545bcb44c5-lncfj
12:50:02 ReplicaSet imc-dispatcher-545bcb44c5 12733:	Created pod: imc-dispatcher-545bcb44c5-svcd5
12:21:26 Deployment imc-dispatcher 1180:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:30:05 Deployment imc-dispatcher 4242:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:34:47 Deployment imc-dispatcher 6360:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:39:28 Deployment imc-dispatcher 8418:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:44:09 Deployment imc-dispatcher 10505:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:50:02 Deployment imc-dispatcher 12731:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:20:59 Pod knative-operator-668fb586bb-jsnkx 794:	Successfully assigned knative-eventing/knative-operator-668fb586bb-jsnkx to acto-cluster-10-worker3
12:20:59 Pod knative-operator-668fb586bb-jsnkx 798:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:20:59 Pod knative-operator-668fb586bb-jsnkx 798:	Created container knative-operator
12:20:59 Pod knative-operator-668fb586bb-jsnkx 798:	Started container knative-operator
12:20:59 ReplicaSet knative-operator-668fb586bb 791:	Created pod: knative-operator-668fb586bb-jsnkx
12:20:48 Pod knative-operator-79bf74d66d-fpbvg 751:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-fpbvg to acto-cluster-10-worker3
12:20:49 Pod knative-operator-79bf74d66d-fpbvg 753:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:20:52 Pod knative-operator-79bf74d66d-fpbvg 753:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.470611573s
12:20:52 Pod knative-operator-79bf74d66d-fpbvg 753:	Created container knative-operator
12:20:53 Pod knative-operator-79bf74d66d-fpbvg 753:	Started container knative-operator
12:21:00 Pod knative-operator-79bf74d66d-fpbvg 753:	Stopping container knative-operator
12:20:48 ReplicaSet knative-operator-79bf74d66d 747:	Created pod: knative-operator-79bf74d66d-fpbvg
12:21:00 ReplicaSet knative-operator-79bf74d66d 814:	Deleted pod: knative-operator-79bf74d66d-fpbvg
12:20:48 Deployment knative-operator 746:	Scaled up replica set knative-operator-79bf74d66d to 1
12:20:59 Deployment knative-operator 789:	Scaled up replica set knative-operator-668fb586bb to 1
12:21:00 Deployment knative-operator 805:	Scaled down replica set knative-operator-79bf74d66d to 0
12:50:04 Pod mt-broker-controller-56cc5dc5cc-74lx5 12819:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-74lx5 to acto-cluster-10-worker2
12:50:05 Pod mt-broker-controller-56cc5dc5cc-74lx5 12821:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:50:05 Pod mt-broker-controller-56cc5dc5cc-74lx5 12821:	Created container mt-broker-controller
12:50:05 Pod mt-broker-controller-56cc5dc5cc-74lx5 12821:	Started container mt-broker-controller
12:34:49 Pod mt-broker-controller-56cc5dc5cc-j6vbt 6436:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-j6vbt to acto-cluster-10-worker
12:34:50 Pod mt-broker-controller-56cc5dc5cc-j6vbt 6441:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:34:53 Pod mt-broker-controller-56cc5dc5cc-j6vbt 6441:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 3.183047541s
12:34:53 Pod mt-broker-controller-56cc5dc5cc-j6vbt 6441:	Created container mt-broker-controller
12:34:53 Pod mt-broker-controller-56cc5dc5cc-j6vbt 6441:	Started container mt-broker-controller
12:38:51 Pod mt-broker-controller-56cc5dc5cc-j6vbt 6441:	Stopping container mt-broker-controller
12:44:11 Pod mt-broker-controller-56cc5dc5cc-m9hhh 10602:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-m9hhh to acto-cluster-10-worker2
12:44:11 Pod mt-broker-controller-56cc5dc5cc-m9hhh 10605:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:44:14 Pod mt-broker-controller-56cc5dc5cc-m9hhh 10605:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.861621203s
12:44:14 Pod mt-broker-controller-56cc5dc5cc-m9hhh 10605:	Created container mt-broker-controller
12:44:15 Pod mt-broker-controller-56cc5dc5cc-m9hhh 10605:	Started container mt-broker-controller
12:48:16 Pod mt-broker-controller-56cc5dc5cc-m9hhh 10605:	Stopping container mt-broker-controller
12:39:30 Pod mt-broker-controller-56cc5dc5cc-n59mn 8500:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-n59mn to acto-cluster-10-worker
12:39:31 Pod mt-broker-controller-56cc5dc5cc-n59mn 8501:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:39:31 Pod mt-broker-controller-56cc5dc5cc-n59mn 8501:	Created container mt-broker-controller
12:39:31 Pod mt-broker-controller-56cc5dc5cc-n59mn 8501:	Started container mt-broker-controller
12:43:32 Pod mt-broker-controller-56cc5dc5cc-n59mn 8501:	Stopping container mt-broker-controller
12:30:07 Pod mt-broker-controller-56cc5dc5cc-r5ddm 4354:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-r5ddm to acto-cluster-10-worker3
12:30:07 Pod mt-broker-controller-56cc5dc5cc-r5ddm 4357:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:30:07 Pod mt-broker-controller-56cc5dc5cc-r5ddm 4357:	Created container mt-broker-controller
12:30:07 Pod mt-broker-controller-56cc5dc5cc-r5ddm 4357:	Started container mt-broker-controller
12:34:10 Pod mt-broker-controller-56cc5dc5cc-r5ddm 4357:	Stopping container mt-broker-controller
12:21:28 Pod mt-broker-controller-56cc5dc5cc-wfsmg 1254:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-wfsmg to acto-cluster-10-worker3
12:21:29 Pod mt-broker-controller-56cc5dc5cc-wfsmg 1258:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:21:37 Pod mt-broker-controller-56cc5dc5cc-wfsmg 1258:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 8.660231294s
12:21:37 Pod mt-broker-controller-56cc5dc5cc-wfsmg 1258:	Created container mt-broker-controller
12:21:37 Pod mt-broker-controller-56cc5dc5cc-wfsmg 1258:	Started container mt-broker-controller
12:25:29 Pod mt-broker-controller-56cc5dc5cc-wfsmg 1258:	Stopping container mt-broker-controller
12:21:28 ReplicaSet mt-broker-controller-56cc5dc5cc 1253:	Created pod: mt-broker-controller-56cc5dc5cc-wfsmg
12:30:07 ReplicaSet mt-broker-controller-56cc5dc5cc 4352:	Created pod: mt-broker-controller-56cc5dc5cc-r5ddm
12:34:49 ReplicaSet mt-broker-controller-56cc5dc5cc 6433:	Created pod: mt-broker-controller-56cc5dc5cc-j6vbt
12:39:30 ReplicaSet mt-broker-controller-56cc5dc5cc 8497:	Created pod: mt-broker-controller-56cc5dc5cc-n59mn
12:44:11 ReplicaSet mt-broker-controller-56cc5dc5cc 10600:	Created pod: mt-broker-controller-56cc5dc5cc-m9hhh
12:50:04 ReplicaSet mt-broker-controller-56cc5dc5cc 12816:	Created pod: mt-broker-controller-56cc5dc5cc-74lx5
12:21:28 Deployment mt-broker-controller 1252:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:30:07 Deployment mt-broker-controller 4351:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:34:49 Deployment mt-broker-controller 6431:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:39:30 Deployment mt-broker-controller 8496:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:44:11 Deployment mt-broker-controller 10599:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:50:04 Deployment mt-broker-controller 12815:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:39:29 Pod mt-broker-filter-846dc966c5-6m4d5 8448:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-6m4d5 to acto-cluster-10-worker
12:39:30 Pod mt-broker-filter-846dc966c5-6m4d5 8451:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:39:30 Pod mt-broker-filter-846dc966c5-6m4d5 8451:	Created container filter
12:39:30 Pod mt-broker-filter-846dc966c5-6m4d5 8451:	Started container filter
12:43:32 Pod mt-broker-filter-846dc966c5-6m4d5 8451:	Stopping container filter
12:50:03 Pod mt-broker-filter-846dc966c5-j5chn 12773:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-j5chn to acto-cluster-10-worker
12:50:04 Pod mt-broker-filter-846dc966c5-j5chn 12776:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:50:04 Pod mt-broker-filter-846dc966c5-j5chn 12776:	Created container filter
12:50:04 Pod mt-broker-filter-846dc966c5-j5chn 12776:	Started container filter
12:21:27 Pod mt-broker-filter-846dc966c5-j7fmk 1215:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-j7fmk to acto-cluster-10-worker2
12:21:28 Pod mt-broker-filter-846dc966c5-j7fmk 1217:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:21:36 Pod mt-broker-filter-846dc966c5-j7fmk 1217:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 8.173772309s
12:21:36 Pod mt-broker-filter-846dc966c5-j7fmk 1217:	Created container filter
12:21:36 Pod mt-broker-filter-846dc966c5-j7fmk 1217:	Started container filter
12:25:29 Pod mt-broker-filter-846dc966c5-j7fmk 1217:	Stopping container filter
12:44:10 Pod mt-broker-filter-846dc966c5-ph5xh 10548:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-ph5xh to acto-cluster-10-worker2
12:44:11 Pod mt-broker-filter-846dc966c5-ph5xh 10551:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:44:11 Pod mt-broker-filter-846dc966c5-ph5xh 10551:	Created container filter
12:44:11 Pod mt-broker-filter-846dc966c5-ph5xh 10551:	Started container filter
12:48:16 Pod mt-broker-filter-846dc966c5-ph5xh 10551:	Stopping container filter
12:48:16 Pod mt-broker-filter-846dc966c5-ph5xh 10551:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:48:16 Pod mt-broker-filter-846dc966c5-ph5xh 10551:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:30:06 Pod mt-broker-filter-846dc966c5-z7jk8 4288:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-z7jk8 to acto-cluster-10-worker
12:30:06 Pod mt-broker-filter-846dc966c5-z7jk8 4292:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:30:09 Pod mt-broker-filter-846dc966c5-z7jk8 4292:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 2.748593367s
12:30:09 Pod mt-broker-filter-846dc966c5-z7jk8 4292:	Created container filter
12:30:09 Pod mt-broker-filter-846dc966c5-z7jk8 4292:	Started container filter
12:34:10 Pod mt-broker-filter-846dc966c5-z7jk8 4292:	Stopping container filter
12:34:48 Pod mt-broker-filter-846dc966c5-zzgx4 6388:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-zzgx4 to acto-cluster-10-worker
12:34:49 Pod mt-broker-filter-846dc966c5-zzgx4 6391:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:34:49 Pod mt-broker-filter-846dc966c5-zzgx4 6391:	Created container filter
12:34:49 Pod mt-broker-filter-846dc966c5-zzgx4 6391:	Started container filter
12:38:51 Pod mt-broker-filter-846dc966c5-zzgx4 6391:	Stopping container filter
12:21:27 ReplicaSet mt-broker-filter-846dc966c5 1212:	Created pod: mt-broker-filter-846dc966c5-j7fmk
12:30:06 ReplicaSet mt-broker-filter-846dc966c5 4286:	Created pod: mt-broker-filter-846dc966c5-z7jk8
12:34:48 ReplicaSet mt-broker-filter-846dc966c5 6386:	Created pod: mt-broker-filter-846dc966c5-zzgx4
12:39:29 ReplicaSet mt-broker-filter-846dc966c5 8446:	Created pod: mt-broker-filter-846dc966c5-6m4d5
12:44:10 ReplicaSet mt-broker-filter-846dc966c5 10546:	Created pod: mt-broker-filter-846dc966c5-ph5xh
12:50:03 ReplicaSet mt-broker-filter-846dc966c5 12771:	Created pod: mt-broker-filter-846dc966c5-j5chn
12:21:27 Deployment mt-broker-filter 1211:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:30:06 Deployment mt-broker-filter 4285:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:34:48 Deployment mt-broker-filter 6385:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:39:29 Deployment mt-broker-filter 8445:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:44:10 Deployment mt-broker-filter 10545:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:50:03 Deployment mt-broker-filter 12770:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:44:11 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10575:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-6srd7 to acto-cluster-10-worker2
12:44:11 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10578:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:44:11 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10578:	Created container ingress
12:44:11 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10578:	Started container ingress
12:48:16 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10578:	Stopping container ingress
12:48:17 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10578:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:48:17 Pod mt-broker-ingress-6dbbfff4b9-6srd7 10578:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:21:27 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1231:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-bf4wj to acto-cluster-10-worker3
12:21:28 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 5.486415183s
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Created container ingress
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Started container ingress
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Readiness probe failed: Get "http://10.244.2.5:8080/healthz": dial tcp 10.244.2.5:8080: connect: connection refused
12:25:29 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Stopping container ingress
12:25:29 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:25:29 Pod mt-broker-ingress-6dbbfff4b9-bf4wj 1234:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:30:06 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4319:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-cdw62 to acto-cluster-10-worker
12:30:07 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4322:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:30:12 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4322:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 5.059705312s
12:30:12 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4322:	Created container ingress
12:30:12 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4322:	Started container ingress
12:30:12 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4322:	Readiness probe failed: Get "http://10.244.3.6:8080/healthz": dial tcp 10.244.3.6:8080: connect: connection refused
12:34:10 Pod mt-broker-ingress-6dbbfff4b9-cdw62 4322:	Stopping container ingress
12:34:49 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6415:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-m95tr to acto-cluster-10-worker3
12:34:49 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6418:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:34:49 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6418:	Created container ingress
12:34:49 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6418:	Started container ingress
12:38:51 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6418:	Stopping container ingress
12:38:51 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6418:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:38:51 Pod mt-broker-ingress-6dbbfff4b9-m95tr 6418:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:50:04 Pod mt-broker-ingress-6dbbfff4b9-pzxdq 12798:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-pzxdq to acto-cluster-10-worker3
12:50:04 Pod mt-broker-ingress-6dbbfff4b9-pzxdq 12800:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:50:04 Pod mt-broker-ingress-6dbbfff4b9-pzxdq 12800:	Created container ingress
12:50:05 Pod mt-broker-ingress-6dbbfff4b9-pzxdq 12800:	Started container ingress
12:39:30 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8471:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-slx8m to acto-cluster-10-worker2
12:39:30 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:39:33 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.646106567s
12:39:33 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Created container ingress
12:39:33 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Started container ingress
12:43:32 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Stopping container ingress
12:43:34 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:43:34 Pod mt-broker-ingress-6dbbfff4b9-slx8m 8473:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:21:27 ReplicaSet mt-broker-ingress-6dbbfff4b9 1229:	Created pod: mt-broker-ingress-6dbbfff4b9-bf4wj
12:30:06 ReplicaSet mt-broker-ingress-6dbbfff4b9 4317:	Created pod: mt-broker-ingress-6dbbfff4b9-cdw62
12:34:49 ReplicaSet mt-broker-ingress-6dbbfff4b9 6413:	Created pod: mt-broker-ingress-6dbbfff4b9-m95tr
12:39:30 ReplicaSet mt-broker-ingress-6dbbfff4b9 8469:	Created pod: mt-broker-ingress-6dbbfff4b9-slx8m
12:44:11 ReplicaSet mt-broker-ingress-6dbbfff4b9 10573:	Created pod: mt-broker-ingress-6dbbfff4b9-6srd7
12:50:04 ReplicaSet mt-broker-ingress-6dbbfff4b9 12796:	Created pod: mt-broker-ingress-6dbbfff4b9-pzxdq
12:21:27 Deployment mt-broker-ingress 1228:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:30:06 Deployment mt-broker-ingress 4314:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:34:49 Deployment mt-broker-ingress 6412:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:39:30 Deployment mt-broker-ingress 8468:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:44:11 Deployment mt-broker-ingress 10572:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:50:04 Deployment mt-broker-ingress 12795:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:50:05 Pod storage-version-migration-eventing-eventing-1.6.0--1-9sw6k 12842:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-9sw6k to acto-cluster-10-worker2
12:50:05 Pod storage-version-migration-eventing-eventing-1.6.0--1-9sw6k 12844:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:50:08 Pod storage-version-migration-eventing-eventing-1.6.0--1-9sw6k 12844:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.505612703s
12:50:08 Pod storage-version-migration-eventing-eventing-1.6.0--1-9sw6k 12844:	Created container migrate
12:50:08 Pod storage-version-migration-eventing-eventing-1.6.0--1-9sw6k 12844:	Started container migrate
12:39:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-c6ztt 8527:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-c6ztt to acto-cluster-10-worker3
12:39:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-c6ztt 8530:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:39:31 Pod storage-version-migration-eventing-eventing-1.6.0--1-c6ztt 8530:	Created container migrate
12:39:32 Pod storage-version-migration-eventing-eventing-1.6.0--1-c6ztt 8530:	Started container migrate
12:44:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-rvl8h 10626:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-rvl8h to acto-cluster-10-worker3
12:44:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-rvl8h 10629:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:44:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-rvl8h 10629:	Created container migrate
12:44:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-rvl8h 10629:	Started container migrate
12:30:07 Pod storage-version-migration-eventing-eventing-1.6.0--1-vd5n5 4383:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-vd5n5 to acto-cluster-10-worker3
12:30:08 Pod storage-version-migration-eventing-eventing-1.6.0--1-vd5n5 4385:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:30:10 Pod storage-version-migration-eventing-eventing-1.6.0--1-vd5n5 4385:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.490424776s
12:30:10 Pod storage-version-migration-eventing-eventing-1.6.0--1-vd5n5 4385:	Created container migrate
12:30:11 Pod storage-version-migration-eventing-eventing-1.6.0--1-vd5n5 4385:	Started container migrate
12:21:29 Pod storage-version-migration-eventing-eventing-1.6.0--1-xggfj 1292:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-xggfj to acto-cluster-10-worker
12:21:29 Pod storage-version-migration-eventing-eventing-1.6.0--1-xggfj 1294:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:21:32 Pod storage-version-migration-eventing-eventing-1.6.0--1-xggfj 1294:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 3.078889606s
12:21:32 Pod storage-version-migration-eventing-eventing-1.6.0--1-xggfj 1294:	Created container migrate
12:21:33 Pod storage-version-migration-eventing-eventing-1.6.0--1-xggfj 1294:	Started container migrate
12:34:50 Pod storage-version-migration-eventing-eventing-1.6.0--1-zwqg6 6467:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-zwqg6 to acto-cluster-10-worker3
12:34:50 Pod storage-version-migration-eventing-eventing-1.6.0--1-zwqg6 6469:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:34:50 Pod storage-version-migration-eventing-eventing-1.6.0--1-zwqg6 6469:	Created container migrate
12:34:51 Pod storage-version-migration-eventing-eventing-1.6.0--1-zwqg6 6469:	Started container migrate
12:21:29 Job storage-version-migration-eventing-eventing-1.6.0 1290:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-xggfj
12:21:38 Job storage-version-migration-eventing-eventing-1.6.0 1295:	Job completed
12:30:07 Job storage-version-migration-eventing-eventing-1.6.0 4382:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-vd5n5
12:30:16 Job storage-version-migration-eventing-eventing-1.6.0 4387:	Job completed
12:34:50 Job storage-version-migration-eventing-eventing-1.6.0 6466:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-zwqg6
12:34:56 Job storage-version-migration-eventing-eventing-1.6.0 6472:	Job completed
12:39:31 Job storage-version-migration-eventing-eventing-1.6.0 8526:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-c6ztt
12:39:37 Job storage-version-migration-eventing-eventing-1.6.0 8533:	Job completed
12:44:12 Job storage-version-migration-eventing-eventing-1.6.0 10625:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-rvl8h
12:44:18 Job storage-version-migration-eventing-eventing-1.6.0 10630:	Job completed
12:50:05 Job storage-version-migration-eventing-eventing-1.6.0 12841:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-9sw6k
12:50:14 Job storage-version-migration-eventing-eventing-1.6.0 12846:	Job completed
12:21:06 KnativeEventing test-cluster 844:	Updated "test-cluster" finalizers
12:26:59 KnativeEventing test-cluster 3073:	Updated "test-cluster" finalizers
12:27:09 KnativeEventing test-cluster 3073:	failed to apply (cluster)rolebindings: clusterrolebindings.rbac.authorization.k8s.io "eventing-sources-rabbitmq-controller" is forbidden: user "system:serviceaccount:knative-eventing:knative-operator" (groups=["system:serviceaccounts" "system:serviceaccounts:knative-eventing" "system:authenticated"]) is attempting to grant RBAC permissions not currently held:
{APIGroups:["rabbitmq.com"], Resources:["bindings"], Verbs:["create" "delete" "get" "list" "patch" "update" "watch"]}
{APIGroups:["rabbitmq.com"], Resources:["bindings/status"], Verbs:["get"]}
{APIGroups:["rabbitmq.com"], Resources:["exchanges"], Verbs:["create" "delete" "get" "list" "patch" "update" "watch"]}
{APIGroups:["rabbitmq.com"], Resources:["exchanges/status"], Verbs:["get"]}
{APIGroups:["rabbitmq.com"], Resources:["queues"], Verbs:["create" "delete" "get" "list" "patch" "update" "watch"]}
{APIGroups:["rabbitmq.com"], Resources:["queues/status"], Verbs:["get"]}
{APIGroups:["rabbitmq.com"], Resources:["rabbitmqclusters"], Verbs:["get" "list" "watch"]}
12:29:46 KnativeEventing test-cluster 3951:	Updated "test-cluster" finalizers
12:34:29 KnativeEventing test-cluster 6024:	Updated "test-cluster" finalizers
12:39:09 KnativeEventing test-cluster 8090:	Updated "test-cluster" finalizers
12:43:50 KnativeEventing test-cluster 10173:	Updated "test-cluster" finalizers
12:49:45 KnativeEventing test-cluster 12414:	Updated "test-cluster" finalizers
