12:23:03 HorizontalPodAutoscaler broker-filter-hpa 1442:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:23:03 HorizontalPodAutoscaler broker-filter-hpa 1442:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:28:53 HorizontalPodAutoscaler broker-filter-hpa 3635:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:28:53 HorizontalPodAutoscaler broker-filter-hpa 3635:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:35 HorizontalPodAutoscaler broker-filter-hpa 5890:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:35 HorizontalPodAutoscaler broker-filter-hpa 5890:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:28 HorizontalPodAutoscaler broker-filter-hpa 8438:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:28 HorizontalPodAutoscaler broker-filter-hpa 8438:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:46:33 HorizontalPodAutoscaler broker-filter-hpa 11071:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:46:33 HorizontalPodAutoscaler broker-filter-hpa 11071:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:54 HorizontalPodAutoscaler broker-filter-hpa 13301:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:55 HorizontalPodAutoscaler broker-filter-hpa 13301:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:23:03 HorizontalPodAutoscaler broker-ingress-hpa 1441:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:23:03 HorizontalPodAutoscaler broker-ingress-hpa 1441:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:28:52 HorizontalPodAutoscaler broker-ingress-hpa 3625:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:28:52 HorizontalPodAutoscaler broker-ingress-hpa 3625:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:35 HorizontalPodAutoscaler broker-ingress-hpa 5883:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:35 HorizontalPodAutoscaler broker-ingress-hpa 5883:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:27 HorizontalPodAutoscaler broker-ingress-hpa 8437:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:27 HorizontalPodAutoscaler broker-ingress-hpa 8437:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:46:33 HorizontalPodAutoscaler broker-ingress-hpa 11065:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:46:33 HorizontalPodAutoscaler broker-ingress-hpa 11065:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:54 HorizontalPodAutoscaler broker-ingress-hpa 13293:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:54 HorizontalPodAutoscaler broker-ingress-hpa 13293:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:33 Pod eventing-controller-6c78bb8c7f-2z6kn 13059:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-2z6kn to acto-cluster-12-worker2
12:52:34 Pod eventing-controller-6c78bb8c7f-2z6kn 13061:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:52:34 Pod eventing-controller-6c78bb8c7f-2z6kn 13061:	Created container eventing-controller
12:52:34 Pod eventing-controller-6c78bb8c7f-2z6kn 13061:	Started container eventing-controller
12:46:12 Pod eventing-controller-6c78bb8c7f-gzbsw 10820:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-gzbsw to acto-cluster-12-worker
12:46:12 Pod eventing-controller-6c78bb8c7f-gzbsw 10822:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:46:12 Pod eventing-controller-6c78bb8c7f-gzbsw 10822:	Created container eventing-controller
12:46:13 Pod eventing-controller-6c78bb8c7f-gzbsw 10822:	Started container eventing-controller
12:50:24 Pod eventing-controller-6c78bb8c7f-gzbsw 10822:	Stopping container eventing-controller
12:39:06 Pod eventing-controller-6c78bb8c7f-lv248 8192:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-lv248 to acto-cluster-12-worker
12:39:07 Pod eventing-controller-6c78bb8c7f-lv248 8195:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:39:07 Pod eventing-controller-6c78bb8c7f-lv248 8195:	Created container eventing-controller
12:39:07 Pod eventing-controller-6c78bb8c7f-lv248 8195:	Started container eventing-controller
12:43:24 Pod eventing-controller-6c78bb8c7f-lv248 8195:	Stopping container eventing-controller
12:28:31 Pod eventing-controller-6c78bb8c7f-p4cqb 3413:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-p4cqb to acto-cluster-12-worker
12:28:32 Pod eventing-controller-6c78bb8c7f-p4cqb 3415:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:28:32 Pod eventing-controller-6c78bb8c7f-p4cqb 3415:	Created container eventing-controller
12:28:32 Pod eventing-controller-6c78bb8c7f-p4cqb 3415:	Started container eventing-controller
12:32:45 Pod eventing-controller-6c78bb8c7f-p4cqb 3415:	Stopping container eventing-controller
12:22:41 Pod eventing-controller-6c78bb8c7f-pllcg 1211:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-pllcg to acto-cluster-12-worker
12:22:42 Pod eventing-controller-6c78bb8c7f-pllcg 1213:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:22:45 Pod eventing-controller-6c78bb8c7f-pllcg 1213:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.050963257s
12:22:45 Pod eventing-controller-6c78bb8c7f-pllcg 1213:	Created container eventing-controller
12:22:45 Pod eventing-controller-6c78bb8c7f-pllcg 1213:	Started container eventing-controller
12:26:54 Pod eventing-controller-6c78bb8c7f-pllcg 1213:	Stopping container eventing-controller
12:22:41 ReplicaSet eventing-controller-6c78bb8c7f 1208:	Created pod: eventing-controller-6c78bb8c7f-pllcg
12:28:31 ReplicaSet eventing-controller-6c78bb8c7f 3410:	Created pod: eventing-controller-6c78bb8c7f-p4cqb
12:39:06 ReplicaSet eventing-controller-6c78bb8c7f 8189:	Created pod: eventing-controller-6c78bb8c7f-lv248
12:46:12 ReplicaSet eventing-controller-6c78bb8c7f 10817:	Created pod: eventing-controller-6c78bb8c7f-gzbsw
12:52:33 ReplicaSet eventing-controller-6c78bb8c7f 13056:	Created pod: eventing-controller-6c78bb8c7f-2z6kn
12:33:14 Pod eventing-controller-779fbf8f65-2rdd4 5482:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-2rdd4 to acto-cluster-12-worker
12:33:15 Pod eventing-controller-779fbf8f65-2rdd4 5485:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:33:15 Pod eventing-controller-779fbf8f65-2rdd4 5485:	Created container eventing-controller
12:33:15 Pod eventing-controller-779fbf8f65-2rdd4 5485:	Started container eventing-controller
12:37:28 Pod eventing-controller-779fbf8f65-2rdd4 5485:	Stopping container eventing-controller
12:33:14 Pod eventing-controller-779fbf8f65-4tr7r 5492:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-4tr7r to acto-cluster-12-worker
12:33:15 Pod eventing-controller-779fbf8f65-4tr7r 5496:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:33:15 Pod eventing-controller-779fbf8f65-4tr7r 5496:	Created container eventing-controller
12:33:15 Pod eventing-controller-779fbf8f65-4tr7r 5496:	Started container eventing-controller
12:37:28 Pod eventing-controller-779fbf8f65-4tr7r 5496:	Stopping container eventing-controller
12:33:14 Pod eventing-controller-779fbf8f65-5flts 5486:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-5flts to acto-cluster-12-worker2
12:33:15 Pod eventing-controller-779fbf8f65-5flts 5491:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:33:17 Pod eventing-controller-779fbf8f65-5flts 5491:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.710995033s
12:33:18 Pod eventing-controller-779fbf8f65-5flts 5491:	Created container eventing-controller
12:33:18 Pod eventing-controller-779fbf8f65-5flts 5491:	Started container eventing-controller
12:37:28 Pod eventing-controller-779fbf8f65-5flts 5491:	Stopping container eventing-controller
12:33:14 Pod eventing-controller-779fbf8f65-pxmc5 5484:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-pxmc5 to acto-cluster-12-worker3
12:33:15 Pod eventing-controller-779fbf8f65-pxmc5 5490:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:33:18 Pod eventing-controller-779fbf8f65-pxmc5 5490:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.006260656s
12:33:18 Pod eventing-controller-779fbf8f65-pxmc5 5490:	Created container eventing-controller
12:33:18 Pod eventing-controller-779fbf8f65-pxmc5 5490:	Started container eventing-controller
12:37:28 Pod eventing-controller-779fbf8f65-pxmc5 5490:	Stopping container eventing-controller
12:33:14 ReplicaSet eventing-controller-779fbf8f65 5479:	Created pod: eventing-controller-779fbf8f65-2rdd4
12:33:14 ReplicaSet eventing-controller-779fbf8f65 5479:	Created pod: eventing-controller-779fbf8f65-pxmc5
12:33:14 ReplicaSet eventing-controller-779fbf8f65 5479:	Created pod: eventing-controller-779fbf8f65-5flts
12:33:14 ReplicaSet eventing-controller-779fbf8f65 5479:	Created pod: eventing-controller-779fbf8f65-4tr7r
12:22:41 Deployment eventing-controller 1207:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:28:31 Deployment eventing-controller 3409:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:33:14 Deployment eventing-controller 5478:	Scaled up replica set eventing-controller-779fbf8f65 to 4
12:39:06 Deployment eventing-controller 8188:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:46:12 Deployment eventing-controller 10816:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:52:33 Deployment eventing-controller 13055:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:28:32 Pod eventing-webhook-5755489569-66qjf 3438:	Successfully assigned knative-eventing/eventing-webhook-5755489569-66qjf to acto-cluster-12-worker2
12:28:33 Pod eventing-webhook-5755489569-66qjf 3441:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:28:33 Pod eventing-webhook-5755489569-66qjf 3441:	Created container eventing-webhook
12:28:34 Pod eventing-webhook-5755489569-66qjf 3441:	Started container eventing-webhook
12:28:34 Pod eventing-webhook-5755489569-66qjf 3441:	Readiness probe failed: Get "https://10.244.2.6:8443/": dial tcp 10.244.2.6:8443: connect: connection refused
12:32:44 Pod eventing-webhook-5755489569-66qjf 3441:	Liveness probe failed: Get "https://10.244.2.6:8443/": remote error: tls: unrecognized name
12:32:44 Pod eventing-webhook-5755489569-66qjf 3441:	Readiness probe failed: Get "https://10.244.2.6:8443/": remote error: tls: unrecognized name
12:32:45 Pod eventing-webhook-5755489569-66qjf 3441:	Stopping container eventing-webhook
12:33:15 Pod eventing-webhook-5755489569-7q74w 5531:	Successfully assigned knative-eventing/eventing-webhook-5755489569-7q74w to acto-cluster-12-worker3
12:33:16 Pod eventing-webhook-5755489569-7q74w 5537:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:33:20 Pod eventing-webhook-5755489569-7q74w 5537:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 4.417571124s
12:33:20 Pod eventing-webhook-5755489569-7q74w 5537:	Created container eventing-webhook
12:33:21 Pod eventing-webhook-5755489569-7q74w 5537:	Started container eventing-webhook
12:33:21 Pod eventing-webhook-5755489569-7q74w 5537:	Readiness probe failed: Get "https://10.244.3.8:8443/": dial tcp 10.244.3.8:8443: connect: connection refused
12:37:26 Pod eventing-webhook-5755489569-7q74w 5537:	Readiness probe failed: Get "https://10.244.3.8:8443/": remote error: tls: unrecognized name
12:37:26 Pod eventing-webhook-5755489569-7q74w 5537:	Liveness probe failed: Get "https://10.244.3.8:8443/": remote error: tls: unrecognized name
12:37:27 Pod eventing-webhook-5755489569-7q74w 5537:	Stopping container eventing-webhook
12:39:07 Pod eventing-webhook-5755489569-7qsxk 8217:	Successfully assigned knative-eventing/eventing-webhook-5755489569-7qsxk to acto-cluster-12-worker3
12:39:08 Pod eventing-webhook-5755489569-7qsxk 8221:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:39:08 Pod eventing-webhook-5755489569-7qsxk 8221:	Created container eventing-webhook
12:39:09 Pod eventing-webhook-5755489569-7qsxk 8221:	Started container eventing-webhook
12:39:09 Pod eventing-webhook-5755489569-7qsxk 8221:	Readiness probe failed: Get "https://10.244.3.16:8443/": dial tcp 10.244.3.16:8443: connect: connection refused
12:43:22 Pod eventing-webhook-5755489569-7qsxk 8221:	Liveness probe failed: Get "https://10.244.3.16:8443/": remote error: tls: unrecognized name
12:43:22 Pod eventing-webhook-5755489569-7qsxk 8221:	Readiness probe failed: Get "https://10.244.3.16:8443/": remote error: tls: unrecognized name
12:43:23 Pod eventing-webhook-5755489569-7qsxk 8221:	Stopping container eventing-webhook
12:46:13 Pod eventing-webhook-5755489569-f52ls 10845:	Successfully assigned knative-eventing/eventing-webhook-5755489569-f52ls to acto-cluster-12-worker3
12:46:14 Pod eventing-webhook-5755489569-f52ls 10848:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:46:14 Pod eventing-webhook-5755489569-f52ls 10848:	Created container eventing-webhook
12:46:14 Pod eventing-webhook-5755489569-f52ls 10848:	Started container eventing-webhook
12:46:14 Pod eventing-webhook-5755489569-f52ls 10848:	Readiness probe failed: Get "https://10.244.3.20:8443/": dial tcp 10.244.3.20:8443: connect: connection refused
12:46:15 Pod eventing-webhook-5755489569-f52ls 10848:	Readiness probe failed: Get "https://10.244.3.20:8443/": remote error: tls: unrecognized name
12:50:23 Pod eventing-webhook-5755489569-f52ls 10848:	Liveness probe failed: Get "https://10.244.3.20:8443/": remote error: tls: unrecognized name
12:50:24 Pod eventing-webhook-5755489569-f52ls 10848:	Stopping container eventing-webhook
12:52:34 Pod eventing-webhook-5755489569-r5jt6 13084:	Successfully assigned knative-eventing/eventing-webhook-5755489569-r5jt6 to acto-cluster-12-worker
12:52:35 Pod eventing-webhook-5755489569-r5jt6 13088:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:52:35 Pod eventing-webhook-5755489569-r5jt6 13088:	Created container eventing-webhook
12:52:36 Pod eventing-webhook-5755489569-r5jt6 13088:	Started container eventing-webhook
12:33:15 Pod eventing-webhook-5755489569-rhgp4 5527:	Successfully assigned knative-eventing/eventing-webhook-5755489569-rhgp4 to acto-cluster-12-worker
12:33:16 Pod eventing-webhook-5755489569-rhgp4 5530:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:33:19 Pod eventing-webhook-5755489569-rhgp4 5530:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.733780657s
12:33:19 Pod eventing-webhook-5755489569-rhgp4 5530:	Created container eventing-webhook
12:33:19 Pod eventing-webhook-5755489569-rhgp4 5530:	Started container eventing-webhook
12:33:20 Pod eventing-webhook-5755489569-rhgp4 5530:	Readiness probe failed: Get "https://10.244.1.9:8443/": dial tcp 10.244.1.9:8443: connect: connection refused
12:37:26 Pod eventing-webhook-5755489569-rhgp4 5530:	Liveness probe failed: Get "https://10.244.1.9:8443/": remote error: tls: unrecognized name
12:37:26 Pod eventing-webhook-5755489569-rhgp4 5530:	Readiness probe failed: Get "https://10.244.1.9:8443/": remote error: tls: unrecognized name
12:37:27 Pod eventing-webhook-5755489569-rhgp4 5530:	Stopping container eventing-webhook
12:22:42 Pod eventing-webhook-5755489569-vb4rz 1236:	Successfully assigned knative-eventing/eventing-webhook-5755489569-vb4rz to acto-cluster-12-worker2
12:22:43 Pod eventing-webhook-5755489569-vb4rz 1240:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:22:46 Pod eventing-webhook-5755489569-vb4rz 1240:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.796007491s
12:22:46 Pod eventing-webhook-5755489569-vb4rz 1240:	Created container eventing-webhook
12:22:46 Pod eventing-webhook-5755489569-vb4rz 1240:	Started container eventing-webhook
12:22:46 Pod eventing-webhook-5755489569-vb4rz 1240:	Readiness probe failed: Get "https://10.244.2.3:8443/": dial tcp 10.244.2.3:8443: connect: connection refused
12:22:47 Pod eventing-webhook-5755489569-vb4rz 1240:	Readiness probe failed: Get "https://10.244.2.3:8443/": remote error: tls: unrecognized name
12:26:53 Pod eventing-webhook-5755489569-vb4rz 1240:	Liveness probe failed: Get "https://10.244.2.3:8443/": remote error: tls: unrecognized name
12:26:53 Pod eventing-webhook-5755489569-vb4rz 1240:	Stopping container eventing-webhook
12:33:15 Pod eventing-webhook-5755489569-wk4x7 5532:	Successfully assigned knative-eventing/eventing-webhook-5755489569-wk4x7 to acto-cluster-12-worker2
12:33:16 Pod eventing-webhook-5755489569-wk4x7 5539:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:33:16 Pod eventing-webhook-5755489569-wk4x7 5539:	Created container eventing-webhook
12:33:17 Pod eventing-webhook-5755489569-wk4x7 5539:	Started container eventing-webhook
12:33:17 Pod eventing-webhook-5755489569-wk4x7 5539:	Readiness probe failed: Get "https://10.244.2.11:8443/": dial tcp 10.244.2.11:8443: connect: connection refused
12:37:26 Pod eventing-webhook-5755489569-wk4x7 5539:	Readiness probe failed: Get "https://10.244.2.11:8443/": remote error: tls: unrecognized name
12:37:26 Pod eventing-webhook-5755489569-wk4x7 5539:	Liveness probe failed: Get "https://10.244.2.11:8443/": remote error: tls: unrecognized name
12:37:27 Pod eventing-webhook-5755489569-wk4x7 5539:	Stopping container eventing-webhook
12:33:15 Pod eventing-webhook-5755489569-xm9hj 5538:	Successfully assigned knative-eventing/eventing-webhook-5755489569-xm9hj to acto-cluster-12-worker
12:33:16 Pod eventing-webhook-5755489569-xm9hj 5543:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:33:19 Pod eventing-webhook-5755489569-xm9hj 5543:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.994623806s
12:33:19 Pod eventing-webhook-5755489569-xm9hj 5543:	Created container eventing-webhook
12:33:20 Pod eventing-webhook-5755489569-xm9hj 5543:	Started container eventing-webhook
12:37:26 Pod eventing-webhook-5755489569-xm9hj 5543:	Readiness probe failed: Get "https://10.244.1.10:8443/": remote error: tls: unrecognized name
12:37:26 Pod eventing-webhook-5755489569-xm9hj 5543:	Liveness probe failed: Get "https://10.244.1.10:8443/": remote error: tls: unrecognized name
12:37:27 Pod eventing-webhook-5755489569-xm9hj 5543:	Stopping container eventing-webhook
12:22:42 ReplicaSet eventing-webhook-5755489569 1234:	Created pod: eventing-webhook-5755489569-vb4rz
12:28:32 ReplicaSet eventing-webhook-5755489569 3435:	Created pod: eventing-webhook-5755489569-66qjf
12:33:15 ReplicaSet eventing-webhook-5755489569 5525:	Created pod: eventing-webhook-5755489569-rhgp4
12:33:15 ReplicaSet eventing-webhook-5755489569 5525:	Created pod: eventing-webhook-5755489569-7q74w
12:33:15 ReplicaSet eventing-webhook-5755489569 5525:	Created pod: eventing-webhook-5755489569-wk4x7
12:33:15 ReplicaSet eventing-webhook-5755489569 5525:	Created pod: eventing-webhook-5755489569-xm9hj
12:39:07 ReplicaSet eventing-webhook-5755489569 8215:	Created pod: eventing-webhook-5755489569-7qsxk
12:46:13 ReplicaSet eventing-webhook-5755489569 10843:	Created pod: eventing-webhook-5755489569-f52ls
12:52:34 ReplicaSet eventing-webhook-5755489569 13082:	Created pod: eventing-webhook-5755489569-r5jt6
12:22:42 PodDisruptionBudget eventing-webhook 1226:	No matching pods found
12:22:42 Deployment eventing-webhook 1233:	Scaled up replica set eventing-webhook-5755489569 to 1
12:22:56 HorizontalPodAutoscaler eventing-webhook 1225:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:22:57 HorizontalPodAutoscaler eventing-webhook 1225:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:26:53 PodDisruptionBudget eventing-webhook 1707:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:28:32 PodDisruptionBudget eventing-webhook 3428:	No matching pods found
12:28:32 Deployment eventing-webhook 3434:	Scaled up replica set eventing-webhook-5755489569 to 1
12:28:47 HorizontalPodAutoscaler eventing-webhook 3427:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:28:47 HorizontalPodAutoscaler eventing-webhook 3427:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:45 PodDisruptionBudget eventing-webhook 3893:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:33:15 PodDisruptionBudget eventing-webhook 5514:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:33:15 Deployment eventing-webhook 5524:	Scaled up replica set eventing-webhook-5755489569 to 4
12:33:15 PodDisruptionBudget eventing-webhook 5516:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-66qjf"
12:33:30 HorizontalPodAutoscaler eventing-webhook 5511:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:33:30 HorizontalPodAutoscaler eventing-webhook 5511:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:07 PodDisruptionBudget eventing-webhook 8208:	No matching pods found
12:39:07 Deployment eventing-webhook 8214:	Scaled up replica set eventing-webhook-5755489569 to 1
12:39:22 HorizontalPodAutoscaler eventing-webhook 8207:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:22 HorizontalPodAutoscaler eventing-webhook 8207:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:43:23 PodDisruptionBudget eventing-webhook 8791:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:46:12 PodDisruptionBudget eventing-webhook 10836:	No matching pods found
12:46:13 Deployment eventing-webhook 10842:	Scaled up replica set eventing-webhook-5755489569 to 1
12:46:27 HorizontalPodAutoscaler eventing-webhook 10834:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:46:27 HorizontalPodAutoscaler eventing-webhook 10834:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:34 PodDisruptionBudget eventing-webhook 13076:	No matching pods found
12:52:34 Deployment eventing-webhook 13081:	Scaled up replica set eventing-webhook-5755489569 to 1
12:52:49 HorizontalPodAutoscaler eventing-webhook 13073:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:52:49 HorizontalPodAutoscaler eventing-webhook 13073:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:39:14 Pod github-controller-manager-0 8501:	Successfully assigned knative-eventing/github-controller-manager-0 to acto-cluster-12-worker
12:39:15 Pod github-controller-manager-0 8504:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-github/cmd/controller@sha256:e63d90d9b5897c7e908ef3f905d2c8226817ee574e961dc5009229227a1b9eaa"
12:39:18 Pod github-controller-manager-0 8504:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-github/cmd/controller@sha256:e63d90d9b5897c7e908ef3f905d2c8226817ee574e961dc5009229227a1b9eaa" in 2.809306342s
12:39:18 Pod github-controller-manager-0 8504:	Created container manager
12:39:18 Pod github-controller-manager-0 8504:	Started container manager
12:43:17 Pod github-controller-manager-0 8504:	Stopping container manager
12:39:14 StatefulSet github-controller-manager 8499:	create Pod github-controller-manager-0 in StatefulSet github-controller-manager successful
12:39:15 Pod github-webhook-65b4486fcc-kqbm5 8512:	Successfully assigned knative-eventing/github-webhook-65b4486fcc-kqbm5 to acto-cluster-12-worker3
12:39:15 Pod github-webhook-65b4486fcc-kqbm5 8515:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-github/cmd/webhook@sha256:ce863fdb84017d3bdf6cf65f48227f0066a91fe2da67521ef563f8c4af206b91"
12:39:19 Pod github-webhook-65b4486fcc-kqbm5 8515:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-github/cmd/webhook@sha256:ce863fdb84017d3bdf6cf65f48227f0066a91fe2da67521ef563f8c4af206b91" in 3.35796295s
12:39:19 Pod github-webhook-65b4486fcc-kqbm5 8515:	Created container github-webhook
12:39:19 Pod github-webhook-65b4486fcc-kqbm5 8515:	Started container github-webhook
12:43:17 Pod github-webhook-65b4486fcc-kqbm5 8515:	Readiness probe failed: Get "https://10.244.3.19:8443/": remote error: tls: unrecognized name
12:43:17 Pod github-webhook-65b4486fcc-kqbm5 8515:	Liveness probe failed: Get "https://10.244.3.19:8443/": remote error: tls: unrecognized name
12:43:17 Pod github-webhook-65b4486fcc-kqbm5 8515:	Stopping container github-webhook
12:39:15 ReplicaSet github-webhook-65b4486fcc 8510:	Created pod: github-webhook-65b4486fcc-kqbm5
12:39:15 Deployment github-webhook 8509:	Scaled up replica set github-webhook-65b4486fcc to 1
12:22:46 Pod imc-controller-567b4f565b-7b8qv 1289:	Successfully assigned knative-eventing/imc-controller-567b4f565b-7b8qv to acto-cluster-12-worker2
12:22:46 Pod imc-controller-567b4f565b-7b8qv 1294:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:22:49 Pod imc-controller-567b4f565b-7b8qv 1294:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.69897378s
12:22:49 Pod imc-controller-567b4f565b-7b8qv 1294:	Created container controller
12:22:49 Pod imc-controller-567b4f565b-7b8qv 1294:	Started container controller
12:26:51 Pod imc-controller-567b4f565b-7b8qv 1294:	Readiness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:26:51 Pod imc-controller-567b4f565b-7b8qv 1294:	Liveness probe failed: Get "https://10.244.2.4:8443/": remote error: tls: unrecognized name
12:26:51 Pod imc-controller-567b4f565b-7b8qv 1294:	Stopping container controller
12:46:15 Pod imc-controller-567b4f565b-82vfp 10932:	Successfully assigned knative-eventing/imc-controller-567b4f565b-82vfp to acto-cluster-12-worker3
12:46:16 Pod imc-controller-567b4f565b-82vfp 10936:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:46:16 Pod imc-controller-567b4f565b-82vfp 10936:	Created container controller
12:46:16 Pod imc-controller-567b4f565b-82vfp 10936:	Started container controller
12:46:16 Pod imc-controller-567b4f565b-82vfp 10936:	Readiness probe failed: Get "https://10.244.3.21:8443/": dial tcp 10.244.3.21:8443: connect: connection refused
12:46:16 Pod imc-controller-567b4f565b-82vfp 10936:	Readiness probe failed: Get "https://10.244.3.21:8443/": remote error: tls: unrecognized name
12:50:20 Pod imc-controller-567b4f565b-82vfp 10936:	Liveness probe failed: Get "https://10.244.3.21:8443/": remote error: tls: unrecognized name
12:50:21 Pod imc-controller-567b4f565b-82vfp 10936:	Stopping container controller
12:33:18 Pod imc-controller-567b4f565b-fbfc7 5637:	Successfully assigned knative-eventing/imc-controller-567b4f565b-fbfc7 to acto-cluster-12-worker2
12:33:18 Pod imc-controller-567b4f565b-fbfc7 5641:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:33:18 Pod imc-controller-567b4f565b-fbfc7 5641:	Created container controller
12:33:18 Pod imc-controller-567b4f565b-fbfc7 5641:	Started container controller
12:37:24 Pod imc-controller-567b4f565b-fbfc7 5641:	Liveness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-fbfc7 5641:	Readiness probe failed: Get "https://10.244.2.12:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-fbfc7 5641:	Stopping container controller
12:33:18 Pod imc-controller-567b4f565b-k7fst 5639:	Successfully assigned knative-eventing/imc-controller-567b4f565b-k7fst to acto-cluster-12-worker
12:33:19 Pod imc-controller-567b4f565b-k7fst 5643:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:33:22 Pod imc-controller-567b4f565b-k7fst 5643:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 3.372874379s
12:33:22 Pod imc-controller-567b4f565b-k7fst 5643:	Created container controller
12:33:22 Pod imc-controller-567b4f565b-k7fst 5643:	Started container controller
12:37:24 Pod imc-controller-567b4f565b-k7fst 5643:	Readiness probe failed: Get "https://10.244.1.11:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-k7fst 5643:	Liveness probe failed: Get "https://10.244.1.11:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-k7fst 5643:	Stopping container controller
12:52:37 Pod imc-controller-567b4f565b-kccnc 13165:	Successfully assigned knative-eventing/imc-controller-567b4f565b-kccnc to acto-cluster-12-worker3
12:52:37 Pod imc-controller-567b4f565b-kccnc 13168:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:52:37 Pod imc-controller-567b4f565b-kccnc 13168:	Created container controller
12:52:38 Pod imc-controller-567b4f565b-kccnc 13168:	Started container controller
12:28:35 Pod imc-controller-567b4f565b-nk4jt 3523:	Successfully assigned knative-eventing/imc-controller-567b4f565b-nk4jt to acto-cluster-12-worker3
12:28:35 Pod imc-controller-567b4f565b-nk4jt 3526:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:28:38 Pod imc-controller-567b4f565b-nk4jt 3526:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.795243464s
12:28:38 Pod imc-controller-567b4f565b-nk4jt 3526:	Created container controller
12:28:38 Pod imc-controller-567b4f565b-nk4jt 3526:	Started container controller
12:32:42 Pod imc-controller-567b4f565b-nk4jt 3526:	Liveness probe failed: Get "https://10.244.3.5:8443/": remote error: tls: unrecognized name
12:32:42 Pod imc-controller-567b4f565b-nk4jt 3526:	Readiness probe failed: Get "https://10.244.3.5:8443/": remote error: tls: unrecognized name
12:32:42 Pod imc-controller-567b4f565b-nk4jt 3526:	Stopping container controller
12:33:18 Pod imc-controller-567b4f565b-prh4g 5648:	Successfully assigned knative-eventing/imc-controller-567b4f565b-prh4g to acto-cluster-12-worker2
12:33:18 Pod imc-controller-567b4f565b-prh4g 5651:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:33:19 Pod imc-controller-567b4f565b-prh4g 5651:	Created container controller
12:33:19 Pod imc-controller-567b4f565b-prh4g 5651:	Started container controller
12:37:24 Pod imc-controller-567b4f565b-prh4g 5651:	Readiness probe failed: Get "https://10.244.2.13:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-prh4g 5651:	Liveness probe failed: Get "https://10.244.2.13:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-prh4g 5651:	Stopping container controller
12:39:10 Pod imc-controller-567b4f565b-pt289 8301:	Successfully assigned knative-eventing/imc-controller-567b4f565b-pt289 to acto-cluster-12-worker2
12:39:11 Pod imc-controller-567b4f565b-pt289 8304:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:39:11 Pod imc-controller-567b4f565b-pt289 8304:	Created container controller
12:39:11 Pod imc-controller-567b4f565b-pt289 8304:	Started container controller
12:39:11 Pod imc-controller-567b4f565b-pt289 8304:	Readiness probe failed: Get "https://10.244.2.19:8443/": remote error: tls: unrecognized name
12:43:20 Pod imc-controller-567b4f565b-pt289 8304:	Liveness probe failed: Get "https://10.244.2.19:8443/": remote error: tls: unrecognized name
12:43:21 Pod imc-controller-567b4f565b-pt289 8304:	Stopping container controller
12:33:18 Pod imc-controller-567b4f565b-vmwbc 5640:	Successfully assigned knative-eventing/imc-controller-567b4f565b-vmwbc to acto-cluster-12-worker3
12:33:18 Pod imc-controller-567b4f565b-vmwbc 5645:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:33:19 Pod imc-controller-567b4f565b-vmwbc 5645:	Created container controller
12:33:19 Pod imc-controller-567b4f565b-vmwbc 5645:	Started container controller
12:37:24 Pod imc-controller-567b4f565b-vmwbc 5645:	Readiness probe failed: Get "https://10.244.3.9:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-vmwbc 5645:	Liveness probe failed: Get "https://10.244.3.9:8443/": remote error: tls: unrecognized name
12:37:24 Pod imc-controller-567b4f565b-vmwbc 5645:	Stopping container controller
12:22:46 ReplicaSet imc-controller-567b4f565b 1287:	Created pod: imc-controller-567b4f565b-7b8qv
12:28:35 ReplicaSet imc-controller-567b4f565b 3521:	Created pod: imc-controller-567b4f565b-nk4jt
12:33:18 ReplicaSet imc-controller-567b4f565b 5634:	Created pod: imc-controller-567b4f565b-fbfc7
12:33:18 ReplicaSet imc-controller-567b4f565b 5634:	Created pod: imc-controller-567b4f565b-k7fst
12:33:18 ReplicaSet imc-controller-567b4f565b 5634:	Created pod: imc-controller-567b4f565b-vmwbc
12:33:18 ReplicaSet imc-controller-567b4f565b 5634:	Created pod: imc-controller-567b4f565b-prh4g
12:39:10 ReplicaSet imc-controller-567b4f565b 8299:	Created pod: imc-controller-567b4f565b-pt289
12:46:15 ReplicaSet imc-controller-567b4f565b 10930:	Created pod: imc-controller-567b4f565b-82vfp
12:52:37 ReplicaSet imc-controller-567b4f565b 13163:	Created pod: imc-controller-567b4f565b-kccnc
12:22:46 Deployment imc-controller 1286:	Scaled up replica set imc-controller-567b4f565b to 1
12:28:35 Deployment imc-controller 3520:	Scaled up replica set imc-controller-567b4f565b to 1
12:33:18 Deployment imc-controller 5633:	Scaled up replica set imc-controller-567b4f565b to 4
12:39:10 Deployment imc-controller 8298:	Scaled up replica set imc-controller-567b4f565b to 1
12:46:15 Deployment imc-controller 10929:	Scaled up replica set imc-controller-567b4f565b to 1
12:52:37 Deployment imc-controller 13162:	Scaled up replica set imc-controller-567b4f565b to 1
12:33:18 Pod imc-dispatcher-545bcb44c5-6xz8f 5692:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-6xz8f to acto-cluster-12-worker2
12:33:19 Pod imc-dispatcher-545bcb44c5-6xz8f 5696:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:33:19 Pod imc-dispatcher-545bcb44c5-6xz8f 5696:	Created container dispatcher
12:33:19 Pod imc-dispatcher-545bcb44c5-6xz8f 5696:	Started container dispatcher
12:37:24 Pod imc-dispatcher-545bcb44c5-6xz8f 5696:	Stopping container dispatcher
12:37:25 Pod imc-dispatcher-545bcb44c5-6xz8f 5696:	Readiness probe failed: Get "http://10.244.2.14:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:37:25 Pod imc-dispatcher-545bcb44c5-6xz8f 5696:	Liveness probe failed: Get "http://10.244.2.14:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:33:18 Pod imc-dispatcher-545bcb44c5-8mbpp 5698:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-8mbpp to acto-cluster-12-worker
12:33:19 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:33:25 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 6.029264601s
12:33:25 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Created container dispatcher
12:33:25 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Started container dispatcher
12:37:24 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Stopping container dispatcher
12:37:25 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Readiness probe failed: Get "http://10.244.1.12:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:37:25 Pod imc-dispatcher-545bcb44c5-8mbpp 5702:	Liveness probe failed: Get "http://10.244.1.12:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:22:46 Pod imc-dispatcher-545bcb44c5-g4k6l 1338:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-g4k6l to acto-cluster-12-worker3
12:22:47 Pod imc-dispatcher-545bcb44c5-g4k6l 1341:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:22:50 Pod imc-dispatcher-545bcb44c5-g4k6l 1341:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.775523425s
12:22:50 Pod imc-dispatcher-545bcb44c5-g4k6l 1341:	Created container dispatcher
12:22:50 Pod imc-dispatcher-545bcb44c5-g4k6l 1341:	Started container dispatcher
12:26:50 Pod imc-dispatcher-545bcb44c5-g4k6l 1341:	Stopping container dispatcher
12:33:18 Pod imc-dispatcher-545bcb44c5-jlzs5 5697:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-jlzs5 to acto-cluster-12-worker3
12:33:19 Pod imc-dispatcher-545bcb44c5-jlzs5 5701:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:33:19 Pod imc-dispatcher-545bcb44c5-jlzs5 5701:	Created container dispatcher
12:33:19 Pod imc-dispatcher-545bcb44c5-jlzs5 5701:	Started container dispatcher
12:37:24 Pod imc-dispatcher-545bcb44c5-jlzs5 5701:	Stopping container dispatcher
12:37:25 Pod imc-dispatcher-545bcb44c5-jlzs5 5701:	Liveness probe failed: Get "http://10.244.3.10:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:37:25 Pod imc-dispatcher-545bcb44c5-jlzs5 5701:	Readiness probe failed: Get "http://10.244.3.10:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:46:16 Pod imc-dispatcher-545bcb44c5-jznjg 10961:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-jznjg to acto-cluster-12-worker2
12:46:17 Pod imc-dispatcher-545bcb44c5-jznjg 10964:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:46:17 Pod imc-dispatcher-545bcb44c5-jznjg 10964:	Created container dispatcher
12:46:17 Pod imc-dispatcher-545bcb44c5-jznjg 10964:	Started container dispatcher
12:50:21 Pod imc-dispatcher-545bcb44c5-jznjg 10964:	Stopping container dispatcher
12:39:11 Pod imc-dispatcher-545bcb44c5-lts9g 8331:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-lts9g to acto-cluster-12-worker3
12:39:11 Pod imc-dispatcher-545bcb44c5-lts9g 8335:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:39:11 Pod imc-dispatcher-545bcb44c5-lts9g 8335:	Created container dispatcher
12:39:11 Pod imc-dispatcher-545bcb44c5-lts9g 8335:	Started container dispatcher
12:43:20 Pod imc-dispatcher-545bcb44c5-lts9g 8335:	Stopping container dispatcher
12:43:22 Pod imc-dispatcher-545bcb44c5-lts9g 8335:	Readiness probe failed: Get "http://10.244.3.17:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:43:22 Pod imc-dispatcher-545bcb44c5-lts9g 8335:	Liveness probe failed: Get "http://10.244.3.17:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:33:18 Pod imc-dispatcher-545bcb44c5-p98kv 5703:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-p98kv to acto-cluster-12-worker
12:33:19 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:33:25 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 5.637343443s
12:33:25 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Created container dispatcher
12:33:25 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Started container dispatcher
12:37:24 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Stopping container dispatcher
12:37:25 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Liveness probe failed: Get "http://10.244.1.13:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:37:25 Pod imc-dispatcher-545bcb44c5-p98kv 5708:	Readiness probe failed: Get "http://10.244.1.13:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:52:37 Pod imc-dispatcher-545bcb44c5-q488c 13194:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-q488c to acto-cluster-12-worker
12:52:38 Pod imc-dispatcher-545bcb44c5-q488c 13198:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:52:38 Pod imc-dispatcher-545bcb44c5-q488c 13198:	Created container dispatcher
12:52:38 Pod imc-dispatcher-545bcb44c5-q488c 13198:	Started container dispatcher
12:28:35 Pod imc-dispatcher-545bcb44c5-s88c2 3551:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-s88c2 to acto-cluster-12-worker2
12:28:36 Pod imc-dispatcher-545bcb44c5-s88c2 3555:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:28:39 Pod imc-dispatcher-545bcb44c5-s88c2 3555:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.727782897s
12:28:39 Pod imc-dispatcher-545bcb44c5-s88c2 3555:	Created container dispatcher
12:28:39 Pod imc-dispatcher-545bcb44c5-s88c2 3555:	Started container dispatcher
12:32:42 Pod imc-dispatcher-545bcb44c5-s88c2 3555:	Stopping container dispatcher
12:22:46 ReplicaSet imc-dispatcher-545bcb44c5 1335:	Created pod: imc-dispatcher-545bcb44c5-g4k6l
12:28:35 ReplicaSet imc-dispatcher-545bcb44c5 3549:	Created pod: imc-dispatcher-545bcb44c5-s88c2
12:33:18 ReplicaSet imc-dispatcher-545bcb44c5 5690:	Created pod: imc-dispatcher-545bcb44c5-6xz8f
12:33:18 ReplicaSet imc-dispatcher-545bcb44c5 5690:	Created pod: imc-dispatcher-545bcb44c5-jlzs5
12:33:18 ReplicaSet imc-dispatcher-545bcb44c5 5690:	Created pod: imc-dispatcher-545bcb44c5-8mbpp
12:33:18 ReplicaSet imc-dispatcher-545bcb44c5 5690:	Created pod: imc-dispatcher-545bcb44c5-p98kv
12:39:11 ReplicaSet imc-dispatcher-545bcb44c5 8329:	Created pod: imc-dispatcher-545bcb44c5-lts9g
12:46:16 ReplicaSet imc-dispatcher-545bcb44c5 10958:	Created pod: imc-dispatcher-545bcb44c5-jznjg
12:52:37 ReplicaSet imc-dispatcher-545bcb44c5 13191:	Created pod: imc-dispatcher-545bcb44c5-q488c
12:22:46 Deployment imc-dispatcher 1334:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:28:35 Deployment imc-dispatcher 3548:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:33:18 Deployment imc-dispatcher 5689:	Scaled up replica set imc-dispatcher-545bcb44c5 to 4
12:37:24 Endpoints imc-dispatcher 6112:	Failed to update endpoint knative-eventing/imc-dispatcher: Operation cannot be fulfilled on endpoints "imc-dispatcher": the object has been modified; please apply your changes to the latest version and try again
12:39:11 Deployment imc-dispatcher 8327:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:46:16 Deployment imc-dispatcher 10957:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:52:37 Deployment imc-dispatcher 13190:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:52:41 Pod kafka-controller-manager-5f4fbfbf4f-7vgx9 13366:	Successfully assigned knative-eventing/kafka-controller-manager-5f4fbfbf4f-7vgx9 to acto-cluster-12-worker3
12:52:42 Pod kafka-controller-manager-5f4fbfbf4f-7vgx9 13371:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-kafka/cmd/source/controller@sha256:e07d09e93891ba1341f4fcf9b0fad67b37ff1c4e1d01844790bdb7fd589992f1"
12:52:45 Pod kafka-controller-manager-5f4fbfbf4f-7vgx9 13371:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-kafka/cmd/source/controller@sha256:e07d09e93891ba1341f4fcf9b0fad67b37ff1c4e1d01844790bdb7fd589992f1" in 3.212042689s
12:52:45 Pod kafka-controller-manager-5f4fbfbf4f-7vgx9 13371:	Created container manager
12:52:45 Pod kafka-controller-manager-5f4fbfbf4f-7vgx9 13371:	Started container manager
12:52:45 Pod kafka-controller-manager-5f4fbfbf4f-7vgx9 13371:	Readiness probe failed: Get "https://10.244.3.24:8443/": remote error: tls: unrecognized name
12:52:41 ReplicaSet kafka-controller-manager-5f4fbfbf4f 13365:	Created pod: kafka-controller-manager-5f4fbfbf4f-7vgx9
12:52:41 Deployment kafka-controller-manager 13364:	Scaled up replica set kafka-controller-manager-5f4fbfbf4f to 1
12:20:58 Pod knative-operator-668fb586bb-dz8tq 802:	Successfully assigned knative-eventing/knative-operator-668fb586bb-dz8tq to acto-cluster-12-worker3
12:20:59 Pod knative-operator-668fb586bb-dz8tq 806:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:02 Pod knative-operator-668fb586bb-dz8tq 806:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.104452728s
12:21:02 Pod knative-operator-668fb586bb-dz8tq 806:	Created container knative-operator
12:21:02 Pod knative-operator-668fb586bb-dz8tq 806:	Started container knative-operator
12:27:08 Pod knative-operator-668fb586bb-dz8tq 806:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:43:40 Pod knative-operator-668fb586bb-dz8tq 806:	Back-off restarting failed container
12:20:58 ReplicaSet knative-operator-668fb586bb 800:	Created pod: knative-operator-668fb586bb-dz8tq
12:20:48 Pod knative-operator-79bf74d66d-vq8k9 761:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-vq8k9 to acto-cluster-12-worker2
12:20:48 Pod knative-operator-79bf74d66d-vq8k9 764:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:20:52 Pod knative-operator-79bf74d66d-vq8k9 764:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.205199486s
12:20:52 Pod knative-operator-79bf74d66d-vq8k9 764:	Created container knative-operator
12:20:52 Pod knative-operator-79bf74d66d-vq8k9 764:	Started container knative-operator
12:21:02 Pod knative-operator-79bf74d66d-vq8k9 764:	Stopping container knative-operator
12:20:48 ReplicaSet knative-operator-79bf74d66d 758:	Created pod: knative-operator-79bf74d66d-vq8k9
12:21:02 ReplicaSet knative-operator-79bf74d66d 828:	Deleted pod: knative-operator-79bf74d66d-vq8k9
12:20:48 Deployment knative-operator 756:	Scaled up replica set knative-operator-79bf74d66d to 1
12:20:58 Deployment knative-operator 798:	Scaled up replica set knative-operator-668fb586bb to 1
12:21:02 Deployment knative-operator 814:	Scaled down replica set knative-operator-79bf74d66d to 0
12:33:20 Pod mt-broker-controller-56cc5dc5cc-76ckx 5858:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-76ckx to acto-cluster-12-worker
12:33:21 Pod mt-broker-controller-56cc5dc5cc-76ckx 5862:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:33:21 Pod mt-broker-controller-56cc5dc5cc-76ckx 5862:	Created container mt-broker-controller
12:33:21 Pod mt-broker-controller-56cc5dc5cc-76ckx 5862:	Started container mt-broker-controller
12:37:23 Pod mt-broker-controller-56cc5dc5cc-76ckx 5862:	Stopping container mt-broker-controller
12:46:18 Pod mt-broker-controller-56cc5dc5cc-7fhfz 11055:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-7fhfz to acto-cluster-12-worker2
12:46:18 Pod mt-broker-controller-56cc5dc5cc-7fhfz 11058:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:46:18 Pod mt-broker-controller-56cc5dc5cc-7fhfz 11058:	Created container mt-broker-controller
12:46:18 Pod mt-broker-controller-56cc5dc5cc-7fhfz 11058:	Started container mt-broker-controller
12:50:19 Pod mt-broker-controller-56cc5dc5cc-7fhfz 11058:	Stopping container mt-broker-controller
12:28:37 Pod mt-broker-controller-56cc5dc5cc-7ltsb 3614:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-7ltsb to acto-cluster-12-worker2
12:28:38 Pod mt-broker-controller-56cc5dc5cc-7ltsb 3618:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:28:42 Pod mt-broker-controller-56cc5dc5cc-7ltsb 3618:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 3.74870495s
12:28:42 Pod mt-broker-controller-56cc5dc5cc-7ltsb 3618:	Created container mt-broker-controller
12:28:42 Pod mt-broker-controller-56cc5dc5cc-7ltsb 3618:	Started container mt-broker-controller
12:32:41 Pod mt-broker-controller-56cc5dc5cc-7ltsb 3618:	Stopping container mt-broker-controller
12:39:12 Pod mt-broker-controller-56cc5dc5cc-94m2z 8417:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-94m2z to acto-cluster-12-worker
12:39:13 Pod mt-broker-controller-56cc5dc5cc-94m2z 8422:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:39:13 Pod mt-broker-controller-56cc5dc5cc-94m2z 8422:	Created container mt-broker-controller
12:39:13 Pod mt-broker-controller-56cc5dc5cc-94m2z 8422:	Started container mt-broker-controller
12:43:18 Pod mt-broker-controller-56cc5dc5cc-94m2z 8422:	Stopping container mt-broker-controller
12:33:20 Pod mt-broker-controller-56cc5dc5cc-kcg9d 5863:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-kcg9d to acto-cluster-12-worker3
12:33:21 Pod mt-broker-controller-56cc5dc5cc-kcg9d 5868:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:33:26 Pod mt-broker-controller-56cc5dc5cc-kcg9d 5868:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 5.185718315s
12:33:26 Pod mt-broker-controller-56cc5dc5cc-kcg9d 5868:	Created container mt-broker-controller
12:33:26 Pod mt-broker-controller-56cc5dc5cc-kcg9d 5868:	Started container mt-broker-controller
12:37:23 Pod mt-broker-controller-56cc5dc5cc-kcg9d 5868:	Stopping container mt-broker-controller
12:52:39 Pod mt-broker-controller-56cc5dc5cc-smsf6 13282:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-smsf6 to acto-cluster-12-worker
12:52:40 Pod mt-broker-controller-56cc5dc5cc-smsf6 13285:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:52:40 Pod mt-broker-controller-56cc5dc5cc-smsf6 13285:	Created container mt-broker-controller
12:52:40 Pod mt-broker-controller-56cc5dc5cc-smsf6 13285:	Started container mt-broker-controller
12:22:48 Pod mt-broker-controller-56cc5dc5cc-vlv6l 1430:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-vlv6l to acto-cluster-12-worker
12:22:49 Pod mt-broker-controller-56cc5dc5cc-vlv6l 1434:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:22:51 Pod mt-broker-controller-56cc5dc5cc-vlv6l 1434:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.708450341s
12:22:51 Pod mt-broker-controller-56cc5dc5cc-vlv6l 1434:	Created container mt-broker-controller
12:22:51 Pod mt-broker-controller-56cc5dc5cc-vlv6l 1434:	Started container mt-broker-controller
12:26:49 Pod mt-broker-controller-56cc5dc5cc-vlv6l 1434:	Stopping container mt-broker-controller
12:33:20 Pod mt-broker-controller-56cc5dc5cc-x89qh 5867:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-x89qh to acto-cluster-12-worker3
12:33:21 Pod mt-broker-controller-56cc5dc5cc-x89qh 5872:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:33:27 Pod mt-broker-controller-56cc5dc5cc-x89qh 5872:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 5.482917324s
12:33:27 Pod mt-broker-controller-56cc5dc5cc-x89qh 5872:	Created container mt-broker-controller
12:33:27 Pod mt-broker-controller-56cc5dc5cc-x89qh 5872:	Started container mt-broker-controller
12:37:23 Pod mt-broker-controller-56cc5dc5cc-x89qh 5872:	Stopping container mt-broker-controller
12:33:20 Pod mt-broker-controller-56cc5dc5cc-xv4lp 5861:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-xv4lp to acto-cluster-12-worker2
12:33:21 Pod mt-broker-controller-56cc5dc5cc-xv4lp 5866:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:33:21 Pod mt-broker-controller-56cc5dc5cc-xv4lp 5866:	Created container mt-broker-controller
12:33:21 Pod mt-broker-controller-56cc5dc5cc-xv4lp 5866:	Started container mt-broker-controller
12:37:23 Pod mt-broker-controller-56cc5dc5cc-xv4lp 5866:	Stopping container mt-broker-controller
12:22:48 ReplicaSet mt-broker-controller-56cc5dc5cc 1428:	Created pod: mt-broker-controller-56cc5dc5cc-vlv6l
12:28:37 ReplicaSet mt-broker-controller-56cc5dc5cc 3612:	Created pod: mt-broker-controller-56cc5dc5cc-7ltsb
12:33:20 ReplicaSet mt-broker-controller-56cc5dc5cc 5856:	Created pod: mt-broker-controller-56cc5dc5cc-76ckx
12:33:20 ReplicaSet mt-broker-controller-56cc5dc5cc 5856:	Created pod: mt-broker-controller-56cc5dc5cc-xv4lp
12:33:20 ReplicaSet mt-broker-controller-56cc5dc5cc 5856:	Created pod: mt-broker-controller-56cc5dc5cc-kcg9d
12:33:20 ReplicaSet mt-broker-controller-56cc5dc5cc 5856:	Created pod: mt-broker-controller-56cc5dc5cc-x89qh
12:39:12 ReplicaSet mt-broker-controller-56cc5dc5cc 8415:	Created pod: mt-broker-controller-56cc5dc5cc-94m2z
12:46:18 ReplicaSet mt-broker-controller-56cc5dc5cc 11052:	Created pod: mt-broker-controller-56cc5dc5cc-7fhfz
12:52:39 ReplicaSet mt-broker-controller-56cc5dc5cc 13280:	Created pod: mt-broker-controller-56cc5dc5cc-smsf6
12:22:48 Deployment mt-broker-controller 1427:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:28:37 Deployment mt-broker-controller 3610:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:33:20 Deployment mt-broker-controller 5855:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 4
12:39:12 Deployment mt-broker-controller 8413:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:46:18 Deployment mt-broker-controller 11051:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:52:39 Deployment mt-broker-controller 13279:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:46:17 Pod mt-broker-filter-846dc966c5-9vcrf 11001:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-9vcrf to acto-cluster-12-worker2
12:46:17 Pod mt-broker-filter-846dc966c5-9vcrf 11004:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:46:17 Pod mt-broker-filter-846dc966c5-9vcrf 11004:	Created container filter
12:46:18 Pod mt-broker-filter-846dc966c5-9vcrf 11004:	Started container filter
12:50:20 Pod mt-broker-filter-846dc966c5-9vcrf 11004:	Stopping container filter
12:50:21 Pod mt-broker-filter-846dc966c5-9vcrf 11004:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:50:21 Pod mt-broker-filter-846dc966c5-9vcrf 11004:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:33:19 Pod mt-broker-filter-846dc966c5-fnhkf 5769:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-fnhkf to acto-cluster-12-worker3
12:33:20 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:33:20 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Created container filter
12:33:20 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Started container filter
12:33:20 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Readiness probe failed: Get "http://10.244.3.11:8080/healthz": dial tcp 10.244.3.11:8080: connect: connection refused
12:37:23 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Stopping container filter
12:37:23 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:37:23 Pod mt-broker-filter-846dc966c5-fnhkf 5774:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:33:19 Pod mt-broker-filter-846dc966c5-hmwxb 5766:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-hmwxb to acto-cluster-12-worker
12:33:20 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:33:28 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 8.312624275s
12:33:28 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Created container filter
12:33:28 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Started container filter
12:37:23 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Stopping container filter
12:37:23 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:37:23 Pod mt-broker-filter-846dc966c5-hmwxb 5770:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:52:38 Pod mt-broker-filter-846dc966c5-htz25 13233:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-htz25 to acto-cluster-12-worker
12:52:39 Pod mt-broker-filter-846dc966c5-htz25 13237:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:52:39 Pod mt-broker-filter-846dc966c5-htz25 13237:	Created container filter
12:52:39 Pod mt-broker-filter-846dc966c5-htz25 13237:	Started container filter
12:22:47 Pod mt-broker-filter-846dc966c5-jdzgt 1388:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-jdzgt to acto-cluster-12-worker3
12:22:48 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:22:52 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 4.493840634s
12:22:52 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Created container filter
12:22:52 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Started container filter
12:26:49 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Stopping container filter
12:26:51 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:26:51 Pod mt-broker-filter-846dc966c5-jdzgt 1390:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:33:19 Pod mt-broker-filter-846dc966c5-ncptz 5771:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-ncptz to acto-cluster-12-worker2
12:33:20 Pod mt-broker-filter-846dc966c5-ncptz 5780:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:33:23 Pod mt-broker-filter-846dc966c5-ncptz 5780:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 2.679593309s
12:33:23 Pod mt-broker-filter-846dc966c5-ncptz 5780:	Created container filter
12:33:23 Pod mt-broker-filter-846dc966c5-ncptz 5780:	Started container filter
12:37:23 Pod mt-broker-filter-846dc966c5-ncptz 5780:	Stopping container filter
12:28:36 Pod mt-broker-filter-846dc966c5-nlvgc 3574:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-nlvgc to acto-cluster-12-worker3
12:28:37 Pod mt-broker-filter-846dc966c5-nlvgc 3578:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:28:37 Pod mt-broker-filter-846dc966c5-nlvgc 3578:	Created container filter
12:28:37 Pod mt-broker-filter-846dc966c5-nlvgc 3578:	Started container filter
12:32:41 Pod mt-broker-filter-846dc966c5-nlvgc 3578:	Stopping container filter
12:39:11 Pod mt-broker-filter-846dc966c5-tljsr 8370:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-tljsr to acto-cluster-12-worker2
12:39:12 Pod mt-broker-filter-846dc966c5-tljsr 8373:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:39:12 Pod mt-broker-filter-846dc966c5-tljsr 8373:	Created container filter
12:39:12 Pod mt-broker-filter-846dc966c5-tljsr 8373:	Started container filter
12:43:19 Pod mt-broker-filter-846dc966c5-tljsr 8373:	Stopping container filter
12:33:19 Pod mt-broker-filter-846dc966c5-vqczr 5775:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-vqczr to acto-cluster-12-worker
12:33:20 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:33:28 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 7.889045147s
12:33:28 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Created container filter
12:33:28 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Started container filter
12:37:23 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Stopping container filter
12:37:23 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:37:23 Pod mt-broker-filter-846dc966c5-vqczr 5781:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:22:47 ReplicaSet mt-broker-filter-846dc966c5 1385:	Created pod: mt-broker-filter-846dc966c5-jdzgt
12:28:36 ReplicaSet mt-broker-filter-846dc966c5 3573:	Created pod: mt-broker-filter-846dc966c5-nlvgc
12:33:19 ReplicaSet mt-broker-filter-846dc966c5 5764:	Created pod: mt-broker-filter-846dc966c5-hmwxb
12:33:19 ReplicaSet mt-broker-filter-846dc966c5 5764:	Created pod: mt-broker-filter-846dc966c5-ncptz
12:33:19 ReplicaSet mt-broker-filter-846dc966c5 5764:	Created pod: mt-broker-filter-846dc966c5-fnhkf
12:33:19 ReplicaSet mt-broker-filter-846dc966c5 5764:	Created pod: mt-broker-filter-846dc966c5-vqczr
12:39:11 ReplicaSet mt-broker-filter-846dc966c5 8368:	Created pod: mt-broker-filter-846dc966c5-tljsr
12:46:17 ReplicaSet mt-broker-filter-846dc966c5 10999:	Created pod: mt-broker-filter-846dc966c5-9vcrf
12:52:38 ReplicaSet mt-broker-filter-846dc966c5 13231:	Created pod: mt-broker-filter-846dc966c5-htz25
12:22:47 Deployment mt-broker-filter 1384:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:28:36 Deployment mt-broker-filter 3572:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:33:19 Deployment mt-broker-filter 5763:	Scaled up replica set mt-broker-filter-846dc966c5 to 4
12:39:11 Deployment mt-broker-filter 8367:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:46:17 Deployment mt-broker-filter 10998:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:52:38 Deployment mt-broker-filter 13230:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:39:12 Pod mt-broker-ingress-6dbbfff4b9-679d4 8392:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-679d4 to acto-cluster-12-worker2
12:39:12 Pod mt-broker-ingress-6dbbfff4b9-679d4 8395:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:39:12 Pod mt-broker-ingress-6dbbfff4b9-679d4 8395:	Created container ingress
12:39:13 Pod mt-broker-ingress-6dbbfff4b9-679d4 8395:	Started container ingress
12:43:19 Pod mt-broker-ingress-6dbbfff4b9-679d4 8395:	Stopping container ingress
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-d2jq5 5816:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-d2jq5 to acto-cluster-12-worker3
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-d2jq5 5820:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:33:23 Pod mt-broker-ingress-6dbbfff4b9-d2jq5 5820:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 2.882639382s
12:33:23 Pod mt-broker-ingress-6dbbfff4b9-d2jq5 5820:	Created container ingress
12:33:23 Pod mt-broker-ingress-6dbbfff4b9-d2jq5 5820:	Started container ingress
12:37:23 Pod mt-broker-ingress-6dbbfff4b9-d2jq5 5820:	Stopping container ingress
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-f7zqh 5821:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-f7zqh to acto-cluster-12-worker3
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-f7zqh 5825:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:33:23 Pod mt-broker-ingress-6dbbfff4b9-f7zqh 5825:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 3.211241703s
12:33:23 Pod mt-broker-ingress-6dbbfff4b9-f7zqh 5825:	Created container ingress
12:33:24 Pod mt-broker-ingress-6dbbfff4b9-f7zqh 5825:	Started container ingress
12:37:23 Pod mt-broker-ingress-6dbbfff4b9-f7zqh 5825:	Stopping container ingress
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-fjk8g 5817:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-fjk8g to acto-cluster-12-worker2
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-fjk8g 5822:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-fjk8g 5822:	Created container ingress
12:33:21 Pod mt-broker-ingress-6dbbfff4b9-fjk8g 5822:	Started container ingress
12:37:23 Pod mt-broker-ingress-6dbbfff4b9-fjk8g 5822:	Stopping container ingress
12:52:39 Pod mt-broker-ingress-6dbbfff4b9-fmwrm 13264:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-fmwrm to acto-cluster-12-worker3
12:52:39 Pod mt-broker-ingress-6dbbfff4b9-fmwrm 13266:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:52:39 Pod mt-broker-ingress-6dbbfff4b9-fmwrm 13266:	Created container ingress
12:52:40 Pod mt-broker-ingress-6dbbfff4b9-fmwrm 13266:	Started container ingress
12:46:17 Pod mt-broker-ingress-6dbbfff4b9-kt2sc 11030:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-kt2sc to acto-cluster-12-worker2
12:46:18 Pod mt-broker-ingress-6dbbfff4b9-kt2sc 11033:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:46:18 Pod mt-broker-ingress-6dbbfff4b9-kt2sc 11033:	Created container ingress
12:46:18 Pod mt-broker-ingress-6dbbfff4b9-kt2sc 11033:	Started container ingress
12:50:20 Pod mt-broker-ingress-6dbbfff4b9-kt2sc 11033:	Stopping container ingress
12:22:48 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1410:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-qv4q7 to acto-cluster-12-worker2
12:22:48 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:22:52 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 3.42523182s
12:22:52 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Created container ingress
12:22:52 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Started container ingress
12:26:49 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Stopping container ingress
12:26:50 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:26:50 Pod mt-broker-ingress-6dbbfff4b9-qv4q7 1413:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:28:37 Pod mt-broker-ingress-6dbbfff4b9-r7889 3594:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-r7889 to acto-cluster-12-worker2
12:28:37 Pod mt-broker-ingress-6dbbfff4b9-r7889 3597:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:28:37 Pod mt-broker-ingress-6dbbfff4b9-r7889 3597:	Created container ingress
12:28:38 Pod mt-broker-ingress-6dbbfff4b9-r7889 3597:	Started container ingress
12:32:41 Pod mt-broker-ingress-6dbbfff4b9-r7889 3597:	Stopping container ingress
12:32:41 Pod mt-broker-ingress-6dbbfff4b9-r7889 3597:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:32:41 Pod mt-broker-ingress-6dbbfff4b9-r7889 3597:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5812:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-xpcdm to acto-cluster-12-worker
12:33:20 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:33:31 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 10.780039246s
12:33:31 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Created container ingress
12:33:31 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Started container ingress
12:37:23 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Stopping container ingress
12:37:24 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:37:24 Pod mt-broker-ingress-6dbbfff4b9-xpcdm 5815:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:22:48 ReplicaSet mt-broker-ingress-6dbbfff4b9 1408:	Created pod: mt-broker-ingress-6dbbfff4b9-qv4q7
12:28:37 ReplicaSet mt-broker-ingress-6dbbfff4b9 3592:	Created pod: mt-broker-ingress-6dbbfff4b9-r7889
12:33:20 ReplicaSet mt-broker-ingress-6dbbfff4b9 5810:	Created pod: mt-broker-ingress-6dbbfff4b9-xpcdm
12:33:20 ReplicaSet mt-broker-ingress-6dbbfff4b9 5810:	Created pod: mt-broker-ingress-6dbbfff4b9-fjk8g
12:33:20 ReplicaSet mt-broker-ingress-6dbbfff4b9 5810:	Created pod: mt-broker-ingress-6dbbfff4b9-d2jq5
12:33:20 ReplicaSet mt-broker-ingress-6dbbfff4b9 5810:	Created pod: mt-broker-ingress-6dbbfff4b9-f7zqh
12:39:12 ReplicaSet mt-broker-ingress-6dbbfff4b9 8390:	Created pod: mt-broker-ingress-6dbbfff4b9-679d4
12:46:17 ReplicaSet mt-broker-ingress-6dbbfff4b9 11028:	Created pod: mt-broker-ingress-6dbbfff4b9-kt2sc
12:52:39 ReplicaSet mt-broker-ingress-6dbbfff4b9 13261:	Created pod: mt-broker-ingress-6dbbfff4b9-fmwrm
12:22:48 Deployment mt-broker-ingress 1407:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:28:37 Deployment mt-broker-ingress 3591:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:33:20 Deployment mt-broker-ingress 5809:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 4
12:39:12 Deployment mt-broker-ingress 8389:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:46:17 Deployment mt-broker-ingress 11027:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:52:39 Deployment mt-broker-ingress 13257:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:52:43 Pod redis-controller-manager-0 13410:	Successfully assigned knative-eventing/redis-controller-manager-0 to acto-cluster-12-worker2
12:52:43 Pod redis-controller-manager-0 13413:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-redis/source/cmd/controller@sha256:f8037befa9b6f90033979b84ff7b943c7e2861394478050ca1e6f604922dfa36"
12:52:46 Pod redis-controller-manager-0 13413:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-redis/source/cmd/controller@sha256:f8037befa9b6f90033979b84ff7b943c7e2861394478050ca1e6f604922dfa36" in 2.888386677s
12:52:46 Pod redis-controller-manager-0 13413:	Created container manager
12:52:47 Pod redis-controller-manager-0 13413:	Started container manager
12:52:43 StatefulSet redis-controller-manager 13408:	create Pod redis-controller-manager-0 in StatefulSet redis-controller-manager successful
12:28:38 Pod storage-version-migration-eventing-eventing-1.6.0--1-hq6dx 3642:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-hq6dx to acto-cluster-12-worker
12:28:39 Pod storage-version-migration-eventing-eventing-1.6.0--1-hq6dx 3644:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:28:39 Pod storage-version-migration-eventing-eventing-1.6.0--1-hq6dx 3644:	Created container migrate
12:28:39 Pod storage-version-migration-eventing-eventing-1.6.0--1-hq6dx 3644:	Started container migrate
12:22:49 Pod storage-version-migration-eventing-eventing-1.6.0--1-j2fph 1450:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-j2fph to acto-cluster-12-worker
12:22:49 Pod storage-version-migration-eventing-eventing-1.6.0--1-j2fph 1452:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:22:54 Pod storage-version-migration-eventing-eventing-1.6.0--1-j2fph 1452:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 4.339494992s
12:22:54 Pod storage-version-migration-eventing-eventing-1.6.0--1-j2fph 1452:	Created container migrate
12:22:54 Pod storage-version-migration-eventing-eventing-1.6.0--1-j2fph 1452:	Started container migrate
12:46:18 Pod storage-version-migration-eventing-eventing-1.6.0--1-jw5rc 11084:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-jw5rc to acto-cluster-12-worker
12:46:19 Pod storage-version-migration-eventing-eventing-1.6.0--1-jw5rc 11086:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:46:19 Pod storage-version-migration-eventing-eventing-1.6.0--1-jw5rc 11086:	Created container migrate
12:46:19 Pod storage-version-migration-eventing-eventing-1.6.0--1-jw5rc 11086:	Started container migrate
12:52:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-nk9fv 13313:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-nk9fv to acto-cluster-12-worker
12:52:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-nk9fv 13315:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:52:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-nk9fv 13315:	Created container migrate
12:52:41 Pod storage-version-migration-eventing-eventing-1.6.0--1-nk9fv 13315:	Started container migrate
12:33:21 Pod storage-version-migration-eventing-eventing-1.6.0--1-p2m9v 5908:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-p2m9v to acto-cluster-12-worker2
12:33:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-p2m9v 5910:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:33:25 Pod storage-version-migration-eventing-eventing-1.6.0--1-p2m9v 5910:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 3.660152871s
12:33:25 Pod storage-version-migration-eventing-eventing-1.6.0--1-p2m9v 5910:	Created container migrate
12:33:25 Pod storage-version-migration-eventing-eventing-1.6.0--1-p2m9v 5910:	Started container migrate
12:39:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-tnj24 8463:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-tnj24 to acto-cluster-12-worker3
12:39:14 Pod storage-version-migration-eventing-eventing-1.6.0--1-tnj24 8465:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:39:16 Pod storage-version-migration-eventing-eventing-1.6.0--1-tnj24 8465:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.455923458s
12:39:16 Pod storage-version-migration-eventing-eventing-1.6.0--1-tnj24 8465:	Created container migrate
12:39:16 Pod storage-version-migration-eventing-eventing-1.6.0--1-tnj24 8465:	Started container migrate
12:22:49 Job storage-version-migration-eventing-eventing-1.6.0 1448:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-j2fph
12:22:59 Job storage-version-migration-eventing-eventing-1.6.0 1453:	Job completed
12:28:38 Job storage-version-migration-eventing-eventing-1.6.0 3641:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-hq6dx
12:28:44 Job storage-version-migration-eventing-eventing-1.6.0 3646:	Job completed
12:33:21 Job storage-version-migration-eventing-eventing-1.6.0 5907:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-p2m9v
12:33:31 Job storage-version-migration-eventing-eventing-1.6.0 5912:	Job completed
12:39:13 Job storage-version-migration-eventing-eventing-1.6.0 8461:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-tnj24
12:39:21 Job storage-version-migration-eventing-eventing-1.6.0 8466:	Job completed
12:46:18 Job storage-version-migration-eventing-eventing-1.6.0 11083:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-jw5rc
12:46:25 Job storage-version-migration-eventing-eventing-1.6.0 11089:	Job completed
12:52:40 Job storage-version-migration-eventing-eventing-1.6.0 13312:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-nk9fv
12:52:46 Job storage-version-migration-eventing-eventing-1.6.0 13318:	Job completed
12:22:27 KnativeEventing test-cluster 994:	Updated "test-cluster" finalizers
12:28:18 KnativeEventing test-cluster 3235:	Updated "test-cluster" finalizers
12:32:59 KnativeEventing test-cluster 5289:	Updated "test-cluster" finalizers
12:38:52 KnativeEventing test-cluster 7998:	Updated "test-cluster" finalizers
12:45:58 KnativeEventing test-cluster 10643:	Updated "test-cluster" finalizers
12:52:18 KnativeEventing test-cluster 12858:	Updated "test-cluster" finalizers
