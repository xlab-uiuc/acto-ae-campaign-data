12:21:44 HorizontalPodAutoscaler broker-filter-hpa 1306:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:44 HorizontalPodAutoscaler broker-filter-hpa 1306:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:39 HorizontalPodAutoscaler broker-filter-hpa 3819:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:39 HorizontalPodAutoscaler broker-filter-hpa 3819:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:27 HorizontalPodAutoscaler broker-filter-hpa 6187:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:27 HorizontalPodAutoscaler broker-filter-hpa 6187:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:55 HorizontalPodAutoscaler broker-filter-hpa 9485:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:55 HorizontalPodAutoscaler broker-filter-hpa 9485:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:37 HorizontalPodAutoscaler broker-filter-hpa 11564:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:37 HorizontalPodAutoscaler broker-filter-hpa 11564:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:27 HorizontalPodAutoscaler broker-filter-hpa 13731:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:27 HorizontalPodAutoscaler broker-filter-hpa 13731:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:44 HorizontalPodAutoscaler broker-ingress-hpa 1304:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:44 HorizontalPodAutoscaler broker-ingress-hpa 1304:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:39 HorizontalPodAutoscaler broker-ingress-hpa 3817:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:39 HorizontalPodAutoscaler broker-ingress-hpa 3817:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:27 HorizontalPodAutoscaler broker-ingress-hpa 6184:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:27 HorizontalPodAutoscaler broker-ingress-hpa 6184:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:54 HorizontalPodAutoscaler broker-ingress-hpa 9475:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:54 HorizontalPodAutoscaler broker-ingress-hpa 9475:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:36 HorizontalPodAutoscaler broker-ingress-hpa 11556:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:36 HorizontalPodAutoscaler broker-ingress-hpa 11556:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:27 HorizontalPodAutoscaler broker-ingress-hpa 13729:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:27 HorizontalPodAutoscaler broker-ingress-hpa 13729:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:06 Pod eventing-controller-57979f756b-vwdrk 5988:	0/4 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 3 node(s) didn't match Pod's node affinity/selector.
12:42:03 Pod eventing-controller-57979f756b-vwdrk 8871:	skip schedule deleting pod: knative-eventing/eventing-controller-57979f756b-vwdrk
12:32:06 ReplicaSet eventing-controller-57979f756b 5985:	Created pod: eventing-controller-57979f756b-vwdrk
12:53:06 Pod eventing-controller-6c78bb8c7f-krnbn 13502:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-krnbn to acto-cluster-13-worker2
12:53:06 Pod eventing-controller-6c78bb8c7f-krnbn 13504:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:53:06 Pod eventing-controller-6c78bb8c7f-krnbn 13504:	Created container eventing-controller
12:53:07 Pod eventing-controller-6c78bb8c7f-krnbn 13504:	Started container eventing-controller
12:27:18 Pod eventing-controller-6c78bb8c7f-lhfhr 3584:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-lhfhr to acto-cluster-13-worker2
12:27:18 Pod eventing-controller-6c78bb8c7f-lhfhr 3586:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:27:21 Pod eventing-controller-6c78bb8c7f-lhfhr 3586:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.73797074s
12:27:21 Pod eventing-controller-6c78bb8c7f-lhfhr 3586:	Created container eventing-controller
12:27:21 Pod eventing-controller-6c78bb8c7f-lhfhr 3586:	Started container eventing-controller
12:31:35 Pod eventing-controller-6c78bb8c7f-lhfhr 3586:	Stopping container eventing-controller
12:21:22 Pod eventing-controller-6c78bb8c7f-tgfd4 1075:	Successfully assigned knative-eventing/eventing-controller-6c78bb8c7f-tgfd4 to acto-cluster-13-worker
12:21:23 Pod eventing-controller-6c78bb8c7f-tgfd4 1077:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:21:26 Pod eventing-controller-6c78bb8c7f-tgfd4 1077:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 3.767834762s
12:21:26 Pod eventing-controller-6c78bb8c7f-tgfd4 1077:	Created container eventing-controller
12:21:27 Pod eventing-controller-6c78bb8c7f-tgfd4 1077:	Started container eventing-controller
12:25:38 Pod eventing-controller-6c78bb8c7f-tgfd4 1077:	Stopping container eventing-controller
12:21:22 ReplicaSet eventing-controller-6c78bb8c7f 1072:	Created pod: eventing-controller-6c78bb8c7f-tgfd4
12:27:18 ReplicaSet eventing-controller-6c78bb8c7f 3581:	Created pod: eventing-controller-6c78bb8c7f-lhfhr
12:53:06 ReplicaSet eventing-controller-6c78bb8c7f 13499:	Created pod: eventing-controller-6c78bb8c7f-krnbn
12:42:33 Pod eventing-controller-779fbf8f65-bvbr2 9252:	Successfully assigned knative-eventing/eventing-controller-779fbf8f65-bvbr2 to acto-cluster-13-worker3
12:42:34 Pod eventing-controller-779fbf8f65-bvbr2 9255:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91"
12:42:37 Pod eventing-controller-779fbf8f65-bvbr2 9255:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" in 2.673325109s
12:42:37 Pod eventing-controller-779fbf8f65-bvbr2 9255:	Created container eventing-controller
12:42:37 Pod eventing-controller-779fbf8f65-bvbr2 9255:	Started container eventing-controller
12:46:47 Pod eventing-controller-779fbf8f65-bvbr2 9255:	Stopping container eventing-controller
12:42:33 ReplicaSet eventing-controller-779fbf8f65 9249:	Created pod: eventing-controller-779fbf8f65-bvbr2
12:47:15 Pod eventing-controller-86d49cf697-gs8tx 11317:	Successfully assigned knative-eventing/eventing-controller-86d49cf697-gs8tx to acto-cluster-13-worker2
12:47:16 Pod eventing-controller-86d49cf697-gs8tx 11319:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/controller@sha256:204fdaa828603a03b66ee30141ebf88c98881829d6af5f57c34400408d15ec91" already present on machine
12:47:16 Pod eventing-controller-86d49cf697-gs8tx 11319:	Created container eventing-controller
12:47:16 Pod eventing-controller-86d49cf697-gs8tx 11319:	Started container eventing-controller
12:51:28 Pod eventing-controller-86d49cf697-gs8tx 11319:	Stopping container eventing-controller
12:47:15 ReplicaSet eventing-controller-86d49cf697 11314:	Created pod: eventing-controller-86d49cf697-gs8tx
12:21:22 Deployment eventing-controller 1071:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:27:18 Deployment eventing-controller 3580:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:32:06 Deployment eventing-controller 5984:	Scaled up replica set eventing-controller-57979f756b to 1
12:42:33 Deployment eventing-controller 9248:	Scaled up replica set eventing-controller-779fbf8f65 to 1
12:47:15 Deployment eventing-controller 11313:	Scaled up replica set eventing-controller-86d49cf697 to 1
12:53:06 Deployment eventing-controller 13498:	Scaled up replica set eventing-controller-6c78bb8c7f to 1
12:47:16 Pod eventing-webhook-5755489569-5tpnv 11343:	Successfully assigned knative-eventing/eventing-webhook-5755489569-5tpnv to acto-cluster-13-worker
12:47:17 Pod eventing-webhook-5755489569-5tpnv 11346:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:47:17 Pod eventing-webhook-5755489569-5tpnv 11346:	Created container eventing-webhook
12:47:18 Pod eventing-webhook-5755489569-5tpnv 11346:	Started container eventing-webhook
12:47:18 Pod eventing-webhook-5755489569-5tpnv 11346:	Readiness probe failed: Get "https://10.244.1.15:8443/": remote error: tls: unrecognized name
12:51:26 Pod eventing-webhook-5755489569-5tpnv 11346:	Liveness probe failed: Get "https://10.244.1.15:8443/": remote error: tls: unrecognized name
12:51:27 Pod eventing-webhook-5755489569-5tpnv 11346:	Stopping container eventing-webhook
12:21:23 Pod eventing-webhook-5755489569-ffqjj 1099:	Successfully assigned knative-eventing/eventing-webhook-5755489569-ffqjj to acto-cluster-13-worker2
12:21:24 Pod eventing-webhook-5755489569-ffqjj 1103:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:21:27 Pod eventing-webhook-5755489569-ffqjj 1103:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 3.144084509s
12:21:27 Pod eventing-webhook-5755489569-ffqjj 1103:	Created container eventing-webhook
12:21:28 Pod eventing-webhook-5755489569-ffqjj 1103:	Started container eventing-webhook
12:21:28 Pod eventing-webhook-5755489569-ffqjj 1103:	Readiness probe failed: Get "https://10.244.2.2:8443/": dial tcp 10.244.2.2:8443: connect: connection refused
12:25:36 Pod eventing-webhook-5755489569-ffqjj 1103:	Liveness probe failed: Get "https://10.244.2.2:8443/": remote error: tls: unrecognized name
12:25:36 Pod eventing-webhook-5755489569-ffqjj 1103:	Readiness probe failed: Get "https://10.244.2.2:8443/": remote error: tls: unrecognized name
12:25:37 Pod eventing-webhook-5755489569-ffqjj 1103:	Stopping container eventing-webhook
12:27:18 Pod eventing-webhook-5755489569-k8v8n 3607:	Successfully assigned knative-eventing/eventing-webhook-5755489569-k8v8n to acto-cluster-13-worker3
12:27:19 Pod eventing-webhook-5755489569-k8v8n 3610:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:27:22 Pod eventing-webhook-5755489569-k8v8n 3610:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.66293461s
12:27:22 Pod eventing-webhook-5755489569-k8v8n 3610:	Created container eventing-webhook
12:27:23 Pod eventing-webhook-5755489569-k8v8n 3610:	Started container eventing-webhook
12:31:33 Pod eventing-webhook-5755489569-k8v8n 3610:	Liveness probe failed: Get "https://10.244.3.6:8443/": remote error: tls: unrecognized name
12:31:33 Pod eventing-webhook-5755489569-k8v8n 3610:	Readiness probe failed: Get "https://10.244.3.6:8443/": remote error: tls: unrecognized name
12:31:34 Pod eventing-webhook-5755489569-k8v8n 3610:	Stopping container eventing-webhook
12:42:34 Pod eventing-webhook-5755489569-kf9mg 9275:	Successfully assigned knative-eventing/eventing-webhook-5755489569-kf9mg to acto-cluster-13-worker3
12:42:35 Pod eventing-webhook-5755489569-kf9mg 9278:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:42:35 Pod eventing-webhook-5755489569-kf9mg 9278:	Created container eventing-webhook
12:42:36 Pod eventing-webhook-5755489569-kf9mg 9278:	Started container eventing-webhook
12:42:36 Pod eventing-webhook-5755489569-kf9mg 9278:	Readiness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:46:45 Pod eventing-webhook-5755489569-kf9mg 9278:	Liveness probe failed: Get "https://10.244.3.10:8443/": remote error: tls: unrecognized name
12:46:46 Pod eventing-webhook-5755489569-kf9mg 9278:	Stopping container eventing-webhook
12:53:07 Pod eventing-webhook-5755489569-xk45p 13527:	Successfully assigned knative-eventing/eventing-webhook-5755489569-xk45p to acto-cluster-13-worker
12:53:07 Pod eventing-webhook-5755489569-xk45p 13530:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" already present on machine
12:53:07 Pod eventing-webhook-5755489569-xk45p 13530:	Created container eventing-webhook
12:53:08 Pod eventing-webhook-5755489569-xk45p 13530:	Started container eventing-webhook
12:32:07 Pod eventing-webhook-5755489569-z242q 6009:	Successfully assigned knative-eventing/eventing-webhook-5755489569-z242q to acto-cluster-13-worker
12:32:08 Pod eventing-webhook-5755489569-z242q 6012:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7"
12:32:10 Pod eventing-webhook-5755489569-z242q 6012:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/webhook@sha256:65e83bd39a909fc6ce171750281660e3df2becd6c7b550b5d902d335f3379ae7" in 2.744144319s
12:32:11 Pod eventing-webhook-5755489569-z242q 6012:	Created container eventing-webhook
12:32:11 Pod eventing-webhook-5755489569-z242q 6012:	Started container eventing-webhook
12:42:02 Pod eventing-webhook-5755489569-z242q 6012:	Readiness probe failed: Get "https://10.244.1.9:8443/": remote error: tls: unrecognized name
12:42:02 Pod eventing-webhook-5755489569-z242q 6012:	Liveness probe failed: Get "https://10.244.1.9:8443/": remote error: tls: unrecognized name
12:42:02 Pod eventing-webhook-5755489569-z242q 6012:	Stopping container eventing-webhook
12:21:23 ReplicaSet eventing-webhook-5755489569 1097:	Created pod: eventing-webhook-5755489569-ffqjj
12:27:18 ReplicaSet eventing-webhook-5755489569 3605:	Created pod: eventing-webhook-5755489569-k8v8n
12:32:07 ReplicaSet eventing-webhook-5755489569 6007:	Created pod: eventing-webhook-5755489569-z242q
12:42:34 ReplicaSet eventing-webhook-5755489569 9273:	Created pod: eventing-webhook-5755489569-kf9mg
12:47:16 ReplicaSet eventing-webhook-5755489569 11341:	Created pod: eventing-webhook-5755489569-5tpnv
12:53:07 ReplicaSet eventing-webhook-5755489569 13524:	Created pod: eventing-webhook-5755489569-xk45p
12:21:23 PodDisruptionBudget eventing-webhook 1091:	No matching pods found
12:21:23 Deployment eventing-webhook 1096:	Scaled up replica set eventing-webhook-5755489569 to 1
12:21:38 HorizontalPodAutoscaler eventing-webhook 1089:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:38 HorizontalPodAutoscaler eventing-webhook 1089:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:25:37 PodDisruptionBudget eventing-webhook 1691:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:27:18 PodDisruptionBudget eventing-webhook 3600:	No matching pods found
12:27:18 Deployment eventing-webhook 3604:	Scaled up replica set eventing-webhook-5755489569 to 1
12:27:33 HorizontalPodAutoscaler eventing-webhook 3598:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:27:33 HorizontalPodAutoscaler eventing-webhook 3598:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:31:34 PodDisruptionBudget eventing-webhook 4169:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:32:07 PodDisruptionBudget eventing-webhook 6002:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:32:07 Deployment eventing-webhook 6006:	Scaled up replica set eventing-webhook-5755489569 to 1
12:32:07 PodDisruptionBudget eventing-webhook 6004:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-k8v8n"
12:32:21 HorizontalPodAutoscaler eventing-webhook 6001:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:32:21 HorizontalPodAutoscaler eventing-webhook 6001:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:34 PodDisruptionBudget eventing-webhook 9268:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:42:34 Deployment eventing-webhook 9272:	Scaled up replica set eventing-webhook-5755489569 to 1
12:42:34 PodDisruptionBudget eventing-webhook 9270:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-z242q"
12:42:49 HorizontalPodAutoscaler eventing-webhook 9266:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:42:49 HorizontalPodAutoscaler eventing-webhook 9266:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:16 PodDisruptionBudget eventing-webhook 11334:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
12:47:16 Deployment eventing-webhook 11340:	Scaled up replica set eventing-webhook-5755489569 to 1
12:47:16 PodDisruptionBudget eventing-webhook 11336:	Failed to calculate the number of expected pods: found no controllers for pod "eventing-webhook-5755489569-kf9mg"
12:47:31 HorizontalPodAutoscaler eventing-webhook 11333:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:47:31 HorizontalPodAutoscaler eventing-webhook 11333:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:06 PodDisruptionBudget eventing-webhook 13519:	No matching pods found
12:53:07 Deployment eventing-webhook 13523:	Scaled up replica set eventing-webhook-5755489569 to 1
12:53:21 HorizontalPodAutoscaler eventing-webhook 13516:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:53:21 HorizontalPodAutoscaler eventing-webhook 13516:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
12:21:31 Pod gitlab-controller-manager-67cf8fccc4-qwzjl 1360:	Successfully assigned knative-eventing/gitlab-controller-manager-67cf8fccc4-qwzjl to acto-cluster-13-worker2
12:21:33 Pod gitlab-controller-manager-67cf8fccc4-qwzjl 1364:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-gitlab/cmd/controller@sha256:d6ebc524950592ced6afdc71e503922c25c5f484bfcf8d9f0da50359887ec213"
12:21:43 Pod gitlab-controller-manager-67cf8fccc4-qwzjl 1364:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-gitlab/cmd/controller@sha256:d6ebc524950592ced6afdc71e503922c25c5f484bfcf8d9f0da50359887ec213" in 10.695796003s
12:21:43 Pod gitlab-controller-manager-67cf8fccc4-qwzjl 1364:	Created container manager
12:21:45 Pod gitlab-controller-manager-67cf8fccc4-qwzjl 1364:	Started container manager
12:25:31 Pod gitlab-controller-manager-67cf8fccc4-qwzjl 1364:	Stopping container manager
12:21:31 ReplicaSet gitlab-controller-manager-67cf8fccc4 1358:	Created pod: gitlab-controller-manager-67cf8fccc4-qwzjl
12:21:31 Deployment gitlab-controller-manager 1357:	Scaled up replica set gitlab-controller-manager-67cf8fccc4 to 1
12:21:32 Pod gitlab-webhook-59bccd8d74-5gh24 1399:	Successfully assigned knative-eventing/gitlab-webhook-59bccd8d74-5gh24 to acto-cluster-13-worker2
12:21:32 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-gitlab/cmd/webhook@sha256:fbd7543577c5764c5c7826f9c9bfaa94b19c14af14cc4bc10b445e684474cb2d"
12:21:40 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-gitlab/cmd/webhook@sha256:fbd7543577c5764c5c7826f9c9bfaa94b19c14af14cc4bc10b445e684474cb2d" in 7.39447469s
12:21:40 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Created container gitlab-webhook
12:21:40 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Started container gitlab-webhook
12:25:31 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Stopping container gitlab-webhook
12:25:31 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Readiness probe failed: Get "https://10.244.2.7:8443/": remote error: tls: unrecognized name
12:25:31 Pod gitlab-webhook-59bccd8d74-5gh24 1402:	Liveness probe failed: Get "https://10.244.2.7:8443/": remote error: tls: unrecognized name
12:21:32 ReplicaSet gitlab-webhook-59bccd8d74 1397:	Created pod: gitlab-webhook-59bccd8d74-5gh24
12:21:32 Deployment gitlab-webhook 1396:	Scaled up replica set gitlab-webhook-59bccd8d74 to 1
12:47:19 Pod imc-controller-567b4f565b-2s26x 11429:	Successfully assigned knative-eventing/imc-controller-567b4f565b-2s26x to acto-cluster-13-worker3
12:47:19 Pod imc-controller-567b4f565b-2s26x 11431:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:47:19 Pod imc-controller-567b4f565b-2s26x 11431:	Created container controller
12:47:20 Pod imc-controller-567b4f565b-2s26x 11431:	Started container controller
12:51:24 Pod imc-controller-567b4f565b-2s26x 11431:	Liveness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
12:51:24 Pod imc-controller-567b4f565b-2s26x 11431:	Readiness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
12:51:25 Pod imc-controller-567b4f565b-2s26x 11431:	Stopping container controller
12:42:37 Pod imc-controller-567b4f565b-gn5hq 9336:	Successfully assigned knative-eventing/imc-controller-567b4f565b-gn5hq to acto-cluster-13-worker
12:42:37 Pod imc-controller-567b4f565b-gn5hq 9340:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:42:40 Pod imc-controller-567b4f565b-gn5hq 9340:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.685858749s
12:42:40 Pod imc-controller-567b4f565b-gn5hq 9340:	Created container controller
12:42:40 Pod imc-controller-567b4f565b-gn5hq 9340:	Started container controller
12:42:40 Pod imc-controller-567b4f565b-gn5hq 9340:	Readiness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:46:43 Pod imc-controller-567b4f565b-gn5hq 9340:	Liveness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
12:46:43 Pod imc-controller-567b4f565b-gn5hq 9340:	Stopping container controller
12:27:21 Pod imc-controller-567b4f565b-r77c7 3643:	Successfully assigned knative-eventing/imc-controller-567b4f565b-r77c7 to acto-cluster-13-worker3
12:27:22 Pod imc-controller-567b4f565b-r77c7 3645:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:27:22 Pod imc-controller-567b4f565b-r77c7 3645:	Created container controller
12:27:22 Pod imc-controller-567b4f565b-r77c7 3645:	Started container controller
12:27:22 Pod imc-controller-567b4f565b-r77c7 3645:	Readiness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
12:31:31 Pod imc-controller-567b4f565b-r77c7 3645:	Liveness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
12:31:32 Pod imc-controller-567b4f565b-r77c7 3645:	Stopping container controller
12:32:10 Pod imc-controller-567b4f565b-rxw24 6047:	Successfully assigned knative-eventing/imc-controller-567b4f565b-rxw24 to acto-cluster-13-worker2
12:32:10 Pod imc-controller-567b4f565b-rxw24 6050:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:32:13 Pod imc-controller-567b4f565b-rxw24 6050:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.770277066s
12:32:13 Pod imc-controller-567b4f565b-rxw24 6050:	Created container controller
12:32:13 Pod imc-controller-567b4f565b-rxw24 6050:	Started container controller
12:42:00 Pod imc-controller-567b4f565b-rxw24 6050:	Liveness probe failed: Get "https://10.244.2.10:8443/": remote error: tls: unrecognized name
12:42:00 Pod imc-controller-567b4f565b-rxw24 6050:	Readiness probe failed: Get "https://10.244.2.10:8443/": remote error: tls: unrecognized name
12:42:00 Pod imc-controller-567b4f565b-rxw24 6050:	Stopping container controller
12:53:09 Pod imc-controller-567b4f565b-s5vts 13609:	Successfully assigned knative-eventing/imc-controller-567b4f565b-s5vts to acto-cluster-13-worker3
12:53:10 Pod imc-controller-567b4f565b-s5vts 13613:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" already present on machine
12:53:10 Pod imc-controller-567b4f565b-s5vts 13613:	Created container controller
12:53:10 Pod imc-controller-567b4f565b-s5vts 13613:	Started container controller
12:21:27 Pod imc-controller-567b4f565b-w7wx5 1151:	Successfully assigned knative-eventing/imc-controller-567b4f565b-w7wx5 to acto-cluster-13-worker3
12:21:28 Pod imc-controller-567b4f565b-w7wx5 1153:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0"
12:21:30 Pod imc-controller-567b4f565b-w7wx5 1153:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_controller@sha256:97d7db62ea35f7f9199787722c352091987e8816d549c3193ee5683424fef8d0" in 2.895247975s
12:21:30 Pod imc-controller-567b4f565b-w7wx5 1153:	Created container controller
12:21:31 Pod imc-controller-567b4f565b-w7wx5 1153:	Started container controller
12:25:34 Pod imc-controller-567b4f565b-w7wx5 1153:	Liveness probe failed: Get "https://10.244.3.3:8443/": remote error: tls: unrecognized name
12:25:34 Pod imc-controller-567b4f565b-w7wx5 1153:	Readiness probe failed: Get "https://10.244.3.3:8443/": remote error: tls: unrecognized name
12:25:34 Pod imc-controller-567b4f565b-w7wx5 1153:	Stopping container controller
12:21:27 ReplicaSet imc-controller-567b4f565b 1149:	Created pod: imc-controller-567b4f565b-w7wx5
12:27:21 ReplicaSet imc-controller-567b4f565b 3640:	Created pod: imc-controller-567b4f565b-r77c7
12:32:10 ReplicaSet imc-controller-567b4f565b 6045:	Created pod: imc-controller-567b4f565b-rxw24
12:42:37 ReplicaSet imc-controller-567b4f565b 9335:	Created pod: imc-controller-567b4f565b-gn5hq
12:47:19 ReplicaSet imc-controller-567b4f565b 11426:	Created pod: imc-controller-567b4f565b-2s26x
12:53:09 ReplicaSet imc-controller-567b4f565b 13607:	Created pod: imc-controller-567b4f565b-s5vts
12:21:27 Deployment imc-controller 1148:	Scaled up replica set imc-controller-567b4f565b to 1
12:27:21 Deployment imc-controller 3639:	Scaled up replica set imc-controller-567b4f565b to 1
12:32:10 Deployment imc-controller 6044:	Scaled up replica set imc-controller-567b4f565b to 1
12:42:37 Deployment imc-controller 9334:	Scaled up replica set imc-controller-567b4f565b to 1
12:47:19 Deployment imc-controller 11425:	Scaled up replica set imc-controller-567b4f565b to 1
12:53:09 Deployment imc-controller 13605:	Scaled up replica set imc-controller-567b4f565b to 1
12:47:19 Pod imc-dispatcher-545bcb44c5-4lngd 11459:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-4lngd to acto-cluster-13-worker
12:47:20 Pod imc-dispatcher-545bcb44c5-4lngd 11463:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:47:20 Pod imc-dispatcher-545bcb44c5-4lngd 11463:	Created container dispatcher
12:47:20 Pod imc-dispatcher-545bcb44c5-4lngd 11463:	Started container dispatcher
12:51:24 Pod imc-dispatcher-545bcb44c5-4lngd 11463:	Stopping container dispatcher
12:32:10 Pod imc-dispatcher-545bcb44c5-cq6gh 6072:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-cq6gh to acto-cluster-13-worker
12:32:11 Pod imc-dispatcher-545bcb44c5-cq6gh 6075:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:32:11 Pod imc-dispatcher-545bcb44c5-cq6gh 6075:	Created container dispatcher
12:32:11 Pod imc-dispatcher-545bcb44c5-cq6gh 6075:	Started container dispatcher
12:42:00 Pod imc-dispatcher-545bcb44c5-cq6gh 6075:	Stopping container dispatcher
12:42:01 Pod imc-dispatcher-545bcb44c5-cq6gh 6075:	Liveness probe failed: Get "http://10.244.1.10:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:42:01 Pod imc-dispatcher-545bcb44c5-cq6gh 6075:	Readiness probe failed: Get "http://10.244.1.10:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:21:27 Pod imc-dispatcher-545bcb44c5-dsv4t 1176:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-dsv4t to acto-cluster-13-worker2
12:21:28 Pod imc-dispatcher-545bcb44c5-dsv4t 1180:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:21:31 Pod imc-dispatcher-545bcb44c5-dsv4t 1180:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.681074516s
12:21:31 Pod imc-dispatcher-545bcb44c5-dsv4t 1180:	Created container dispatcher
12:21:31 Pod imc-dispatcher-545bcb44c5-dsv4t 1180:	Started container dispatcher
12:25:34 Pod imc-dispatcher-545bcb44c5-dsv4t 1180:	Stopping container dispatcher
12:42:37 Pod imc-dispatcher-545bcb44c5-h4265 9388:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-h4265 to acto-cluster-13-worker2
12:42:38 Pod imc-dispatcher-545bcb44c5-h4265 9392:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" already present on machine
12:42:38 Pod imc-dispatcher-545bcb44c5-h4265 9392:	Created container dispatcher
12:42:38 Pod imc-dispatcher-545bcb44c5-h4265 9392:	Started container dispatcher
12:46:43 Pod imc-dispatcher-545bcb44c5-h4265 9392:	Stopping container dispatcher
12:46:44 Pod imc-dispatcher-545bcb44c5-h4265 9392:	Readiness probe failed: Get "http://10.244.2.14:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:46:44 Pod imc-dispatcher-545bcb44c5-h4265 9392:	Liveness probe failed: Get "http://10.244.2.14:8080/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
12:53:10 Pod imc-dispatcher-545bcb44c5-w62g2 13635:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-w62g2 to acto-cluster-13-worker3
12:53:10 Pod imc-dispatcher-545bcb44c5-w62g2 13638:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:53:13 Pod imc-dispatcher-545bcb44c5-w62g2 13638:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.718525718s
12:53:13 Pod imc-dispatcher-545bcb44c5-w62g2 13638:	Created container dispatcher
12:53:13 Pod imc-dispatcher-545bcb44c5-w62g2 13638:	Started container dispatcher
12:27:22 Pod imc-dispatcher-545bcb44c5-wxwd5 3695:	Successfully assigned knative-eventing/imc-dispatcher-545bcb44c5-wxwd5 to acto-cluster-13-worker
12:27:22 Pod imc-dispatcher-545bcb44c5-wxwd5 3699:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20"
12:27:25 Pod imc-dispatcher-545bcb44c5-wxwd5 3699:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/in_memory/channel_dispatcher@sha256:3163f0a3b3ba5b81c36357df3dd2bff834056f2943c5b395adb497fb97476d20" in 2.686921261s
12:27:25 Pod imc-dispatcher-545bcb44c5-wxwd5 3699:	Created container dispatcher
12:27:25 Pod imc-dispatcher-545bcb44c5-wxwd5 3699:	Started container dispatcher
12:31:31 Pod imc-dispatcher-545bcb44c5-wxwd5 3699:	Stopping container dispatcher
12:21:27 ReplicaSet imc-dispatcher-545bcb44c5 1174:	Created pod: imc-dispatcher-545bcb44c5-dsv4t
12:27:22 ReplicaSet imc-dispatcher-545bcb44c5 3693:	Created pod: imc-dispatcher-545bcb44c5-wxwd5
12:32:10 ReplicaSet imc-dispatcher-545bcb44c5 6069:	Created pod: imc-dispatcher-545bcb44c5-cq6gh
12:42:37 ReplicaSet imc-dispatcher-545bcb44c5 9386:	Created pod: imc-dispatcher-545bcb44c5-h4265
12:47:19 ReplicaSet imc-dispatcher-545bcb44c5 11457:	Created pod: imc-dispatcher-545bcb44c5-4lngd
12:53:10 ReplicaSet imc-dispatcher-545bcb44c5 13633:	Created pod: imc-dispatcher-545bcb44c5-w62g2
12:21:27 Deployment imc-dispatcher 1173:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:27:22 Deployment imc-dispatcher 3692:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:32:10 Deployment imc-dispatcher 6068:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:42:37 Deployment imc-dispatcher 9385:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:47:19 Deployment imc-dispatcher 11456:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:53:10 Deployment imc-dispatcher 13632:	Scaled up replica set imc-dispatcher-545bcb44c5 to 1
12:27:25 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3855:	Successfully assigned knative-eventing/kafka-controller-manager-5f4fbfbf4f-skx76 to acto-cluster-13-worker2
12:27:26 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-kafka/cmd/source/controller@sha256:e07d09e93891ba1341f4fcf9b0fad67b37ff1c4e1d01844790bdb7fd589992f1"
12:27:29 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-kafka/cmd/source/controller@sha256:e07d09e93891ba1341f4fcf9b0fad67b37ff1c4e1d01844790bdb7fd589992f1" in 2.773439098s
12:27:29 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Created container manager
12:27:29 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Started container manager
12:31:28 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Stopping container manager
12:31:28 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Liveness probe failed: Get "https://10.244.2.9:8443/": remote error: tls: unrecognized name
12:31:28 Pod kafka-controller-manager-5f4fbfbf4f-skx76 3859:	Readiness probe failed: Get "https://10.244.2.9:8443/": remote error: tls: unrecognized name
12:27:25 ReplicaSet kafka-controller-manager-5f4fbfbf4f 3853:	Created pod: kafka-controller-manager-5f4fbfbf4f-skx76
12:27:25 Deployment kafka-controller-manager 3852:	Scaled up replica set kafka-controller-manager-5f4fbfbf4f to 1
12:20:59 Pod knative-operator-668fb586bb-7gvvk 797:	Successfully assigned knative-eventing/knative-operator-668fb586bb-7gvvk to acto-cluster-13-worker3
12:20:59 Pod knative-operator-668fb586bb-7gvvk 800:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:21:03 Pod knative-operator-668fb586bb-7gvvk 800:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 3.411336626s
12:21:03 Pod knative-operator-668fb586bb-7gvvk 800:	Created container knative-operator
12:21:03 Pod knative-operator-668fb586bb-7gvvk 800:	Started container knative-operator
12:25:53 Pod knative-operator-668fb586bb-7gvvk 800:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
12:20:59 ReplicaSet knative-operator-668fb586bb 794:	Created pod: knative-operator-668fb586bb-7gvvk
12:20:48 Pod knative-operator-79bf74d66d-ndf2t 753:	Successfully assigned knative-eventing/knative-operator-79bf74d66d-ndf2t to acto-cluster-13-worker
12:20:49 Pod knative-operator-79bf74d66d-ndf2t 755:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
12:20:52 Pod knative-operator-79bf74d66d-ndf2t 755:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.938362449s
12:20:52 Pod knative-operator-79bf74d66d-ndf2t 755:	Created container knative-operator
12:20:52 Pod knative-operator-79bf74d66d-ndf2t 755:	Started container knative-operator
12:21:03 Pod knative-operator-79bf74d66d-ndf2t 755:	Stopping container knative-operator
12:20:48 ReplicaSet knative-operator-79bf74d66d 750:	Created pod: knative-operator-79bf74d66d-ndf2t
12:21:03 ReplicaSet knative-operator-79bf74d66d 822:	Deleted pod: knative-operator-79bf74d66d-ndf2t
12:20:48 Deployment knative-operator 749:	Scaled up replica set knative-operator-79bf74d66d to 1
12:20:59 Deployment knative-operator 791:	Scaled up replica set knative-operator-668fb586bb to 1
12:21:03 Deployment knative-operator 808:	Scaled down replica set knative-operator-79bf74d66d to 0
12:32:12 Pod mt-broker-controller-56cc5dc5cc-7bpgz 6153:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-7bpgz to acto-cluster-13-worker
12:32:12 Pod mt-broker-controller-56cc5dc5cc-7bpgz 6156:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:32:13 Pod mt-broker-controller-56cc5dc5cc-7bpgz 6156:	Created container mt-broker-controller
12:32:13 Pod mt-broker-controller-56cc5dc5cc-7bpgz 6156:	Started container mt-broker-controller
12:41:58 Pod mt-broker-controller-56cc5dc5cc-7bpgz 6156:	Stopping container mt-broker-controller
12:42:39 Pod mt-broker-controller-56cc5dc5cc-d4nng 9465:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-d4nng to acto-cluster-13-worker3
12:42:40 Pod mt-broker-controller-56cc5dc5cc-d4nng 9468:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:42:40 Pod mt-broker-controller-56cc5dc5cc-d4nng 9468:	Created container mt-broker-controller
12:42:40 Pod mt-broker-controller-56cc5dc5cc-d4nng 9468:	Started container mt-broker-controller
12:46:42 Pod mt-broker-controller-56cc5dc5cc-d4nng 9468:	Stopping container mt-broker-controller
12:47:21 Pod mt-broker-controller-56cc5dc5cc-hs94v 11542:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-hs94v to acto-cluster-13-worker
12:47:22 Pod mt-broker-controller-56cc5dc5cc-hs94v 11546:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" already present on machine
12:47:22 Pod mt-broker-controller-56cc5dc5cc-hs94v 11546:	Created container mt-broker-controller
12:47:22 Pod mt-broker-controller-56cc5dc5cc-hs94v 11546:	Started container mt-broker-controller
12:51:23 Pod mt-broker-controller-56cc5dc5cc-hs94v 11546:	Stopping container mt-broker-controller
12:53:12 Pod mt-broker-controller-56cc5dc5cc-ntkj7 13714:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-ntkj7 to acto-cluster-13-worker2
12:53:12 Pod mt-broker-controller-56cc5dc5cc-ntkj7 13716:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:53:15 Pod mt-broker-controller-56cc5dc5cc-ntkj7 13716:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 2.754203765s
12:53:15 Pod mt-broker-controller-56cc5dc5cc-ntkj7 13716:	Created container mt-broker-controller
12:53:15 Pod mt-broker-controller-56cc5dc5cc-ntkj7 13716:	Started container mt-broker-controller
12:21:29 Pod mt-broker-controller-56cc5dc5cc-px542 1293:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-px542 to acto-cluster-13-worker3
12:21:30 Pod mt-broker-controller-56cc5dc5cc-px542 1297:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:21:37 Pod mt-broker-controller-56cc5dc5cc-px542 1297:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 7.511513381s
12:21:37 Pod mt-broker-controller-56cc5dc5cc-px542 1297:	Created container mt-broker-controller
12:21:37 Pod mt-broker-controller-56cc5dc5cc-px542 1297:	Started container mt-broker-controller
12:25:32 Pod mt-broker-controller-56cc5dc5cc-px542 1297:	Stopping container mt-broker-controller
12:27:23 Pod mt-broker-controller-56cc5dc5cc-szx74 3798:	Successfully assigned knative-eventing/mt-broker-controller-56cc5dc5cc-szx74 to acto-cluster-13-worker
12:27:24 Pod mt-broker-controller-56cc5dc5cc-szx74 3801:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4"
12:27:33 Pod mt-broker-controller-56cc5dc5cc-szx74 3801:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/mtchannel_broker@sha256:915d73c4d00990d5db5aa1e26b54b128df025cea7b688b95af8f14e1570fb4d4" in 9.106515503s
12:27:33 Pod mt-broker-controller-56cc5dc5cc-szx74 3801:	Created container mt-broker-controller
12:27:33 Pod mt-broker-controller-56cc5dc5cc-szx74 3801:	Started container mt-broker-controller
12:31:29 Pod mt-broker-controller-56cc5dc5cc-szx74 3801:	Stopping container mt-broker-controller
12:21:29 ReplicaSet mt-broker-controller-56cc5dc5cc 1292:	Created pod: mt-broker-controller-56cc5dc5cc-px542
12:27:23 ReplicaSet mt-broker-controller-56cc5dc5cc 3796:	Created pod: mt-broker-controller-56cc5dc5cc-szx74
12:32:12 ReplicaSet mt-broker-controller-56cc5dc5cc 6151:	Created pod: mt-broker-controller-56cc5dc5cc-7bpgz
12:42:39 ReplicaSet mt-broker-controller-56cc5dc5cc 9463:	Created pod: mt-broker-controller-56cc5dc5cc-d4nng
12:47:21 ReplicaSet mt-broker-controller-56cc5dc5cc 11540:	Created pod: mt-broker-controller-56cc5dc5cc-hs94v
12:53:12 ReplicaSet mt-broker-controller-56cc5dc5cc 13712:	Created pod: mt-broker-controller-56cc5dc5cc-ntkj7
12:21:29 Deployment mt-broker-controller 1291:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:27:23 Deployment mt-broker-controller 3795:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:32:12 Deployment mt-broker-controller 6150:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:42:39 Deployment mt-broker-controller 9462:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:47:21 Deployment mt-broker-controller 11539:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:53:12 Deployment mt-broker-controller 13711:	Scaled up replica set mt-broker-controller-56cc5dc5cc to 1
12:32:11 Pod mt-broker-filter-846dc966c5-4xmnf 6098:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-4xmnf to acto-cluster-13-worker2
12:32:12 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:32:16 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 3.936663372s
12:32:16 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Created container filter
12:32:16 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Started container filter
12:41:58 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Stopping container filter
12:41:59 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:41:59 Pod mt-broker-filter-846dc966c5-4xmnf 6101:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:47:20 Pod mt-broker-filter-846dc966c5-6hpfl 11502:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-6hpfl to acto-cluster-13-worker3
12:47:21 Pod mt-broker-filter-846dc966c5-6hpfl 11505:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:47:21 Pod mt-broker-filter-846dc966c5-6hpfl 11505:	Created container filter
12:47:21 Pod mt-broker-filter-846dc966c5-6hpfl 11505:	Started container filter
12:51:23 Pod mt-broker-filter-846dc966c5-6hpfl 11505:	Stopping container filter
12:27:23 Pod mt-broker-filter-846dc966c5-8rszg 3737:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-8rszg to acto-cluster-13-worker
12:27:23 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:27:28 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 4.484415331s
12:27:28 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Created container filter
12:27:28 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Started container filter
12:31:30 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Stopping container filter
12:31:31 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:31:31 Pod mt-broker-filter-846dc966c5-8rszg 3740:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:42:38 Pod mt-broker-filter-846dc966c5-hm8lg 9417:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-hm8lg to acto-cluster-13-worker
12:42:39 Pod mt-broker-filter-846dc966c5-hm8lg 9419:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:42:39 Pod mt-broker-filter-846dc966c5-hm8lg 9419:	Created container filter
12:42:39 Pod mt-broker-filter-846dc966c5-hm8lg 9419:	Started container filter
12:46:42 Pod mt-broker-filter-846dc966c5-hm8lg 9419:	Stopping container filter
12:46:42 Pod mt-broker-filter-846dc966c5-hm8lg 9419:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:46:42 Pod mt-broker-filter-846dc966c5-hm8lg 9419:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:53:11 Pod mt-broker-filter-846dc966c5-k28qj 13670:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-k28qj to acto-cluster-13-worker
12:53:11 Pod mt-broker-filter-846dc966c5-k28qj 13673:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" already present on machine
12:53:11 Pod mt-broker-filter-846dc966c5-k28qj 13673:	Created container filter
12:53:12 Pod mt-broker-filter-846dc966c5-k28qj 13673:	Started container filter
12:21:28 Pod mt-broker-filter-846dc966c5-slf44 1236:	Successfully assigned knative-eventing/mt-broker-filter-846dc966c5-slf44 to acto-cluster-13-worker3
12:21:29 Pod mt-broker-filter-846dc966c5-slf44 1239:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000"
12:21:34 Pod mt-broker-filter-846dc966c5-slf44 1239:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/filter@sha256:32d368bcbabee58fad2dd84c39c1d84b6dc5b608cc599d1387add40bae41b000" in 4.860377035s
12:21:34 Pod mt-broker-filter-846dc966c5-slf44 1239:	Created container filter
12:21:34 Pod mt-broker-filter-846dc966c5-slf44 1239:	Started container filter
12:25:33 Pod mt-broker-filter-846dc966c5-slf44 1239:	Stopping container filter
12:21:28 ReplicaSet mt-broker-filter-846dc966c5 1234:	Created pod: mt-broker-filter-846dc966c5-slf44
12:27:23 ReplicaSet mt-broker-filter-846dc966c5 3735:	Created pod: mt-broker-filter-846dc966c5-8rszg
12:32:11 ReplicaSet mt-broker-filter-846dc966c5 6096:	Created pod: mt-broker-filter-846dc966c5-4xmnf
12:42:38 ReplicaSet mt-broker-filter-846dc966c5 9414:	Created pod: mt-broker-filter-846dc966c5-hm8lg
12:47:20 ReplicaSet mt-broker-filter-846dc966c5 11500:	Created pod: mt-broker-filter-846dc966c5-6hpfl
12:53:11 ReplicaSet mt-broker-filter-846dc966c5 13668:	Created pod: mt-broker-filter-846dc966c5-k28qj
12:21:28 Deployment mt-broker-filter 1233:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:27:23 Deployment mt-broker-filter 3734:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:32:11 Deployment mt-broker-filter 6095:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:42:38 Deployment mt-broker-filter 9413:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:47:20 Deployment mt-broker-filter 11499:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:53:11 Deployment mt-broker-filter 13667:	Scaled up replica set mt-broker-filter-846dc966c5 to 1
12:32:11 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6119:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-2cb2z to acto-cluster-13-worker2
12:32:12 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:32:12 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Created container ingress
12:32:12 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Started container ingress
12:32:12 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Readiness probe failed: Get "http://10.244.2.12:8080/healthz": dial tcp 10.244.2.12:8080: connect: connection refused
12:41:58 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Stopping container ingress
12:41:59 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:41:59 Pod mt-broker-ingress-6dbbfff4b9-2cb2z 6122:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:27:23 Pod mt-broker-ingress-6dbbfff4b9-58js8 3755:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-58js8 to acto-cluster-13-worker
12:27:24 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:27:30 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 6.780288273s
12:27:30 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Created container ingress
12:27:31 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Started container ingress
12:31:30 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Stopping container ingress
12:31:31 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:31:31 Pod mt-broker-ingress-6dbbfff4b9-58js8 3758:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:53:11 Pod mt-broker-ingress-6dbbfff4b9-78rff 13695:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-78rff to acto-cluster-13-worker
12:53:12 Pod mt-broker-ingress-6dbbfff4b9-78rff 13698:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:53:12 Pod mt-broker-ingress-6dbbfff4b9-78rff 13698:	Created container ingress
12:53:12 Pod mt-broker-ingress-6dbbfff4b9-78rff 13698:	Started container ingress
12:53:12 Pod mt-broker-ingress-6dbbfff4b9-78rff 13698:	Readiness probe failed: Get "http://10.244.1.21:8080/healthz": dial tcp 10.244.1.21:8080: connect: connection refused
12:47:21 Pod mt-broker-ingress-6dbbfff4b9-fltm5 11521:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-fltm5 to acto-cluster-13-worker
12:47:21 Pod mt-broker-ingress-6dbbfff4b9-fltm5 11525:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:47:21 Pod mt-broker-ingress-6dbbfff4b9-fltm5 11525:	Created container ingress
12:47:22 Pod mt-broker-ingress-6dbbfff4b9-fltm5 11525:	Started container ingress
12:51:23 Pod mt-broker-ingress-6dbbfff4b9-fltm5 11525:	Stopping container ingress
12:21:29 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1269:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-nrrpf to acto-cluster-13-worker2
12:21:29 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Pulling image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f"
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" in 4.571060587s
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Created container ingress
12:21:34 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Started container ingress
12:25:32 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Stopping container ingress
12:25:33 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:25:33 Pod mt-broker-ingress-6dbbfff4b9-nrrpf 1272:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:42:39 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9437:	Successfully assigned knative-eventing/mt-broker-ingress-6dbbfff4b9-sbdxx to acto-cluster-13-worker2
12:42:39 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9440:	Container image "gcr.io/knative-releases/knative.dev/eventing/cmd/broker/ingress@sha256:924bbc1944abb6ab91a8c3d7d6dfbb27f1e55b56ec456b9efc88e4f7320bae2f" already present on machine
12:42:39 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9440:	Created container ingress
12:42:40 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9440:	Started container ingress
12:46:42 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9440:	Stopping container ingress
12:46:43 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9440:	Liveness probe failed: HTTP probe failed with statuscode: 503
12:46:43 Pod mt-broker-ingress-6dbbfff4b9-sbdxx 9440:	Readiness probe failed: HTTP probe failed with statuscode: 503
12:21:29 ReplicaSet mt-broker-ingress-6dbbfff4b9 1267:	Created pod: mt-broker-ingress-6dbbfff4b9-nrrpf
12:27:23 ReplicaSet mt-broker-ingress-6dbbfff4b9 3752:	Created pod: mt-broker-ingress-6dbbfff4b9-58js8
12:32:11 ReplicaSet mt-broker-ingress-6dbbfff4b9 6117:	Created pod: mt-broker-ingress-6dbbfff4b9-2cb2z
12:42:39 ReplicaSet mt-broker-ingress-6dbbfff4b9 9435:	Created pod: mt-broker-ingress-6dbbfff4b9-sbdxx
12:47:21 ReplicaSet mt-broker-ingress-6dbbfff4b9 11519:	Created pod: mt-broker-ingress-6dbbfff4b9-fltm5
12:53:11 ReplicaSet mt-broker-ingress-6dbbfff4b9 13693:	Created pod: mt-broker-ingress-6dbbfff4b9-78rff
12:21:29 Deployment mt-broker-ingress 1266:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:27:23 Deployment mt-broker-ingress 3751:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:32:11 Deployment mt-broker-ingress 6115:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:42:39 Deployment mt-broker-ingress 9434:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:47:21 Deployment mt-broker-ingress 11518:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:53:11 Deployment mt-broker-ingress 13692:	Scaled up replica set mt-broker-ingress-6dbbfff4b9 to 1
12:32:14 Pod redis-controller-manager-0 6263:	Successfully assigned knative-eventing/redis-controller-manager-0 to acto-cluster-13-worker2
12:32:15 Pod redis-controller-manager-0 6267:	Pulling image "gcr.io/knative-releases/knative.dev/eventing-redis/source/cmd/controller@sha256:f8037befa9b6f90033979b84ff7b943c7e2861394478050ca1e6f604922dfa36"
12:32:19 Pod redis-controller-manager-0 6267:	Successfully pulled image "gcr.io/knative-releases/knative.dev/eventing-redis/source/cmd/controller@sha256:f8037befa9b6f90033979b84ff7b943c7e2861394478050ca1e6f604922dfa36" in 3.88821435s
12:32:19 Pod redis-controller-manager-0 6267:	Created container manager
12:32:19 Pod redis-controller-manager-0 6267:	Started container manager
12:41:56 Pod redis-controller-manager-0 6267:	Stopping container manager
12:32:14 StatefulSet redis-controller-manager 6261:	create Pod redis-controller-manager-0 in StatefulSet redis-controller-manager successful
12:53:12 Pod storage-version-migration-eventing-eventing-1.6.0--1-bbmnd 13751:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-bbmnd to acto-cluster-13-worker
12:53:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-bbmnd 13753:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:53:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-bbmnd 13753:	Created container migrate
12:53:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-bbmnd 13753:	Started container migrate
12:47:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-gzjpf 11575:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-gzjpf to acto-cluster-13-worker3
12:47:22 Pod storage-version-migration-eventing-eventing-1.6.0--1-gzjpf 11577:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:47:23 Pod storage-version-migration-eventing-eventing-1.6.0--1-gzjpf 11577:	Created container migrate
12:47:23 Pod storage-version-migration-eventing-eventing-1.6.0--1-gzjpf 11577:	Started container migrate
12:21:30 Pod storage-version-migration-eventing-eventing-1.6.0--1-jf2c5 1315:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-jf2c5 to acto-cluster-13-worker2
12:21:30 Pod storage-version-migration-eventing-eventing-1.6.0--1-jf2c5 1317:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:21:37 Pod storage-version-migration-eventing-eventing-1.6.0--1-jf2c5 1317:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 6.474814198s
12:21:37 Pod storage-version-migration-eventing-eventing-1.6.0--1-jf2c5 1317:	Created container migrate
12:21:37 Pod storage-version-migration-eventing-eventing-1.6.0--1-jf2c5 1317:	Started container migrate
12:27:24 Pod storage-version-migration-eventing-eventing-1.6.0--1-pfflt 3825:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-pfflt to acto-cluster-13-worker
12:27:25 Pod storage-version-migration-eventing-eventing-1.6.0--1-pfflt 3827:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:27:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-pfflt 3827:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 10.813463976s
12:27:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-pfflt 3827:	Created container migrate
12:27:36 Pod storage-version-migration-eventing-eventing-1.6.0--1-pfflt 3827:	Started container migrate
12:42:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-rff4h 9494:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-rff4h to acto-cluster-13-worker
12:42:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-rff4h 9497:	Container image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" already present on machine
12:42:40 Pod storage-version-migration-eventing-eventing-1.6.0--1-rff4h 9497:	Created container migrate
12:42:41 Pod storage-version-migration-eventing-eventing-1.6.0--1-rff4h 9497:	Started container migrate
12:32:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-tc725 6200:	Successfully assigned knative-eventing/storage-version-migration-eventing-eventing-1.6.0--1-tc725 to acto-cluster-13-worker3
12:32:13 Pod storage-version-migration-eventing-eventing-1.6.0--1-tc725 6202:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b"
12:32:16 Pod storage-version-migration-eventing-eventing-1.6.0--1-tc725 6202:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate@sha256:c456482a9cd1c9a443c6e56bf9c7a5efb6a687602eef74481895cf215c76d19b" in 2.574459084s
12:32:16 Pod storage-version-migration-eventing-eventing-1.6.0--1-tc725 6202:	Created container migrate
12:32:16 Pod storage-version-migration-eventing-eventing-1.6.0--1-tc725 6202:	Started container migrate
12:21:30 Job storage-version-migration-eventing-eventing-1.6.0 1313:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-jf2c5
12:21:43 Job storage-version-migration-eventing-eventing-1.6.0 1318:	Job completed
12:27:24 Job storage-version-migration-eventing-eventing-1.6.0 3824:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-pfflt
12:27:41 Job storage-version-migration-eventing-eventing-1.6.0 3829:	Job completed
12:32:13 Job storage-version-migration-eventing-eventing-1.6.0 6199:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-tc725
12:32:21 Job storage-version-migration-eventing-eventing-1.6.0 6204:	Job completed
12:42:40 Job storage-version-migration-eventing-eventing-1.6.0 9493:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-rff4h
12:42:47 Job storage-version-migration-eventing-eventing-1.6.0 9498:	Job completed
12:47:22 Job storage-version-migration-eventing-eventing-1.6.0 11573:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-gzjpf
12:47:28 Job storage-version-migration-eventing-eventing-1.6.0 11580:	Job completed
12:53:12 Job storage-version-migration-eventing-eventing-1.6.0 13750:	Created pod: storage-version-migration-eventing-eventing-1.6.0--1-bbmnd
12:53:18 Job storage-version-migration-eventing-eventing-1.6.0 13755:	Job completed
12:21:06 KnativeEventing test-cluster 848:	Updated "test-cluster" finalizers
12:27:03 KnativeEventing test-cluster 3394:	Updated "test-cluster" finalizers
12:31:51 KnativeEventing test-cluster 5790:	Updated "test-cluster" finalizers
12:42:20 KnativeEventing test-cluster 9055:	Updated "test-cluster" finalizers
12:47:01 KnativeEventing test-cluster 11121:	Updated "test-cluster" finalizers
12:52:52 KnativeEventing test-cluster 13323:	Updated "test-cluster" finalizers
