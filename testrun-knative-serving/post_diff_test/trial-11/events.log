17:20:17 Pod 3scale-kourier-gateway-6966cb4956-4tf6s 3032:	Successfully assigned knative-serving/3scale-kourier-gateway-6966cb4956-4tf6s to acto-cluster-11-worker3
17:20:18 Pod 3scale-kourier-gateway-6966cb4956-4tf6s 3035:	Pulling image "docker.io/envoyproxy/envoy:v1.20-latest"
17:20:21 Pod 3scale-kourier-gateway-6966cb4956-4tf6s 3035:	Successfully pulled image "docker.io/envoyproxy/envoy:v1.20-latest" in 2.974456002s
17:20:21 Pod 3scale-kourier-gateway-6966cb4956-4tf6s 3035:	Created container kourier-gateway
17:20:21 Pod 3scale-kourier-gateway-6966cb4956-4tf6s 3035:	Started container kourier-gateway
17:28:59 Pod 3scale-kourier-gateway-6966cb4956-4tf6s 3035:	Stopping container kourier-gateway
17:34:54 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7160:	Successfully assigned knative-serving/3scale-kourier-gateway-6966cb4956-fznfg to acto-cluster-11-worker2
17:34:55 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7162:	Pulling image "docker.io/envoyproxy/envoy:v1.20-latest"
17:34:58 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7162:	Successfully pulled image "docker.io/envoyproxy/envoy:v1.20-latest" in 2.975406023s
17:34:58 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7162:	Created container kourier-gateway
17:34:58 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7162:	Started container kourier-gateway
17:35:09 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7162:	Readiness probe failed: Get "http://10.244.1.14:8081/ready": dial tcp 10.244.1.14:8081: connect: connection refused
17:38:54 Pod 3scale-kourier-gateway-6966cb4956-fznfg 7162:	Stopping container kourier-gateway
17:14:44 Pod 3scale-kourier-gateway-6966cb4956-jvrm6 1171:	Successfully assigned knative-serving/3scale-kourier-gateway-6966cb4956-jvrm6 to acto-cluster-11-worker
17:14:45 Pod 3scale-kourier-gateway-6966cb4956-jvrm6 1174:	Pulling image "docker.io/envoyproxy/envoy:v1.20-latest"
17:14:54 Pod 3scale-kourier-gateway-6966cb4956-jvrm6 1174:	Successfully pulled image "docker.io/envoyproxy/envoy:v1.20-latest" in 8.916748049s
17:14:54 Pod 3scale-kourier-gateway-6966cb4956-jvrm6 1174:	Created container kourier-gateway
17:14:54 Pod 3scale-kourier-gateway-6966cb4956-jvrm6 1174:	Started container kourier-gateway
17:18:44 Pod 3scale-kourier-gateway-6966cb4956-jvrm6 1174:	Stopping container kourier-gateway
17:30:32 Pod 3scale-kourier-gateway-6966cb4956-lpm66 5439:	Successfully assigned knative-serving/3scale-kourier-gateway-6966cb4956-lpm66 to acto-cluster-11-worker
17:30:32 Pod 3scale-kourier-gateway-6966cb4956-lpm66 5441:	Container image "docker.io/envoyproxy/envoy:v1.20-latest" already present on machine
17:30:32 Pod 3scale-kourier-gateway-6966cb4956-lpm66 5441:	Created container kourier-gateway
17:30:33 Pod 3scale-kourier-gateway-6966cb4956-lpm66 5441:	Started container kourier-gateway
17:34:30 Pod 3scale-kourier-gateway-6966cb4956-lpm66 5441:	Stopping container kourier-gateway
17:40:36 Pod 3scale-kourier-gateway-6966cb4956-t4l24 9090:	Successfully assigned knative-serving/3scale-kourier-gateway-6966cb4956-t4l24 to acto-cluster-11-worker3
17:40:37 Pod 3scale-kourier-gateway-6966cb4956-t4l24 9093:	Container image "docker.io/envoyproxy/envoy:v1.20-latest" already present on machine
17:40:37 Pod 3scale-kourier-gateway-6966cb4956-t4l24 9093:	Created container kourier-gateway
17:40:37 Pod 3scale-kourier-gateway-6966cb4956-t4l24 9093:	Started container kourier-gateway
17:14:44 ReplicaSet 3scale-kourier-gateway-6966cb4956 1168:	Created pod: 3scale-kourier-gateway-6966cb4956-jvrm6
17:20:17 ReplicaSet 3scale-kourier-gateway-6966cb4956 3030:	Created pod: 3scale-kourier-gateway-6966cb4956-4tf6s
17:30:32 ReplicaSet 3scale-kourier-gateway-6966cb4956 5435:	Created pod: 3scale-kourier-gateway-6966cb4956-lpm66
17:34:54 ReplicaSet 3scale-kourier-gateway-6966cb4956 7157:	Created pod: 3scale-kourier-gateway-6966cb4956-fznfg
17:40:36 ReplicaSet 3scale-kourier-gateway-6966cb4956 9088:	Created pod: 3scale-kourier-gateway-6966cb4956-t4l24
17:14:44 Deployment 3scale-kourier-gateway 1167:	Scaled up replica set 3scale-kourier-gateway-6966cb4956 to 1
17:20:17 Deployment 3scale-kourier-gateway 3029:	Scaled up replica set 3scale-kourier-gateway-6966cb4956 to 1
17:30:32 Deployment 3scale-kourier-gateway 5434:	Scaled up replica set 3scale-kourier-gateway-6966cb4956 to 1
17:34:54 Deployment 3scale-kourier-gateway 7156:	Scaled up replica set 3scale-kourier-gateway-6966cb4956 to 1
17:40:36 Deployment 3scale-kourier-gateway 9087:	Scaled up replica set 3scale-kourier-gateway-6966cb4956 to 1
17:14:39 Pod activator-5cbfc86654-6d78g 977:	Successfully assigned knative-serving/activator-5cbfc86654-6d78g to acto-cluster-11-worker3
17:14:40 Pod activator-5cbfc86654-6d78g 980:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/activator:v1.6.0"
17:14:43 Pod activator-5cbfc86654-6d78g 980:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/activator:v1.6.0" in 3.284800996s
17:14:43 Pod activator-5cbfc86654-6d78g 980:	Created container activator
17:14:43 Pod activator-5cbfc86654-6d78g 980:	Started container activator
17:14:44 Pod activator-5cbfc86654-6d78g 980:	Readiness probe failed: HTTP probe failed with statuscode: 500
17:18:48 Pod activator-5cbfc86654-6d78g 980:	Stopping container activator
17:18:49 Pod activator-5cbfc86654-6d78g 980:	Liveness probe failed: HTTP probe failed with statuscode: 500
17:40:31 Pod activator-5cbfc86654-9l622 8817:	Successfully assigned knative-serving/activator-5cbfc86654-9l622 to acto-cluster-11-worker3
17:40:32 Pod activator-5cbfc86654-9l622 8821:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/activator:v1.6.0" already present on machine
17:40:32 Pod activator-5cbfc86654-9l622 8821:	Created container activator
17:40:32 Pod activator-5cbfc86654-9l622 8821:	Started container activator
17:40:33 Pod activator-5cbfc86654-9l622 8821:	Readiness probe failed: HTTP probe failed with statuscode: 500
17:20:12 Pod activator-5cbfc86654-cldmc 2822:	Successfully assigned knative-serving/activator-5cbfc86654-cldmc to acto-cluster-11-worker3
17:20:13 Pod activator-5cbfc86654-cldmc 2825:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/activator:v1.6.0" already present on machine
17:20:13 Pod activator-5cbfc86654-cldmc 2825:	Created container activator
17:20:13 Pod activator-5cbfc86654-cldmc 2825:	Started container activator
17:20:14 Pod activator-5cbfc86654-cldmc 2825:	Readiness probe failed: HTTP probe failed with statuscode: 500
17:29:03 Pod activator-5cbfc86654-cldmc 2825:	Stopping container activator
17:30:27 Pod activator-5cbfc86654-gv6vs 5212:	Successfully assigned knative-serving/activator-5cbfc86654-gv6vs to acto-cluster-11-worker3
17:30:28 Pod activator-5cbfc86654-gv6vs 5214:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/activator:v1.6.0" already present on machine
17:30:28 Pod activator-5cbfc86654-gv6vs 5214:	Created container activator
17:30:28 Pod activator-5cbfc86654-gv6vs 5214:	Started container activator
17:30:28 Pod activator-5cbfc86654-gv6vs 5214:	Readiness probe failed: HTTP probe failed with statuscode: 500
17:34:35 Pod activator-5cbfc86654-gv6vs 5214:	Stopping container activator
17:34:50 Pod activator-5cbfc86654-sgrd8 6911:	Successfully assigned knative-serving/activator-5cbfc86654-sgrd8 to acto-cluster-11-worker3
17:34:50 Pod activator-5cbfc86654-sgrd8 6913:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/activator:v1.6.0" already present on machine
17:34:50 Pod activator-5cbfc86654-sgrd8 6913:	Created container activator
17:34:50 Pod activator-5cbfc86654-sgrd8 6913:	Started container activator
17:34:51 Pod activator-5cbfc86654-sgrd8 6913:	Readiness probe failed: HTTP probe failed with statuscode: 500
17:38:57 Pod activator-5cbfc86654-sgrd8 6913:	Stopping container activator
17:14:39 ReplicaSet activator-5cbfc86654 974:	Created pod: activator-5cbfc86654-6d78g
17:20:12 ReplicaSet activator-5cbfc86654 2819:	Created pod: activator-5cbfc86654-cldmc
17:30:27 ReplicaSet activator-5cbfc86654 5209:	Created pod: activator-5cbfc86654-gv6vs
17:34:50 ReplicaSet activator-5cbfc86654 6908:	Created pod: activator-5cbfc86654-sgrd8
17:40:31 ReplicaSet activator-5cbfc86654 8814:	Created pod: activator-5cbfc86654-9l622
17:14:39 PodDisruptionBudget activator-pdb 968:	No matching pods found
17:18:48 PodDisruptionBudget activator-pdb 1386:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:20:12 PodDisruptionBudget activator-pdb 2813:	No matching pods found
17:29:03 PodDisruptionBudget activator-pdb 3193:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:30:27 PodDisruptionBudget activator-pdb 5204:	No matching pods found
17:34:35 PodDisruptionBudget activator-pdb 5626:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:34:49 PodDisruptionBudget activator-pdb 6903:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:34:50 PodDisruptionBudget activator-pdb 6905:	Failed to calculate the number of expected pods: found no controllers for pod "activator-5cbfc86654-gv6vs"
17:40:31 PodDisruptionBudget activator-pdb 8807:	No matching pods found
17:14:39 Deployment activator 973:	Scaled up replica set activator-5cbfc86654 to 1
17:14:54 HorizontalPodAutoscaler activator 967:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:14:54 HorizontalPodAutoscaler activator 967:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:20:12 Deployment activator 2818:	Scaled up replica set activator-5cbfc86654 to 1
17:20:27 HorizontalPodAutoscaler activator 2812:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:20:27 HorizontalPodAutoscaler activator 2812:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:30:27 Deployment activator 5208:	Scaled up replica set activator-5cbfc86654 to 1
17:30:42 HorizontalPodAutoscaler activator 5203:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:30:42 HorizontalPodAutoscaler activator 5203:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:34:50 Deployment activator 6907:	Scaled up replica set activator-5cbfc86654 to 1
17:35:04 HorizontalPodAutoscaler activator 6902:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:35:04 HorizontalPodAutoscaler activator 6902:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:40:31 Deployment activator 8813:	Scaled up replica set activator-5cbfc86654 to 1
17:40:46 HorizontalPodAutoscaler activator 8806:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:40:46 HorizontalPodAutoscaler activator 8806:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:40:32 Pod autoscaler-575ffcc8b6-45txs 8834:	Successfully assigned knative-serving/autoscaler-575ffcc8b6-45txs to acto-cluster-11-worker2
17:40:32 Pod autoscaler-575ffcc8b6-45txs 8837:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0" already present on machine
17:40:32 Pod autoscaler-575ffcc8b6-45txs 8837:	Created container autoscaler
17:40:33 Pod autoscaler-575ffcc8b6-45txs 8837:	Started container autoscaler
17:40:33 Pod autoscaler-575ffcc8b6-45txs 8837:	Readiness probe failed: Get "http://10.244.1.15:8080/": dial tcp 10.244.1.15:8080: connect: connection refused
17:30:27 Pod autoscaler-575ffcc8b6-4fd54 5229:	Successfully assigned knative-serving/autoscaler-575ffcc8b6-4fd54 to acto-cluster-11-worker
17:30:28 Pod autoscaler-575ffcc8b6-4fd54 5232:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0" already present on machine
17:30:28 Pod autoscaler-575ffcc8b6-4fd54 5232:	Created container autoscaler
17:30:28 Pod autoscaler-575ffcc8b6-4fd54 5232:	Started container autoscaler
17:34:34 Pod autoscaler-575ffcc8b6-4fd54 5232:	Stopping container autoscaler
17:14:40 Pod autoscaler-575ffcc8b6-8w2kd 995:	Successfully assigned knative-serving/autoscaler-575ffcc8b6-8w2kd to acto-cluster-11-worker
17:14:40 Pod autoscaler-575ffcc8b6-8w2kd 999:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0"
17:14:43 Pod autoscaler-575ffcc8b6-8w2kd 999:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0" in 3.127869706s
17:14:43 Pod autoscaler-575ffcc8b6-8w2kd 999:	Created container autoscaler
17:14:44 Pod autoscaler-575ffcc8b6-8w2kd 999:	Started container autoscaler
17:18:48 Pod autoscaler-575ffcc8b6-8w2kd 999:	Stopping container autoscaler
17:20:13 Pod autoscaler-575ffcc8b6-drv5z 2839:	Successfully assigned knative-serving/autoscaler-575ffcc8b6-drv5z to acto-cluster-11-worker2
17:20:13 Pod autoscaler-575ffcc8b6-drv5z 2842:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0"
17:20:16 Pod autoscaler-575ffcc8b6-drv5z 2842:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0" in 2.921616582s
17:20:16 Pod autoscaler-575ffcc8b6-drv5z 2842:	Created container autoscaler
17:20:17 Pod autoscaler-575ffcc8b6-drv5z 2842:	Started container autoscaler
17:20:17 Pod autoscaler-575ffcc8b6-drv5z 2842:	Readiness probe failed: Get "http://10.244.1.6:8080/": dial tcp 10.244.1.6:8080: connect: connection refused
17:29:03 Pod autoscaler-575ffcc8b6-drv5z 2842:	Stopping container autoscaler
17:29:03 Pod autoscaler-575ffcc8b6-drv5z 2842:	Liveness probe failed: Get "http://10.244.1.6:8080/": read tcp 10.244.1.1:43304->10.244.1.6:8080: read: connection reset by peer
17:34:50 Pod autoscaler-575ffcc8b6-f6s68 6930:	Successfully assigned knative-serving/autoscaler-575ffcc8b6-f6s68 to acto-cluster-11-worker2
17:34:51 Pod autoscaler-575ffcc8b6-f6s68 6934:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler:v1.6.0" already present on machine
17:34:51 Pod autoscaler-575ffcc8b6-f6s68 6934:	Created container autoscaler
17:34:51 Pod autoscaler-575ffcc8b6-f6s68 6934:	Started container autoscaler
17:34:51 Pod autoscaler-575ffcc8b6-f6s68 6934:	Readiness probe failed: Get "http://10.244.1.11:8080/": dial tcp 10.244.1.11:8080: connect: connection refused
17:38:57 Pod autoscaler-575ffcc8b6-f6s68 6934:	Stopping container autoscaler
17:14:40 ReplicaSet autoscaler-575ffcc8b6 993:	Created pod: autoscaler-575ffcc8b6-8w2kd
17:20:13 ReplicaSet autoscaler-575ffcc8b6 2837:	Created pod: autoscaler-575ffcc8b6-drv5z
17:30:27 ReplicaSet autoscaler-575ffcc8b6 5227:	Created pod: autoscaler-575ffcc8b6-4fd54
17:34:50 ReplicaSet autoscaler-575ffcc8b6 6929:	Created pod: autoscaler-575ffcc8b6-f6s68
17:40:32 ReplicaSet autoscaler-575ffcc8b6 8832:	Created pod: autoscaler-575ffcc8b6-45txs
17:34:53 Pod autoscaler-hpa-77f844b585-cm2dm 7082:	Successfully assigned knative-serving/autoscaler-hpa-77f844b585-cm2dm to acto-cluster-11-worker
17:34:53 Pod autoscaler-hpa-77f844b585-cm2dm 7086:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0"
17:34:56 Pod autoscaler-hpa-77f844b585-cm2dm 7086:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0" in 3.066543185s
17:34:56 Pod autoscaler-hpa-77f844b585-cm2dm 7086:	Created container autoscaler-hpa
17:34:57 Pod autoscaler-hpa-77f844b585-cm2dm 7086:	Started container autoscaler-hpa
17:38:53 Pod autoscaler-hpa-77f844b585-cm2dm 7086:	Stopping container autoscaler-hpa
17:30:30 Pod autoscaler-hpa-77f844b585-g2sbv 5375:	Successfully assigned knative-serving/autoscaler-hpa-77f844b585-g2sbv to acto-cluster-11-worker3
17:30:31 Pod autoscaler-hpa-77f844b585-g2sbv 5377:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0" already present on machine
17:30:31 Pod autoscaler-hpa-77f844b585-g2sbv 5377:	Created container autoscaler-hpa
17:30:31 Pod autoscaler-hpa-77f844b585-g2sbv 5377:	Started container autoscaler-hpa
17:34:31 Pod autoscaler-hpa-77f844b585-g2sbv 5377:	Stopping container autoscaler-hpa
17:14:42 Pod autoscaler-hpa-77f844b585-hk8ps 1098:	Successfully assigned knative-serving/autoscaler-hpa-77f844b585-hk8ps to acto-cluster-11-worker3
17:14:43 Pod autoscaler-hpa-77f844b585-hk8ps 1102:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0"
17:14:51 Pod autoscaler-hpa-77f844b585-hk8ps 1102:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0" in 7.639007511s
17:14:51 Pod autoscaler-hpa-77f844b585-hk8ps 1102:	Created container autoscaler-hpa
17:14:51 Pod autoscaler-hpa-77f844b585-hk8ps 1102:	Started container autoscaler-hpa
17:18:44 Pod autoscaler-hpa-77f844b585-hk8ps 1102:	Stopping container autoscaler-hpa
17:20:15 Pod autoscaler-hpa-77f844b585-qpwkz 2951:	Successfully assigned knative-serving/autoscaler-hpa-77f844b585-qpwkz to acto-cluster-11-worker2
17:20:16 Pod autoscaler-hpa-77f844b585-qpwkz 2955:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0"
17:20:20 Pod autoscaler-hpa-77f844b585-qpwkz 2955:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0" in 3.556958284s
17:20:20 Pod autoscaler-hpa-77f844b585-qpwkz 2955:	Created container autoscaler-hpa
17:20:20 Pod autoscaler-hpa-77f844b585-qpwkz 2955:	Started container autoscaler-hpa
17:28:59 Pod autoscaler-hpa-77f844b585-qpwkz 2955:	Stopping container autoscaler-hpa
17:40:34 Pod autoscaler-hpa-77f844b585-zzrjl 9002:	Successfully assigned knative-serving/autoscaler-hpa-77f844b585-zzrjl to acto-cluster-11-worker
17:40:35 Pod autoscaler-hpa-77f844b585-zzrjl 9005:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler-hpa:v1.6.0" already present on machine
17:40:35 Pod autoscaler-hpa-77f844b585-zzrjl 9005:	Created container autoscaler-hpa
17:40:35 Pod autoscaler-hpa-77f844b585-zzrjl 9005:	Started container autoscaler-hpa
17:14:42 ReplicaSet autoscaler-hpa-77f844b585 1097:	Created pod: autoscaler-hpa-77f844b585-hk8ps
17:20:15 ReplicaSet autoscaler-hpa-77f844b585 2949:	Created pod: autoscaler-hpa-77f844b585-qpwkz
17:30:30 ReplicaSet autoscaler-hpa-77f844b585 5373:	Created pod: autoscaler-hpa-77f844b585-g2sbv
17:34:53 ReplicaSet autoscaler-hpa-77f844b585 7079:	Created pod: autoscaler-hpa-77f844b585-cm2dm
17:40:34 ReplicaSet autoscaler-hpa-77f844b585 9000:	Created pod: autoscaler-hpa-77f844b585-zzrjl
17:14:42 Deployment autoscaler-hpa 1096:	Scaled up replica set autoscaler-hpa-77f844b585 to 1
17:20:15 Deployment autoscaler-hpa 2948:	Scaled up replica set autoscaler-hpa-77f844b585 to 1
17:30:30 Deployment autoscaler-hpa 5372:	Scaled up replica set autoscaler-hpa-77f844b585 to 1
17:34:53 Deployment autoscaler-hpa 7078:	Scaled up replica set autoscaler-hpa-77f844b585 to 1
17:40:34 Deployment autoscaler-hpa 8999:	Scaled up replica set autoscaler-hpa-77f844b585 to 1
17:14:40 Deployment autoscaler 992:	Scaled up replica set autoscaler-575ffcc8b6 to 1
17:20:13 Deployment autoscaler 2836:	Scaled up replica set autoscaler-575ffcc8b6 to 1
17:30:27 Deployment autoscaler 5226:	Scaled up replica set autoscaler-575ffcc8b6 to 1
17:34:50 Deployment autoscaler 6928:	Scaled up replica set autoscaler-575ffcc8b6 to 1
17:40:32 Deployment autoscaler 8831:	Scaled up replica set autoscaler-575ffcc8b6 to 1
17:40:32 Pod controller-55cf84c8df-q9zth 8853:	Successfully assigned knative-serving/controller-55cf84c8df-q9zth to acto-cluster-11-worker
17:40:33 Pod controller-55cf84c8df-q9zth 8856:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0" already present on machine
17:40:33 Pod controller-55cf84c8df-q9zth 8856:	Created container controller
17:40:33 Pod controller-55cf84c8df-q9zth 8856:	Started container controller
17:34:50 Pod controller-55cf84c8df-vsmqh 6952:	Successfully assigned knative-serving/controller-55cf84c8df-vsmqh to acto-cluster-11-worker3
17:34:51 Pod controller-55cf84c8df-vsmqh 6956:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0"
17:34:54 Pod controller-55cf84c8df-vsmqh 6956:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0" in 2.758088176s
17:34:54 Pod controller-55cf84c8df-vsmqh 6956:	Created container controller
17:34:54 Pod controller-55cf84c8df-vsmqh 6956:	Started container controller
17:38:56 Pod controller-55cf84c8df-vsmqh 6956:	Stopping container controller
17:14:40 Pod controller-55cf84c8df-wlbgp 1015:	Successfully assigned knative-serving/controller-55cf84c8df-wlbgp to acto-cluster-11-worker
17:14:41 Pod controller-55cf84c8df-wlbgp 1018:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0"
17:14:47 Pod controller-55cf84c8df-wlbgp 1018:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0" in 6.411556337s
17:14:47 Pod controller-55cf84c8df-wlbgp 1018:	Created container controller
17:14:47 Pod controller-55cf84c8df-wlbgp 1018:	Started container controller
17:18:47 Pod controller-55cf84c8df-wlbgp 1018:	Stopping container controller
17:14:40 ReplicaSet controller-55cf84c8df 1013:	Created pod: controller-55cf84c8df-wlbgp
17:34:50 ReplicaSet controller-55cf84c8df 6950:	Created pod: controller-55cf84c8df-vsmqh
17:40:32 ReplicaSet controller-55cf84c8df 8851:	Created pod: controller-55cf84c8df-q9zth
17:20:13 Pod controller-66cbfc5d9b-bdzqr 2859:	0/4 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 3 node(s) didn't match Pod's node affinity/selector.
17:20:13 ReplicaSet controller-66cbfc5d9b 2857:	Created pod: controller-66cbfc5d9b-bdzqr
17:30:28 Pod controller-7ccd75bb85-qvkkb 5249:	Successfully assigned knative-serving/controller-7ccd75bb85-qvkkb to acto-cluster-11-worker2
17:30:28 Pod controller-7ccd75bb85-qvkkb 5252:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0"
17:30:32 Pod controller-7ccd75bb85-qvkkb 5252:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/controller:v1.6.0" in 3.216847918s
17:30:32 Pod controller-7ccd75bb85-qvkkb 5252:	Created container controller
17:30:32 Pod controller-7ccd75bb85-qvkkb 5252:	Started container controller
17:34:34 Pod controller-7ccd75bb85-qvkkb 5252:	Stopping container controller
17:30:28 ReplicaSet controller-7ccd75bb85 5247:	Created pod: controller-7ccd75bb85-qvkkb
17:14:40 Deployment controller 1012:	Scaled up replica set controller-55cf84c8df to 1
17:20:13 Deployment controller 2856:	Scaled up replica set controller-66cbfc5d9b to 1
17:30:28 Deployment controller 5246:	Scaled up replica set controller-7ccd75bb85 to 1
17:34:50 Deployment controller 6949:	Scaled up replica set controller-55cf84c8df to 1
17:40:32 Deployment controller 8850:	Scaled up replica set controller-55cf84c8df to 1
17:30:28 Pod domain-mapping-594c9b6787-gpf9m 5273:	Successfully assigned knative-serving/domain-mapping-594c9b6787-gpf9m to acto-cluster-11-worker3
17:30:29 Pod domain-mapping-594c9b6787-gpf9m 5276:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0" already present on machine
17:30:29 Pod domain-mapping-594c9b6787-gpf9m 5276:	Created container domain-mapping
17:30:29 Pod domain-mapping-594c9b6787-gpf9m 5276:	Started container domain-mapping
17:34:33 Pod domain-mapping-594c9b6787-gpf9m 5276:	Stopping container domain-mapping
17:34:51 Pod domain-mapping-594c9b6787-j7td7 6976:	Successfully assigned knative-serving/domain-mapping-594c9b6787-j7td7 to acto-cluster-11-worker
17:34:52 Pod domain-mapping-594c9b6787-j7td7 6980:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0" already present on machine
17:34:52 Pod domain-mapping-594c9b6787-j7td7 6980:	Created container domain-mapping
17:34:52 Pod domain-mapping-594c9b6787-j7td7 6980:	Started container domain-mapping
17:38:56 Pod domain-mapping-594c9b6787-j7td7 6980:	Stopping container domain-mapping
17:40:33 Pod domain-mapping-594c9b6787-nwv96 8873:	Successfully assigned knative-serving/domain-mapping-594c9b6787-nwv96 to acto-cluster-11-worker3
17:40:33 Pod domain-mapping-594c9b6787-nwv96 8877:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0" already present on machine
17:40:33 Pod domain-mapping-594c9b6787-nwv96 8877:	Created container domain-mapping
17:40:34 Pod domain-mapping-594c9b6787-nwv96 8877:	Started container domain-mapping
17:14:40 Pod domain-mapping-594c9b6787-pgznw 1033:	Successfully assigned knative-serving/domain-mapping-594c9b6787-pgznw to acto-cluster-11-worker3
17:14:41 Pod domain-mapping-594c9b6787-pgznw 1036:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0"
17:14:47 Pod domain-mapping-594c9b6787-pgznw 1036:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0" in 5.562267585s
17:14:47 Pod domain-mapping-594c9b6787-pgznw 1036:	Created container domain-mapping
17:14:47 Pod domain-mapping-594c9b6787-pgznw 1036:	Started container domain-mapping
17:18:47 Pod domain-mapping-594c9b6787-pgznw 1036:	Stopping container domain-mapping
17:20:14 Pod domain-mapping-594c9b6787-smdw4 2879:	Successfully assigned knative-serving/domain-mapping-594c9b6787-smdw4 to acto-cluster-11-worker
17:20:14 Pod domain-mapping-594c9b6787-smdw4 2883:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0"
17:20:18 Pod domain-mapping-594c9b6787-smdw4 2883:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping:v1.6.0" in 3.04036365s
17:20:18 Pod domain-mapping-594c9b6787-smdw4 2883:	Created container domain-mapping
17:20:18 Pod domain-mapping-594c9b6787-smdw4 2883:	Started container domain-mapping
17:29:02 Pod domain-mapping-594c9b6787-smdw4 2883:	Stopping container domain-mapping
17:14:40 ReplicaSet domain-mapping-594c9b6787 1031:	Created pod: domain-mapping-594c9b6787-pgznw
17:20:14 ReplicaSet domain-mapping-594c9b6787 2877:	Created pod: domain-mapping-594c9b6787-smdw4
17:30:28 ReplicaSet domain-mapping-594c9b6787 5271:	Created pod: domain-mapping-594c9b6787-gpf9m
17:34:51 ReplicaSet domain-mapping-594c9b6787 6974:	Created pod: domain-mapping-594c9b6787-j7td7
17:40:32 ReplicaSet domain-mapping-594c9b6787 8871:	Created pod: domain-mapping-594c9b6787-nwv96
17:14:40 Deployment domain-mapping 1030:	Scaled up replica set domain-mapping-594c9b6787 to 1
17:20:14 Deployment domain-mapping 2876:	Scaled up replica set domain-mapping-594c9b6787 to 1
17:30:28 Deployment domain-mapping 5270:	Scaled up replica set domain-mapping-594c9b6787 to 1
17:34:51 Deployment domain-mapping 6973:	Scaled up replica set domain-mapping-594c9b6787 to 1
17:40:32 Deployment domain-mapping 8870:	Scaled up replica set domain-mapping-594c9b6787 to 1
17:30:28 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5288:	Successfully assigned knative-serving/domainmapping-webhook-6bd9b5f874-9qnc8 to acto-cluster-11-worker
17:30:29 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5291:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0" already present on machine
17:30:29 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5291:	Created container domainmapping-webhook
17:30:29 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5291:	Started container domainmapping-webhook
17:34:32 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5291:	Liveness probe failed: Get "https://10.244.3.11:8443/": remote error: tls: unrecognized name
17:34:32 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5291:	Readiness probe failed: Get "https://10.244.3.11:8443/": remote error: tls: unrecognized name
17:34:33 Pod domainmapping-webhook-6bd9b5f874-9qnc8 5291:	Stopping container domainmapping-webhook
17:14:41 Pod domainmapping-webhook-6bd9b5f874-brw78 1047:	Successfully assigned knative-serving/domainmapping-webhook-6bd9b5f874-brw78 to acto-cluster-11-worker2
17:14:41 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0"
17:14:44 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0" in 2.927052134s
17:14:44 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Created container domainmapping-webhook
17:14:45 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Started container domainmapping-webhook
17:14:45 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Readiness probe failed: Get "https://10.244.1.3:8443/": dial tcp 10.244.1.3:8443: connect: connection refused
17:18:46 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Readiness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
17:18:46 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Liveness probe failed: Get "https://10.244.1.3:8443/": remote error: tls: unrecognized name
17:18:47 Pod domainmapping-webhook-6bd9b5f874-brw78 1050:	Stopping container domainmapping-webhook
17:40:33 Pod domainmapping-webhook-6bd9b5f874-drg54 8892:	Successfully assigned knative-serving/domainmapping-webhook-6bd9b5f874-drg54 to acto-cluster-11-worker2
17:40:33 Pod domainmapping-webhook-6bd9b5f874-drg54 8895:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0" already present on machine
17:40:33 Pod domainmapping-webhook-6bd9b5f874-drg54 8895:	Created container domainmapping-webhook
17:40:34 Pod domainmapping-webhook-6bd9b5f874-drg54 8895:	Started container domainmapping-webhook
17:20:14 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2897:	Successfully assigned knative-serving/domainmapping-webhook-6bd9b5f874-kxgtd to acto-cluster-11-worker
17:20:15 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0"
17:20:25 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0" in 10.638858413s
17:20:25 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Created container domainmapping-webhook
17:20:25 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Started container domainmapping-webhook
17:29:01 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Liveness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
17:29:01 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Readiness probe failed: Get "https://10.244.3.7:8443/": remote error: tls: unrecognized name
17:29:02 Pod domainmapping-webhook-6bd9b5f874-kxgtd 2900:	Stopping container domainmapping-webhook
17:34:51 Pod domainmapping-webhook-6bd9b5f874-z2hbc 6999:	Successfully assigned knative-serving/domainmapping-webhook-6bd9b5f874-z2hbc to acto-cluster-11-worker2
17:34:52 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/domain-mapping-webhook:v1.6.0" already present on machine
17:34:52 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Created container domainmapping-webhook
17:34:52 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Started container domainmapping-webhook
17:34:52 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Readiness probe failed: Get "https://10.244.1.12:8443/": dial tcp 10.244.1.12:8443: connect: connection refused
17:38:55 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Liveness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
17:38:55 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Readiness probe failed: Get "https://10.244.1.12:8443/": remote error: tls: unrecognized name
17:38:56 Pod domainmapping-webhook-6bd9b5f874-z2hbc 7002:	Stopping container domainmapping-webhook
17:14:41 ReplicaSet domainmapping-webhook-6bd9b5f874 1045:	Created pod: domainmapping-webhook-6bd9b5f874-brw78
17:20:14 ReplicaSet domainmapping-webhook-6bd9b5f874 2895:	Created pod: domainmapping-webhook-6bd9b5f874-kxgtd
17:30:28 ReplicaSet domainmapping-webhook-6bd9b5f874 5286:	Created pod: domainmapping-webhook-6bd9b5f874-9qnc8
17:34:51 ReplicaSet domainmapping-webhook-6bd9b5f874 6997:	Created pod: domainmapping-webhook-6bd9b5f874-z2hbc
17:40:33 ReplicaSet domainmapping-webhook-6bd9b5f874 8890:	Created pod: domainmapping-webhook-6bd9b5f874-drg54
17:14:41 Deployment domainmapping-webhook 1044:	Scaled up replica set domainmapping-webhook-6bd9b5f874 to 1
17:20:14 Deployment domainmapping-webhook 2894:	Scaled up replica set domainmapping-webhook-6bd9b5f874 to 1
17:30:28 Deployment domainmapping-webhook 5285:	Scaled up replica set domainmapping-webhook-6bd9b5f874 to 1
17:34:51 Deployment domainmapping-webhook 6995:	Scaled up replica set domainmapping-webhook-6bd9b5f874 to 1
17:40:33 Deployment domainmapping-webhook 8889:	Scaled up replica set domainmapping-webhook-6bd9b5f874 to 1
17:14:23 Pod knative-operator-668fb586bb-4g88b 802:	Successfully assigned knative-serving/knative-operator-668fb586bb-4g88b to acto-cluster-11-worker2
17:14:24 Pod knative-operator-668fb586bb-4g88b 805:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
17:14:27 Pod knative-operator-668fb586bb-4g88b 805:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.962823s
17:14:27 Pod knative-operator-668fb586bb-4g88b 805:	Created container knative-operator
17:14:27 Pod knative-operator-668fb586bb-4g88b 805:	Started container knative-operator
17:18:55 Pod knative-operator-668fb586bb-4g88b 805:	Container image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" already present on machine
17:39:05 Pod knative-operator-668fb586bb-4g88b 805:	Back-off restarting failed container
17:14:23 ReplicaSet knative-operator-668fb586bb 799:	Created pod: knative-operator-668fb586bb-4g88b
17:14:13 Pod knative-operator-79bf74d66d-xt2vh 761:	Successfully assigned knative-serving/knative-operator-79bf74d66d-xt2vh to acto-cluster-11-worker3
17:14:14 Pod knative-operator-79bf74d66d-xt2vh 763:	Pulling image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0"
17:14:17 Pod knative-operator-79bf74d66d-xt2vh 763:	Successfully pulled image "gcr.io/knative-releases/knative.dev/operator/cmd/operator:v1.6.0" in 2.99756043s
17:14:17 Pod knative-operator-79bf74d66d-xt2vh 763:	Created container knative-operator
17:14:17 Pod knative-operator-79bf74d66d-xt2vh 763:	Started container knative-operator
17:14:28 Pod knative-operator-79bf74d66d-xt2vh 763:	Stopping container knative-operator
17:14:13 ReplicaSet knative-operator-79bf74d66d 758:	Created pod: knative-operator-79bf74d66d-xt2vh
17:14:28 ReplicaSet knative-operator-79bf74d66d 830:	Deleted pod: knative-operator-79bf74d66d-xt2vh
17:14:13 Deployment knative-operator 757:	Scaled up replica set knative-operator-79bf74d66d to 1
17:14:23 Deployment knative-operator 798:	Scaled up replica set knative-operator-668fb586bb to 1
17:14:28 Deployment knative-operator 812:	Scaled down replica set knative-operator-79bf74d66d to 0
17:20:17 Pod net-kourier-controller-64cb75974d-djtsm 3015:	Successfully assigned knative-serving/net-kourier-controller-64cb75974d-djtsm to acto-cluster-11-worker
17:20:17 Pod net-kourier-controller-64cb75974d-djtsm 3018:	Container image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0" already present on machine
17:20:17 Pod net-kourier-controller-64cb75974d-djtsm 3018:	Created container controller
17:20:18 Pod net-kourier-controller-64cb75974d-djtsm 3018:	Started container controller
17:28:59 Pod net-kourier-controller-64cb75974d-djtsm 3018:	Stopping container controller
17:40:36 Pod net-kourier-controller-64cb75974d-gs5wr 9069:	Successfully assigned knative-serving/net-kourier-controller-64cb75974d-gs5wr to acto-cluster-11-worker2
17:40:36 Pod net-kourier-controller-64cb75974d-gs5wr 9072:	Container image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0" already present on machine
17:40:36 Pod net-kourier-controller-64cb75974d-gs5wr 9072:	Created container controller
17:40:37 Pod net-kourier-controller-64cb75974d-gs5wr 9072:	Started container controller
17:30:31 Pod net-kourier-controller-64cb75974d-jxjln 5416:	Successfully assigned knative-serving/net-kourier-controller-64cb75974d-jxjln to acto-cluster-11-worker2
17:30:32 Pod net-kourier-controller-64cb75974d-jxjln 5419:	Pulling image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0"
17:30:35 Pod net-kourier-controller-64cb75974d-jxjln 5419:	Successfully pulled image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0" in 2.734518691s
17:30:35 Pod net-kourier-controller-64cb75974d-jxjln 5419:	Created container controller
17:30:35 Pod net-kourier-controller-64cb75974d-jxjln 5419:	Started container controller
17:34:30 Pod net-kourier-controller-64cb75974d-jxjln 5419:	Stopping container controller
17:14:44 Pod net-kourier-controller-64cb75974d-qwrd9 1144:	Successfully assigned knative-serving/net-kourier-controller-64cb75974d-qwrd9 to acto-cluster-11-worker
17:14:44 Pod net-kourier-controller-64cb75974d-qwrd9 1146:	Pulling image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0"
17:14:51 Pod net-kourier-controller-64cb75974d-qwrd9 1146:	Successfully pulled image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0" in 6.211859085s
17:14:51 Pod net-kourier-controller-64cb75974d-qwrd9 1146:	Created container controller
17:14:51 Pod net-kourier-controller-64cb75974d-qwrd9 1146:	Started container controller
17:18:44 Pod net-kourier-controller-64cb75974d-qwrd9 1146:	Stopping container controller
17:18:44 Pod net-kourier-controller-64cb75974d-qwrd9 1146:	Readiness probe failed: 
17:34:54 Pod net-kourier-controller-64cb75974d-zl62l 7124:	Successfully assigned knative-serving/net-kourier-controller-64cb75974d-zl62l to acto-cluster-11-worker2
17:34:55 Pod net-kourier-controller-64cb75974d-zl62l 7127:	Container image "gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier:v1.6.0" already present on machine
17:34:55 Pod net-kourier-controller-64cb75974d-zl62l 7127:	Created container controller
17:34:55 Pod net-kourier-controller-64cb75974d-zl62l 7127:	Started container controller
17:38:53 Pod net-kourier-controller-64cb75974d-zl62l 7127:	Stopping container controller
17:14:44 ReplicaSet net-kourier-controller-64cb75974d 1141:	Created pod: net-kourier-controller-64cb75974d-qwrd9
17:20:17 ReplicaSet net-kourier-controller-64cb75974d 3013:	Created pod: net-kourier-controller-64cb75974d-djtsm
17:30:31 ReplicaSet net-kourier-controller-64cb75974d 5414:	Created pod: net-kourier-controller-64cb75974d-jxjln
17:34:54 ReplicaSet net-kourier-controller-64cb75974d 7122:	Created pod: net-kourier-controller-64cb75974d-zl62l
17:40:36 ReplicaSet net-kourier-controller-64cb75974d 9066:	Created pod: net-kourier-controller-64cb75974d-gs5wr
17:14:44 Deployment net-kourier-controller 1140:	Scaled up replica set net-kourier-controller-64cb75974d to 1
17:20:17 Deployment net-kourier-controller 3012:	Scaled up replica set net-kourier-controller-64cb75974d to 1
17:30:31 Deployment net-kourier-controller 5413:	Scaled up replica set net-kourier-controller-64cb75974d to 1
17:34:54 Deployment net-kourier-controller 7121:	Scaled up replica set net-kourier-controller-64cb75974d to 1
17:40:36 Deployment net-kourier-controller 9065:	Scaled up replica set net-kourier-controller-64cb75974d to 1
17:20:16 Pod storage-version-migration-serving-serving-1.6.0--1-cbzxj 2975:	Successfully assigned knative-serving/storage-version-migration-serving-serving-1.6.0--1-cbzxj to acto-cluster-11-worker
17:20:16 Pod storage-version-migration-serving-serving-1.6.0--1-cbzxj 2977:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest"
17:20:28 Pod storage-version-migration-serving-serving-1.6.0--1-cbzxj 2977:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest" in 11.986371429s
17:20:28 Pod storage-version-migration-serving-serving-1.6.0--1-cbzxj 2977:	Created container migrate
17:20:29 Pod storage-version-migration-serving-serving-1.6.0--1-cbzxj 2977:	Started container migrate
17:40:35 Pod storage-version-migration-serving-serving-1.6.0--1-fjsqh 9026:	Successfully assigned knative-serving/storage-version-migration-serving-serving-1.6.0--1-fjsqh to acto-cluster-11-worker2
17:40:35 Pod storage-version-migration-serving-serving-1.6.0--1-fjsqh 9027:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest"
17:40:36 Pod storage-version-migration-serving-serving-1.6.0--1-fjsqh 9027:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest" in 378.335608ms
17:40:36 Pod storage-version-migration-serving-serving-1.6.0--1-fjsqh 9027:	Created container migrate
17:40:36 Pod storage-version-migration-serving-serving-1.6.0--1-fjsqh 9027:	Started container migrate
17:30:30 Pod storage-version-migration-serving-serving-1.6.0--1-hhkgh 5393:	Successfully assigned knative-serving/storage-version-migration-serving-serving-1.6.0--1-hhkgh to acto-cluster-11-worker
17:30:31 Pod storage-version-migration-serving-serving-1.6.0--1-hhkgh 5396:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest"
17:30:33 Pod storage-version-migration-serving-serving-1.6.0--1-hhkgh 5396:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest" in 1.795956226s
17:30:33 Pod storage-version-migration-serving-serving-1.6.0--1-hhkgh 5396:	Created container migrate
17:30:33 Pod storage-version-migration-serving-serving-1.6.0--1-hhkgh 5396:	Started container migrate
17:34:53 Pod storage-version-migration-serving-serving-1.6.0--1-j8nkv 7103:	Successfully assigned knative-serving/storage-version-migration-serving-serving-1.6.0--1-j8nkv to acto-cluster-11-worker
17:34:54 Pod storage-version-migration-serving-serving-1.6.0--1-j8nkv 7105:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest"
17:34:57 Pod storage-version-migration-serving-serving-1.6.0--1-j8nkv 7105:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest" in 3.160134905s
17:34:57 Pod storage-version-migration-serving-serving-1.6.0--1-j8nkv 7105:	Created container migrate
17:34:57 Pod storage-version-migration-serving-serving-1.6.0--1-j8nkv 7105:	Started container migrate
17:14:43 Pod storage-version-migration-serving-serving-1.6.0--1-m4qtw 1115:	Successfully assigned knative-serving/storage-version-migration-serving-serving-1.6.0--1-m4qtw to acto-cluster-11-worker2
17:14:43 Pod storage-version-migration-serving-serving-1.6.0--1-m4qtw 1117:	Pulling image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest"
17:14:52 Pod storage-version-migration-serving-serving-1.6.0--1-m4qtw 1117:	Successfully pulled image "gcr.io/knative-releases/knative.dev/pkg/apiextensions/storageversion/cmd/migrate:latest" in 8.75680212s
17:14:52 Pod storage-version-migration-serving-serving-1.6.0--1-m4qtw 1117:	Created container migrate
17:14:52 Pod storage-version-migration-serving-serving-1.6.0--1-m4qtw 1117:	Started container migrate
17:14:43 Job storage-version-migration-serving-serving-1.6.0 1113:	Created pod: storage-version-migration-serving-serving-1.6.0--1-m4qtw
17:14:55 Job storage-version-migration-serving-serving-1.6.0 1118:	Job completed
17:20:16 Job storage-version-migration-serving-serving-1.6.0 2974:	Created pod: storage-version-migration-serving-serving-1.6.0--1-cbzxj
17:20:31 Job storage-version-migration-serving-serving-1.6.0 2979:	Job completed
17:30:30 Job storage-version-migration-serving-serving-1.6.0 5392:	Created pod: storage-version-migration-serving-serving-1.6.0--1-hhkgh
17:30:36 Job storage-version-migration-serving-serving-1.6.0 5398:	Job completed
17:34:53 Job storage-version-migration-serving-serving-1.6.0 7102:	Created pod: storage-version-migration-serving-serving-1.6.0--1-j8nkv
17:35:00 Job storage-version-migration-serving-serving-1.6.0 7106:	Job completed
17:40:35 Job storage-version-migration-serving-serving-1.6.0 9025:	Created pod: storage-version-migration-serving-serving-1.6.0--1-fjsqh
17:40:39 Job storage-version-migration-serving-serving-1.6.0 9034:	Job completed
17:14:30 KnativeServing test-cluster 852:	Updated "test-cluster" finalizers
17:20:05 KnativeServing test-cluster 2753:	Updated "test-cluster" finalizers
17:30:20 KnativeServing test-cluster 5146:	Updated "test-cluster" finalizers
17:34:41 KnativeServing test-cluster 6841:	Updated "test-cluster" finalizers
17:40:24 KnativeServing test-cluster 8748:	Updated "test-cluster" finalizers
17:20:15 Pod webhook-669dbd554c-7bd7x 2926:	Successfully assigned knative-serving/webhook-669dbd554c-7bd7x to acto-cluster-11-worker2
17:20:15 Pod webhook-669dbd554c-7bd7x 2928:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0" already present on machine
17:20:15 Pod webhook-669dbd554c-7bd7x 2928:	Created container webhook
17:20:16 Pod webhook-669dbd554c-7bd7x 2928:	Started container webhook
17:20:16 Pod webhook-669dbd554c-7bd7x 2928:	Readiness probe failed: Get "https://10.244.1.7:8443/": dial tcp 10.244.1.7:8443: connect: connection refused
17:29:00 Pod webhook-669dbd554c-7bd7x 2928:	Readiness probe failed: Get "https://10.244.1.7:8443/": remote error: tls: unrecognized name
17:29:00 Pod webhook-669dbd554c-7bd7x 2928:	Liveness probe failed: Get "https://10.244.1.7:8443/": remote error: tls: unrecognized name
17:29:01 Pod webhook-669dbd554c-7bd7x 2928:	Stopping container webhook
17:40:34 Pod webhook-669dbd554c-lz9kl 8958:	Successfully assigned knative-serving/webhook-669dbd554c-lz9kl to acto-cluster-11-worker3
17:40:34 Pod webhook-669dbd554c-lz9kl 8963:	Container image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0" already present on machine
17:40:34 Pod webhook-669dbd554c-lz9kl 8963:	Created container webhook
17:40:34 Pod webhook-669dbd554c-lz9kl 8963:	Started container webhook
17:40:35 Pod webhook-669dbd554c-lz9kl 8963:	Readiness probe failed: Get "https://10.244.2.16:8443/": remote error: tls: unrecognized name
17:34:52 Pod webhook-669dbd554c-mnbs2 7033:	Successfully assigned knative-serving/webhook-669dbd554c-mnbs2 to acto-cluster-11-worker3
17:34:52 Pod webhook-669dbd554c-mnbs2 7036:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0"
17:34:57 Pod webhook-669dbd554c-mnbs2 7036:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0" in 4.383429289s
17:34:57 Pod webhook-669dbd554c-mnbs2 7036:	Created container webhook
17:34:57 Pod webhook-669dbd554c-mnbs2 7036:	Started container webhook
17:38:54 Pod webhook-669dbd554c-mnbs2 7036:	Liveness probe failed: Get "https://10.244.2.13:8443/": remote error: tls: unrecognized name
17:38:54 Pod webhook-669dbd554c-mnbs2 7036:	Readiness probe failed: Get "https://10.244.2.13:8443/": remote error: tls: unrecognized name
17:38:55 Pod webhook-669dbd554c-mnbs2 7036:	Stopping container webhook
17:14:41 Pod webhook-669dbd554c-qdwcv 1077:	Successfully assigned knative-serving/webhook-669dbd554c-qdwcv to acto-cluster-11-worker2
17:14:42 Pod webhook-669dbd554c-qdwcv 1081:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0"
17:14:48 Pod webhook-669dbd554c-qdwcv 1081:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0" in 5.645049621s
17:14:48 Pod webhook-669dbd554c-qdwcv 1081:	Created container webhook
17:14:48 Pod webhook-669dbd554c-qdwcv 1081:	Started container webhook
17:18:44 Pod webhook-669dbd554c-qdwcv 1081:	Liveness probe failed: Get "https://10.244.1.4:8443/": remote error: tls: unrecognized name
17:18:44 Pod webhook-669dbd554c-qdwcv 1081:	Readiness probe failed: Get "https://10.244.1.4:8443/": remote error: tls: unrecognized name
17:18:46 Pod webhook-669dbd554c-qdwcv 1081:	Stopping container webhook
17:30:29 Pod webhook-669dbd554c-vfrwr 5333:	Successfully assigned knative-serving/webhook-669dbd554c-vfrwr to acto-cluster-11-worker
17:30:30 Pod webhook-669dbd554c-vfrwr 5337:	Pulling image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0"
17:30:32 Pod webhook-669dbd554c-vfrwr 5337:	Successfully pulled image "gcr.io/knative-releases/knative.dev/serving/cmd/webhook:v1.6.0" in 2.633386382s
17:30:32 Pod webhook-669dbd554c-vfrwr 5337:	Created container webhook
17:30:33 Pod webhook-669dbd554c-vfrwr 5337:	Started container webhook
17:30:33 Pod webhook-669dbd554c-vfrwr 5337:	Readiness probe failed: Get "https://10.244.3.12:8443/": dial tcp 10.244.3.12:8443: connect: connection refused
17:34:31 Pod webhook-669dbd554c-vfrwr 5337:	Readiness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
17:34:31 Pod webhook-669dbd554c-vfrwr 5337:	Liveness probe failed: Get "https://10.244.3.12:8443/": remote error: tls: unrecognized name
17:34:32 Pod webhook-669dbd554c-vfrwr 5337:	Stopping container webhook
17:14:41 ReplicaSet webhook-669dbd554c 1075:	Created pod: webhook-669dbd554c-qdwcv
17:20:15 ReplicaSet webhook-669dbd554c 2924:	Created pod: webhook-669dbd554c-7bd7x
17:30:29 ReplicaSet webhook-669dbd554c 5331:	Created pod: webhook-669dbd554c-vfrwr
17:34:52 ReplicaSet webhook-669dbd554c 7031:	Created pod: webhook-669dbd554c-mnbs2
17:40:33 ReplicaSet webhook-669dbd554c 8956:	Created pod: webhook-669dbd554c-lz9kl
17:14:41 PodDisruptionBudget webhook-pdb 1066:	No matching pods found
17:18:46 PodDisruptionBudget webhook-pdb 1418:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:20:14 PodDisruptionBudget webhook-pdb 2916:	No matching pods found
17:29:01 PodDisruptionBudget webhook-pdb 3226:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:30:29 PodDisruptionBudget webhook-pdb 5323:	No matching pods found
17:34:32 PodDisruptionBudget webhook-pdb 5660:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:34:52 PodDisruptionBudget webhook-pdb 7021:	Failed to calculate the number of expected pods: replicasets.apps does not implement the scale subresource
17:34:52 PodDisruptionBudget webhook-pdb 7024:	Failed to calculate the number of expected pods: found no controllers for pod "webhook-669dbd554c-vfrwr"
17:40:33 PodDisruptionBudget webhook-pdb 8933:	No matching pods found
17:14:41 Deployment webhook 1074:	Scaled up replica set webhook-669dbd554c to 1
17:14:56 HorizontalPodAutoscaler webhook 1064:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:14:56 HorizontalPodAutoscaler webhook 1064:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:20:15 Deployment webhook 2923:	Scaled up replica set webhook-669dbd554c to 1
17:20:29 HorizontalPodAutoscaler webhook 2914:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:20:29 HorizontalPodAutoscaler webhook 2914:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:30:29 Deployment webhook 5330:	Scaled up replica set webhook-669dbd554c to 1
17:30:44 HorizontalPodAutoscaler webhook 5312:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:30:44 HorizontalPodAutoscaler webhook 5312:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:34:52 Deployment webhook 7030:	Scaled up replica set webhook-669dbd554c to 1
17:35:06 HorizontalPodAutoscaler webhook 7020:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:35:06 HorizontalPodAutoscaler webhook 7020:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:40:33 Deployment webhook 8955:	Scaled up replica set webhook-669dbd554c to 1
17:40:48 HorizontalPodAutoscaler webhook 8919:	failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
17:40:48 HorizontalPodAutoscaler webhook 8919:	invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
