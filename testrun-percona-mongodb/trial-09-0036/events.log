23:33:53 ConfigMap 08db0feb.percona.com 842:	percona-server-mongodb-operator-67d4f7db5f-6w5l8_191ad198-a43a-4c11-b181-279eeaeddc16 became leader
23:33:53 Lease 08db0feb.percona.com 843:	percona-server-mongodb-operator-67d4f7db5f-6w5l8_191ad198-a43a-4c11-b181-279eeaeddc16 became leader
23:34:21 ConfigMap 08db0feb.percona.com 931:	percona-server-mongodb-operator-fb6cf9f7c-b68vs_30a57a22-7447-4f10-9648-963784c5ac50 became leader
23:34:21 Lease 08db0feb.percona.com 932:	percona-server-mongodb-operator-fb6cf9f7c-b68vs_30a57a22-7447-4f10-9648-963784c5ac50 became leader
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-cfg-0 949:	waiting for first consumer to be created before binding
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-cfg-0 956:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-cfg-0 956:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-cfg-0"
23:34:34 PersistentVolumeClaim mongod-data-test-cluster-cfg-0 956:	Successfully provisioned volume pvc-9a6fd9bd-2aa7-448a-9827-7080c33002ad
23:34:47 PersistentVolumeClaim mongod-data-test-cluster-cfg-1 1227:	waiting for first consumer to be created before binding
23:34:47 PersistentVolumeClaim mongod-data-test-cluster-cfg-1 1234:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:34:47 PersistentVolumeClaim mongod-data-test-cluster-cfg-1 1234:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-cfg-1"
23:34:51 PersistentVolumeClaim mongod-data-test-cluster-cfg-1 1234:	Successfully provisioned volume pvc-16dbf74b-5ae6-4368-9dc7-8272dd008922
23:35:04 PersistentVolumeClaim mongod-data-test-cluster-cfg-2 1435:	waiting for first consumer to be created before binding
23:35:04 PersistentVolumeClaim mongod-data-test-cluster-cfg-2 1442:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:35:04 PersistentVolumeClaim mongod-data-test-cluster-cfg-2 1442:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-cfg-2"
23:35:08 PersistentVolumeClaim mongod-data-test-cluster-cfg-2 1442:	Successfully provisioned volume pvc-680c84cf-dc8d-4ecb-a5eb-bca79483f06f
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-rs0-0 975:	waiting for first consumer to be created before binding
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-rs0-0 989:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-rs0-0 989:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-rs0-0"
23:34:34 PersistentVolumeClaim mongod-data-test-cluster-rs0-0 989:	Successfully provisioned volume pvc-af68ec01-d8e9-4ae7-a276-ef2be1a9aabf
23:34:50 PersistentVolumeClaim mongod-data-test-cluster-rs0-1 1291:	waiting for first consumer to be created before binding
23:34:50 PersistentVolumeClaim mongod-data-test-cluster-rs0-1 1298:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:34:50 PersistentVolumeClaim mongod-data-test-cluster-rs0-1 1298:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-rs0-1"
23:34:54 PersistentVolumeClaim mongod-data-test-cluster-rs0-1 1298:	Successfully provisioned volume pvc-c73c0e92-0863-43d2-8169-f6ea8e76965f
23:35:10 PersistentVolumeClaim mongod-data-test-cluster-rs0-2 1507:	waiting for first consumer to be created before binding
23:35:10 PersistentVolumeClaim mongod-data-test-cluster-rs0-2 1514:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:35:10 PersistentVolumeClaim mongod-data-test-cluster-rs0-2 1514:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-rs0-2"
23:35:15 PersistentVolumeClaim mongod-data-test-cluster-rs0-2 1514:	Successfully provisioned volume pvc-1a105e08-10e0-450d-8caa-52c51594ea6a
23:35:31 PersistentVolumeClaim mongod-data-test-cluster-rs0-3 1663:	waiting for first consumer to be created before binding
23:35:31 PersistentVolumeClaim mongod-data-test-cluster-rs0-3 1670:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:35:31 PersistentVolumeClaim mongod-data-test-cluster-rs0-3 1670:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-rs0-3"
23:35:35 PersistentVolumeClaim mongod-data-test-cluster-rs0-3 1670:	Successfully provisioned volume pvc-6da48eeb-2789-47e5-b5e1-7c1c9152e9ec
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-0 1006:	waiting for first consumer to be created before binding
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-0 1017:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:34:24 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-0 1017:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-rs0-nv-0"
23:34:34 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-0 1017:	Successfully provisioned volume pvc-7e961f23-7176-44df-a6c2-b20dddd7a4f4
23:34:49 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-1 1258:	waiting for first consumer to be created before binding
23:34:49 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-1 1265:	waiting for a volume to be created, either by external provisioner "rancher.io/local-path" or manually created by system administrator
23:34:49 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-1 1265:	External provisioner is provisioning volume for claim "acto-namespace/mongod-data-test-cluster-rs0-nv-1"
23:34:53 PersistentVolumeClaim mongod-data-test-cluster-rs0-nv-1 1265:	Successfully provisioned volume pvc-3302c278-837b-4ea5-b2fe-3af74538dd41
23:33:50 Pod percona-server-mongodb-operator-67d4f7db5f-6w5l8 819:	Successfully assigned acto-namespace/percona-server-mongodb-operator-67d4f7db5f-6w5l8 to acto-cluster-9-worker2
23:33:51 Pod percona-server-mongodb-operator-67d4f7db5f-6w5l8 821:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:33:51 Pod percona-server-mongodb-operator-67d4f7db5f-6w5l8 821:	Created container percona-server-mongodb-operator
23:33:51 Pod percona-server-mongodb-operator-67d4f7db5f-6w5l8 821:	Started container percona-server-mongodb-operator
23:34:01 Pod percona-server-mongodb-operator-67d4f7db5f-6w5l8 821:	Stopping container percona-server-mongodb-operator
23:33:50 ReplicaSet percona-server-mongodb-operator-67d4f7db5f 814:	Created pod: percona-server-mongodb-operator-67d4f7db5f-6w5l8
23:34:01 ReplicaSet percona-server-mongodb-operator-67d4f7db5f 886:	Deleted pod: percona-server-mongodb-operator-67d4f7db5f-6w5l8
23:34:00 Pod percona-server-mongodb-operator-fb6cf9f7c-b68vs 872:	Successfully assigned acto-namespace/percona-server-mongodb-operator-fb6cf9f7c-b68vs to acto-cluster-9-worker2
23:34:01 Pod percona-server-mongodb-operator-fb6cf9f7c-b68vs 874:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:01 Pod percona-server-mongodb-operator-fb6cf9f7c-b68vs 874:	Created container percona-server-mongodb-operator
23:34:01 Pod percona-server-mongodb-operator-fb6cf9f7c-b68vs 874:	Started container percona-server-mongodb-operator
23:34:00 ReplicaSet percona-server-mongodb-operator-fb6cf9f7c 869:	Created pod: percona-server-mongodb-operator-fb6cf9f7c-b68vs
23:33:50 Deployment percona-server-mongodb-operator 812:	Scaled up replica set percona-server-mongodb-operator-67d4f7db5f to 1
23:34:00 Deployment percona-server-mongodb-operator 868:	Scaled up replica set percona-server-mongodb-operator-fb6cf9f7c to 1
23:34:01 Deployment percona-server-mongodb-operator 879:	Scaled down replica set percona-server-mongodb-operator-67d4f7db5f to 0
23:34:24 PodDisruptionBudget test-cluster-arbiter-rs0 974:	No matching pods found
23:34:35 Pod test-cluster-cfg-0 951:	Successfully assigned acto-namespace/test-cluster-cfg-0 to acto-cluster-9-worker4
23:34:35 Pod test-cluster-cfg-0 1129:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:36 Pod test-cluster-cfg-0 1129:	Created container mongo-init
23:34:36 Pod test-cluster-cfg-0 1129:	Started container mongo-init
23:34:36 Pod test-cluster-cfg-0 1129:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:36 Pod test-cluster-cfg-0 1129:	Created container mongod
23:34:37 Pod test-cluster-cfg-0 1129:	Started container mongod
23:34:37 Pod test-cluster-cfg-0 1129:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:34:42 Pod test-cluster-cfg-0 1129:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 5.282426485s
23:34:42 Pod test-cluster-cfg-0 1129:	Created container backup-agent
23:34:42 Pod test-cluster-cfg-0 1129:	Started container backup-agent
23:34:52 Pod test-cluster-cfg-1 1230:	Successfully assigned acto-namespace/test-cluster-cfg-1 to acto-cluster-9-worker
23:34:52 Pod test-cluster-cfg-1 1320:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:52 Pod test-cluster-cfg-1 1320:	Created container mongo-init
23:34:53 Pod test-cluster-cfg-1 1320:	Started container mongo-init
23:34:53 Pod test-cluster-cfg-1 1320:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:53 Pod test-cluster-cfg-1 1320:	Created container mongod
23:34:54 Pod test-cluster-cfg-1 1320:	Started container mongod
23:34:54 Pod test-cluster-cfg-1 1320:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:34:58 Pod test-cluster-cfg-1 1320:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 4.524446575s
23:34:58 Pod test-cluster-cfg-1 1320:	Created container backup-agent
23:34:58 Pod test-cluster-cfg-1 1320:	Started container backup-agent
23:35:09 Pod test-cluster-cfg-2 1438:	Successfully assigned acto-namespace/test-cluster-cfg-2 to acto-cluster-9-worker3
23:35:09 Pod test-cluster-cfg-2 1492:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:35:09 Pod test-cluster-cfg-2 1492:	Created container mongo-init
23:35:10 Pod test-cluster-cfg-2 1492:	Started container mongo-init
23:35:10 Pod test-cluster-cfg-2 1492:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:35:10 Pod test-cluster-cfg-2 1492:	Created container mongod
23:35:11 Pod test-cluster-cfg-2 1492:	Started container mongod
23:35:11 Pod test-cluster-cfg-2 1492:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:35:11 Pod test-cluster-cfg-2 1492:	Created container backup-agent
23:35:11 Pod test-cluster-cfg-2 1492:	Started container backup-agent
23:34:24 StatefulSet test-cluster-cfg 947:	create Claim mongod-data-test-cluster-cfg-0 Pod test-cluster-cfg-0 in StatefulSet test-cluster-cfg success
23:34:24 StatefulSet test-cluster-cfg 947:	create Pod test-cluster-cfg-0 in StatefulSet test-cluster-cfg successful
23:34:47 StatefulSet test-cluster-cfg 954:	create Claim mongod-data-test-cluster-cfg-1 Pod test-cluster-cfg-1 in StatefulSet test-cluster-cfg success
23:34:47 StatefulSet test-cluster-cfg 954:	create Pod test-cluster-cfg-1 in StatefulSet test-cluster-cfg successful
23:35:04 StatefulSet test-cluster-cfg 1233:	create Claim mongod-data-test-cluster-cfg-2 Pod test-cluster-cfg-2 in StatefulSet test-cluster-cfg success
23:35:04 StatefulSet test-cluster-cfg 1233:	create Pod test-cluster-cfg-2 in StatefulSet test-cluster-cfg successful
23:34:24 PodDisruptionBudget test-cluster-mongod-rs0 968:	No matching pods found
23:35:22 PodDisruptionBudget test-cluster-mongos- 1598:	No matching pods found
23:35:22 Pod test-cluster-mongos-0 1607:	Successfully assigned acto-namespace/test-cluster-mongos-0 to acto-cluster-9-worker4
23:35:22 Pod test-cluster-mongos-0 1611:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:35:22 Pod test-cluster-mongos-0 1611:	Created container mongo-init
23:35:23 Pod test-cluster-mongos-0 1611:	Started container mongo-init
23:35:24 Pod test-cluster-mongos-0 1611:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:35:24 Pod test-cluster-mongos-0 1611:	Created container mongos
23:35:25 Pod test-cluster-mongos-0 1611:	Started container mongos
23:35:35 Pod test-cluster-mongos-1 1699:	Successfully assigned acto-namespace/test-cluster-mongos-1 to acto-cluster-9-worker
23:35:36 Pod test-cluster-mongos-1 1701:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:35:36 Pod test-cluster-mongos-1 1701:	Created container mongo-init
23:35:36 Pod test-cluster-mongos-1 1701:	Started container mongo-init
23:35:37 Pod test-cluster-mongos-1 1701:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:35:37 Pod test-cluster-mongos-1 1701:	Created container mongos
23:35:37 Pod test-cluster-mongos-1 1701:	Started container mongos
23:35:22 StatefulSet test-cluster-mongos 1596:	create Pod test-cluster-mongos-0 in StatefulSet test-cluster-mongos successful
23:35:35 StatefulSet test-cluster-mongos 1613:	create Pod test-cluster-mongos-1 in StatefulSet test-cluster-mongos successful
23:34:24 PodDisruptionBudget test-cluster-nonVoting-rs0 988:	No matching pods found
23:34:35 Pod test-cluster-rs0-0 981:	Successfully assigned acto-namespace/test-cluster-rs0-0 to acto-cluster-9-worker3
23:34:36 Pod test-cluster-rs0-0 1135:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:36 Pod test-cluster-rs0-0 1135:	Created container mongo-init
23:34:36 Pod test-cluster-rs0-0 1135:	Started container mongo-init
23:34:37 Pod test-cluster-rs0-0 1135:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:37 Pod test-cluster-rs0-0 1135:	Created container mongod
23:34:38 Pod test-cluster-rs0-0 1135:	Started container mongod
23:34:38 Pod test-cluster-rs0-0 1135:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:34:42 Pod test-cluster-rs0-0 1135:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 4.650751554s
23:34:42 Pod test-cluster-rs0-0 1135:	Created container backup-agent
23:34:43 Pod test-cluster-rs0-0 1135:	Started container backup-agent
23:36:15 Pod test-cluster-rs0-0 1135:	Liveness probe failed: 
23:37:45 Pod test-cluster-rs0-0 1135:	Container mongod failed liveness probe, will be restarted
23:34:55 Pod test-cluster-rs0-1 1294:	Successfully assigned acto-namespace/test-cluster-rs0-1 to acto-cluster-9-worker
23:34:56 Pod test-cluster-rs0-1 1369:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:56 Pod test-cluster-rs0-1 1369:	Created container mongo-init
23:34:56 Pod test-cluster-rs0-1 1369:	Started container mongo-init
23:34:57 Pod test-cluster-rs0-1 1369:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:57 Pod test-cluster-rs0-1 1369:	Created container mongod
23:34:58 Pod test-cluster-rs0-1 1369:	Started container mongod
23:34:58 Pod test-cluster-rs0-1 1369:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:34:59 Pod test-cluster-rs0-1 1369:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 826.583306ms
23:34:59 Pod test-cluster-rs0-1 1369:	Created container backup-agent
23:34:59 Pod test-cluster-rs0-1 1369:	Started container backup-agent
23:35:16 Pod test-cluster-rs0-2 1510:	Successfully assigned acto-namespace/test-cluster-rs0-2 to acto-cluster-9-worker2
23:35:17 Pod test-cluster-rs0-2 1557:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:35:17 Pod test-cluster-rs0-2 1557:	Created container mongo-init
23:35:17 Pod test-cluster-rs0-2 1557:	Started container mongo-init
23:35:18 Pod test-cluster-rs0-2 1557:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:35:18 Pod test-cluster-rs0-2 1557:	Created container mongod
23:35:19 Pod test-cluster-rs0-2 1557:	Started container mongod
23:35:19 Pod test-cluster-rs0-2 1557:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:35:23 Pod test-cluster-rs0-2 1557:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 4.230848554s
23:35:23 Pod test-cluster-rs0-2 1557:	Created container backup-agent
23:35:23 Pod test-cluster-rs0-2 1557:	Started container backup-agent
23:36:56 Pod test-cluster-rs0-2 1557:	Liveness probe failed: 
23:35:36 Pod test-cluster-rs0-3 1666:	Successfully assigned acto-namespace/test-cluster-rs0-3 to acto-cluster-9-worker4
23:35:37 Pod test-cluster-rs0-3 1715:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:35:37 Pod test-cluster-rs0-3 1715:	Created container mongo-init
23:35:37 Pod test-cluster-rs0-3 1715:	Started container mongo-init
23:35:37 Pod test-cluster-rs0-3 1715:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:35:37 Pod test-cluster-rs0-3 1715:	Created container mongod
23:35:38 Pod test-cluster-rs0-3 1715:	Started container mongod
23:35:38 Pod test-cluster-rs0-3 1715:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:35:38 Pod test-cluster-rs0-3 1715:	Created container backup-agent
23:35:38 Pod test-cluster-rs0-3 1715:	Started container backup-agent
23:37:16 Pod test-cluster-rs0-3 1715:	Liveness probe failed: 
23:34:24 Pod test-cluster-rs0-arbiter-0 987:	Successfully assigned acto-namespace/test-cluster-rs0-arbiter-0 to acto-cluster-9-worker
23:34:26 Pod test-cluster-rs0-arbiter-0 993:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:26 Pod test-cluster-rs0-arbiter-0 993:	Created container mongo-init
23:34:28 Pod test-cluster-rs0-arbiter-0 993:	Started container mongo-init
23:34:29 Pod test-cluster-rs0-arbiter-0 993:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:29 Pod test-cluster-rs0-arbiter-0 993:	Created container mongod-arbiter
23:34:33 Pod test-cluster-rs0-arbiter-0 993:	Started container mongod-arbiter
23:36:05 Pod test-cluster-rs0-arbiter-0 993:	Liveness probe failed: 
23:37:34 Pod test-cluster-rs0-arbiter-0 993:	Container mongod-arbiter failed liveness probe, will be restarted
23:34:24 StatefulSet test-cluster-rs0-arbiter 973:	create Pod test-cluster-rs0-arbiter-0 in StatefulSet test-cluster-rs0-arbiter successful
23:34:34 Pod test-cluster-rs0-nv-0 1010:	Successfully assigned acto-namespace/test-cluster-rs0-nv-0 to acto-cluster-9-worker3
23:34:35 Pod test-cluster-rs0-nv-0 1117:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:35 Pod test-cluster-rs0-nv-0 1117:	Created container mongo-init
23:34:35 Pod test-cluster-rs0-nv-0 1117:	Started container mongo-init
23:34:36 Pod test-cluster-rs0-nv-0 1117:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:36 Pod test-cluster-rs0-nv-0 1117:	Created container mongod-nv
23:34:37 Pod test-cluster-rs0-nv-0 1117:	Started container mongod-nv
23:34:37 Pod test-cluster-rs0-nv-0 1117:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:34:42 Pod test-cluster-rs0-nv-0 1117:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 5.234367368s
23:34:42 Pod test-cluster-rs0-nv-0 1117:	Created container backup-agent
23:34:42 Pod test-cluster-rs0-nv-0 1117:	Started container backup-agent
23:36:15 Pod test-cluster-rs0-nv-0 1117:	Liveness probe failed: 
23:37:44 Pod test-cluster-rs0-nv-0 1117:	Container mongod-nv failed liveness probe, will be restarted
23:39:32 Pod test-cluster-rs0-nv-0 1117:	Stopping container backup-agent
23:39:32 Pod test-cluster-rs0-nv-0 1117:	Stopping container mongod-nv
23:39:33 Pod test-cluster-rs0-nv-0 2522:	Successfully assigned acto-namespace/test-cluster-rs0-nv-0 to acto-cluster-9-worker3
23:39:34 Pod test-cluster-rs0-nv-0 2524:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:39:34 Pod test-cluster-rs0-nv-0 2524:	Created container mongo-init
23:39:34 Pod test-cluster-rs0-nv-0 2524:	Started container mongo-init
23:39:35 Pod test-cluster-rs0-nv-0 2524:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:39:35 Pod test-cluster-rs0-nv-0 2524:	Created container mongod-nv
23:39:35 Pod test-cluster-rs0-nv-0 2524:	Started container mongod-nv
23:39:35 Pod test-cluster-rs0-nv-0 2524:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:39:35 Pod test-cluster-rs0-nv-0 2524:	Created container backup-agent
23:39:36 Pod test-cluster-rs0-nv-0 2524:	Started container backup-agent
23:41:12 Pod test-cluster-rs0-nv-0 2524:	Stopping container mongod-nv
23:41:12 Pod test-cluster-rs0-nv-0 2524:	Stopping container backup-agent
23:41:13 Pod test-cluster-rs0-nv-0 2894:	Successfully assigned acto-namespace/test-cluster-rs0-nv-0 to acto-cluster-9-worker3
23:41:14 Pod test-cluster-rs0-nv-0 2895:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:41:14 Pod test-cluster-rs0-nv-0 2895:	Created container mongo-init
23:41:15 Pod test-cluster-rs0-nv-0 2895:	Started container mongo-init
23:41:15 Pod test-cluster-rs0-nv-0 2895:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:41:15 Pod test-cluster-rs0-nv-0 2895:	Created container mongod-nv
23:41:16 Pod test-cluster-rs0-nv-0 2895:	Started container mongod-nv
23:41:16 Pod test-cluster-rs0-nv-0 2895:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:41:16 Pod test-cluster-rs0-nv-0 2895:	Created container backup-agent
23:41:16 Pod test-cluster-rs0-nv-0 2895:	Started container backup-agent
23:34:54 Pod test-cluster-rs0-nv-1 1261:	Successfully assigned acto-namespace/test-cluster-rs0-nv-1 to acto-cluster-9-worker
23:34:54 Pod test-cluster-rs0-nv-1 1349:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:34:54 Pod test-cluster-rs0-nv-1 1349:	Created container mongo-init
23:34:55 Pod test-cluster-rs0-nv-1 1349:	Started container mongo-init
23:34:55 Pod test-cluster-rs0-nv-1 1349:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:34:55 Pod test-cluster-rs0-nv-1 1349:	Created container mongod-nv
23:34:56 Pod test-cluster-rs0-nv-1 1349:	Started container mongod-nv
23:34:56 Pod test-cluster-rs0-nv-1 1349:	Pulling image "percona/percona-backup-mongodb:1.7.0"
23:34:58 Pod test-cluster-rs0-nv-1 1349:	Successfully pulled image "percona/percona-backup-mongodb:1.7.0" in 2.507215407s
23:34:58 Pod test-cluster-rs0-nv-1 1349:	Created container backup-agent
23:34:59 Pod test-cluster-rs0-nv-1 1349:	Started container backup-agent
23:36:34 Pod test-cluster-rs0-nv-1 1349:	Liveness probe failed: 
23:39:14 Pod test-cluster-rs0-nv-1 1349:	Stopping container mongod-nv
23:39:14 Pod test-cluster-rs0-nv-1 1349:	Stopping container backup-agent
23:39:16 Pod test-cluster-rs0-nv-1 2431:	Successfully assigned acto-namespace/test-cluster-rs0-nv-1 to acto-cluster-9-worker
23:39:17 Pod test-cluster-rs0-nv-1 2432:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:39:17 Pod test-cluster-rs0-nv-1 2432:	Created container mongo-init
23:39:17 Pod test-cluster-rs0-nv-1 2432:	Started container mongo-init
23:39:18 Pod test-cluster-rs0-nv-1 2432:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:39:18 Pod test-cluster-rs0-nv-1 2432:	Created container mongod-nv
23:39:19 Pod test-cluster-rs0-nv-1 2432:	Started container mongod-nv
23:39:19 Pod test-cluster-rs0-nv-1 2432:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:39:19 Pod test-cluster-rs0-nv-1 2432:	Created container backup-agent
23:39:19 Pod test-cluster-rs0-nv-1 2432:	Started container backup-agent
23:40:54 Pod test-cluster-rs0-nv-1 2432:	Stopping container mongod-nv
23:40:54 Pod test-cluster-rs0-nv-1 2432:	Stopping container backup-agent
23:40:56 Pod test-cluster-rs0-nv-1 2800:	Successfully assigned acto-namespace/test-cluster-rs0-nv-1 to acto-cluster-9-worker
23:40:57 Pod test-cluster-rs0-nv-1 2801:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:40:57 Pod test-cluster-rs0-nv-1 2801:	Created container mongo-init
23:40:58 Pod test-cluster-rs0-nv-1 2801:	Started container mongo-init
23:40:58 Pod test-cluster-rs0-nv-1 2801:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:40:58 Pod test-cluster-rs0-nv-1 2801:	Created container mongod-nv
23:40:59 Pod test-cluster-rs0-nv-1 2801:	Started container mongod-nv
23:40:59 Pod test-cluster-rs0-nv-1 2801:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:40:59 Pod test-cluster-rs0-nv-1 2801:	Created container backup-agent
23:40:59 Pod test-cluster-rs0-nv-1 2801:	Started container backup-agent
23:42:34 Pod test-cluster-rs0-nv-1 2801:	Stopping container mongod-nv
23:42:34 Pod test-cluster-rs0-nv-1 2801:	Stopping container backup-agent
23:42:35 Pod test-cluster-rs0-nv-1 2801:	Readiness probe failed: dial tcp 10.244.2.11:27017: connect: network is unreachable
23:52:27 Pod test-cluster-rs0-nv-1 4720:	Successfully assigned acto-namespace/test-cluster-rs0-nv-1 to acto-cluster-9-worker
23:52:27 Pod test-cluster-rs0-nv-1 4721:	Container image "perconalab/percona-server-mongodb-operator:release-1-12-0" already present on machine
23:52:27 Pod test-cluster-rs0-nv-1 4721:	Created container mongo-init
23:52:28 Pod test-cluster-rs0-nv-1 4721:	Started container mongo-init
23:52:29 Pod test-cluster-rs0-nv-1 4721:	Container image "percona/percona-server-mongodb:4.4.10-11" already present on machine
23:52:29 Pod test-cluster-rs0-nv-1 4721:	Created container mongod-nv
23:52:30 Pod test-cluster-rs0-nv-1 4721:	Started container mongod-nv
23:52:30 Pod test-cluster-rs0-nv-1 4721:	Container image "percona/percona-backup-mongodb:1.7.0" already present on machine
23:52:30 Pod test-cluster-rs0-nv-1 4721:	Created container backup-agent
23:52:30 Pod test-cluster-rs0-nv-1 4721:	Started container backup-agent
23:34:24 StatefulSet test-cluster-rs0-nv 983:	create Claim mongod-data-test-cluster-rs0-nv-0 Pod test-cluster-rs0-nv-0 in StatefulSet test-cluster-rs0-nv success
23:34:24 StatefulSet test-cluster-rs0-nv 983:	create Pod test-cluster-rs0-nv-0 in StatefulSet test-cluster-rs0-nv successful
23:34:49 StatefulSet test-cluster-rs0-nv 1015:	create Claim mongod-data-test-cluster-rs0-nv-1 Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv success
23:34:49 StatefulSet test-cluster-rs0-nv 1015:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv successful
23:42:36 StatefulSet test-cluster-rs0-nv 3110:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc01a7665a0)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00b691890), Privileged:(*bool)(0xc01a17c58e), SELinuxOptions:(*core.SELinuxOptions)(0xc01a1afd00), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc00e2fefc0), RunAsUser:(*int64)(0xc01a17c5a0), RunAsGroup:(*int64)(0xc01a17c5b0), RunAsNonRoot:(*bool)(0xc01a17c5a8), ReadOnlyRootFilesystem:(*bool)(0xc01a17c5a9), AllowPrivilegeEscalation:(*bool)(0xc01a17c5aa), ProcMount:(*core.ProcMountType)(0xc012aa36c0), SeccompProfile:(*core.SeccompProfile)(0xc011d39020)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc019cf6f30)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00a840990), Privileged:(*bool)(0xc01a3ccbce), SELinuxOptions:(*core.SELinuxOptions)(0xc01a223040), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc007122f20), RunAsUser:(*int64)(0xc01a3ccbe0), RunAsGroup:(*int64)(0xc01a3ccbf0), RunAsNonRoot:(*bool)(0xc01a3ccbe8), ReadOnlyRootFilesystem:(*bool)(0xc01a3ccbe9), AllowPrivilegeEscalation:(*bool)(0xc01a3ccbea), ProcMount:(*core.ProcMountType)(0xc01980f780), SeccompProfile:(*core.SeccompProfile)(0xc0161e5de8)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc019ecd050)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00b225710), Privileged:(*bool)(0xc01a73249e), SELinuxOptions:(*core.SELinuxOptions)(0xc00b669c40), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc01a317a40), RunAsUser:(*int64)(0xc01a7324b0), RunAsGroup:(*int64)(0xc01a7324c0), RunAsNonRoot:(*bool)(0xc01a7324b8), ReadOnlyRootFilesystem:(*bool)(0xc01a7324b9), AllowPrivilegeEscalation:(*bool)(0xc01a7324ba), ProcMount:(*core.ProcMountType)(0xc01b3b19b0), SeccompProfile:(*core.SeccompProfile)(0xc01b33d020)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc01bfc9ad0)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00b5e4b10), Privileged:(*bool)(0xc00297662e), SELinuxOptions:(*core.SELinuxOptions)(0xc01bcf3d40), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc006e19920), RunAsUser:(*int64)(0xc0029767a0), RunAsGroup:(*int64)(0xc0029767d0), RunAsNonRoot:(*bool)(0xc0029767a8), ReadOnlyRootFilesystem:(*bool)(0xc0029767a9), AllowPrivilegeEscalation:(*bool)(0xc0029767aa), ProcMount:(*core.ProcMountType)(0xc01cc504f0), SeccompProfile:(*core.SeccompProfile)(0xc014b9e480)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc00fef0d60)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00968f6e0), Privileged:(*bool)(0xc0199021ee), SELinuxOptions:(*core.SELinuxOptions)(0xc00a239300), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc006bcd160), RunAsUser:(*int64)(0xc019902200), RunAsGroup:(*int64)(0xc019902210), RunAsNonRoot:(*bool)(0xc019902208), ReadOnlyRootFilesystem:(*bool)(0xc019902209), AllowPrivilegeEscalation:(*bool)(0xc01990220a), ProcMount:(*core.ProcMountType)(0xc01a3a39a0), SeccompProfile:(*core.SeccompProfile)(0xc0034dac78)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc01c4fac60)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00b091ce0), Privileged:(*bool)(0xc01b36504e), SELinuxOptions:(*core.SELinuxOptions)(0xc01b26e000), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc00d490f60), RunAsUser:(*int64)(0xc01b365060), RunAsGroup:(*int64)(0xc01b365070), RunAsNonRoot:(*bool)(0xc01b365068), ReadOnlyRootFilesystem:(*bool)(0xc01b365069), AllowPrivilegeEscalation:(*bool)(0xc01b36506a), ProcMount:(*core.ProcMountType)(0xc00a60f5c0), SeccompProfile:(*core.SeccompProfile)(0xc01ae80cc0)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc00b19e7f0)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00c6fe7e0), Privileged:(*bool)(0xc01ac757ae), SELinuxOptions:(*core.SELinuxOptions)(0xc01a7e4f40), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc00d3c8f40), RunAsUser:(*int64)(0xc01ac758d0), RunAsGroup:(*int64)(0xc01ac758e0), RunAsNonRoot:(*bool)(0xc01ac758d8), ReadOnlyRootFilesystem:(*bool)(0xc01ac758d9), AllowPrivilegeEscalation:(*bool)(0xc01ac758da), ProcMount:(*core.ProcMountType)(0xc01a553300), SeccompProfile:(*core.SeccompProfile)(0xc01b22e330)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:36 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc018b49c50)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00bde9aa0), Privileged:(*bool)(0xc00828d7be), SELinuxOptions:(*core.SELinuxOptions)(0xc019450940), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc005bfe640), RunAsUser:(*int64)(0xc00828d7d0), RunAsGroup:(*int64)(0xc00828d7e0), RunAsNonRoot:(*bool)(0xc00828d7d8), ReadOnlyRootFilesystem:(*bool)(0xc00828d7d9), AllowPrivilegeEscalation:(*bool)(0xc00828d7da), ProcMount:(*core.ProcMountType)(0xc00b584ef0), SeccompProfile:(*core.SeccompProfile)(0xc00d8fc978)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:37 StatefulSet test-cluster-rs0-nv 3162:	create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc006e4a680)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc00d0c9d70), Privileged:(*bool)(0xc01b4912ee), SELinuxOptions:(*core.SELinuxOptions)(0xc01a0c05c0), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc00bf25c60), RunAsUser:(*int64)(0xc01b491300), RunAsGroup:(*int64)(0xc01b491310), RunAsNonRoot:(*bool)(0xc01b491308), ReadOnlyRootFilesystem:(*bool)(0xc01b491309), AllowPrivilegeEscalation:(*bool)(0xc01b49130a), ProcMount:(*core.ProcMountType)(0xc00b25b800), SeccompProfile:(*core.SeccompProfile)(0xc0097c2408)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:42:38 StatefulSet test-cluster-rs0-nv 3162:	(combined from similar events): create Pod test-cluster-rs0-nv-1 in StatefulSet test-cluster-rs0-nv failed error: Pod "test-cluster-rs0-nv-1" is invalid: [spec.containers[0].securityContext.seccompProfile.type: Unsupported value: "ACTOKEY": supported values: "Localhost", "RuntimeDefault", "Unconfined", spec.containers[0].securityContext.seccompProfile.localhostProfile: Invalid value: core.SeccompProfile{Type:"ACTOKEY", LocalhostProfile:(*string)(0xc0068ea080)}: can only be set when seccomp type is Localhost, spec.containers[0].securityContext: Invalid value: core.SecurityContext{Capabilities:(*core.Capabilities)(0xc017f6baa0), Privileged:(*bool)(0xc01cbbec7e), SELinuxOptions:(*core.SELinuxOptions)(0xc00eeffb80), WindowsOptions:(*core.WindowsSecurityContextOptions)(0xc00d389e40), RunAsUser:(*int64)(0xc01cbbec90), RunAsGroup:(*int64)(0xc01cbbeca0), RunAsNonRoot:(*bool)(0xc01cbbec98), ReadOnlyRootFilesystem:(*bool)(0xc01cbbec99), AllowPrivilegeEscalation:(*bool)(0xc01cbbec9a), ProcMount:(*core.ProcMountType)(0xc00a995d80), SeccompProfile:(*core.SeccompProfile)(0xc00aa9a870)}: cannot set `allowPrivilegeEscalation` to false and `privileged` to true, spec.containers[0].securityContext.windowsOptions.gmsaCredentialSpecName: Invalid value: "ACTOKEY": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), spec.containers[0].securityContext.windowsOptions.hostProcess: Forbidden: not allowed when feature gate 'WindowsHostProcessContainers' is not enabled, spec: Forbidden: pod must not contain Windows hostProcess containers when feature gate 'WindowsHostProcessContainers' is not enabled]
23:34:24 StatefulSet test-cluster-rs0 967:	create Claim mongod-data-test-cluster-rs0-0 Pod test-cluster-rs0-0 in StatefulSet test-cluster-rs0 success
23:34:24 StatefulSet test-cluster-rs0 967:	create Pod test-cluster-rs0-0 in StatefulSet test-cluster-rs0 successful
23:34:50 StatefulSet test-cluster-rs0 990:	create Claim mongod-data-test-cluster-rs0-1 Pod test-cluster-rs0-1 in StatefulSet test-cluster-rs0 success
23:34:50 StatefulSet test-cluster-rs0 990:	create Pod test-cluster-rs0-1 in StatefulSet test-cluster-rs0 successful
23:35:10 StatefulSet test-cluster-rs0 1297:	create Claim mongod-data-test-cluster-rs0-2 Pod test-cluster-rs0-2 in StatefulSet test-cluster-rs0 success
23:35:10 StatefulSet test-cluster-rs0 1297:	create Pod test-cluster-rs0-2 in StatefulSet test-cluster-rs0 successful
23:35:31 StatefulSet test-cluster-rs0 1513:	create Claim mongod-data-test-cluster-rs0-3 Pod test-cluster-rs0-3 in StatefulSet test-cluster-rs0 success
23:35:31 StatefulSet test-cluster-rs0 1513:	create Pod test-cluster-rs0-3 in StatefulSet test-cluster-rs0 successful
